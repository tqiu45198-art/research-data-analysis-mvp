import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
import warnings
import io
import re
import os
from datetime import datetime

# ---------------------- 1. ä¾èµ–å¯¼å…¥ä¸å¼‚å¸¸å¤„ç† ----------------------
warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
st.set_page_config(page_title="ç§‘ç ”æ•°æ®åˆ†æå¹³å°ï¼ˆSPSSæ ¸å¿ƒåŠŸèƒ½ç‰ˆï¼‰", page_icon="ğŸ”¬ğŸ“Š", layout="wide", initial_sidebar_state="expanded")

# åˆ†æ¨¡å—å¯¼å…¥scipyï¼Œé¿å…å•ä¸ªå‡½æ•°å¤±è´¥å¯¼è‡´æ•´ä½“å´©æºƒ
SCIPY_CORE_IMPORTED = False
try:
    from scipy.stats import chi2_contingency, ttest_1samp, ttest_ind, ttest_rel
    from scipy.stats import ks_2samp, mannwhitneyu, kruskal, friedmanchisquare, wilcoxon
    SCIPY_CORE_IMPORTED = True
    # ç”¨statsmodelsæ›¿ä»£binom_test
    from statsmodels.stats.proportion import binom_test as sm_binom_test
    binom_test = sm_binom_test
except ImportError as e:
    st.warning(f"éƒ¨åˆ†ç»Ÿè®¡å‡½æ•°å¯¼å…¥å¤±è´¥ï¼š{str(e)}ï¼ŒåŸºç¡€åŠŸèƒ½ä»å¯ä½¿ç”¨")
    binom_test = None

# å»¶è¿Ÿå¯¼å…¥å…¶ä»–ä¾èµ–
STATSMODELS_IMPORTED = False
try:
    from statsmodels.stats.contingency_tables import mcnemar
    from statsmodels.formula.api import ols, glm
    from statsmodels.stats.anova import anova_lm
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    STATSMODELS_IMPORTED = True
except ImportError:
    st.warning("statsmodelså¯¼å…¥å¤±è´¥ï¼Œæ–¹å·®åˆ†æåŠŸèƒ½å—é™")

SKLEARN_IMPORTED = False
try:
    from sklearn.cluster import KMeans, AgglomerativeClustering
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.linear_model import LinearRegression, LogisticRegression
    from sklearn.metrics import r2_score, classification_report
    SKLEARN_IMPORTED = True
except ImportError:
    st.warning("sklearnå¯¼å…¥å¤±è´¥ï¼Œèšç±»/å›å½’åŠŸèƒ½å—é™")

FACTOR_ANALYZER_IMPORTED = False
try:
    from factor_analyzer import FactorAnalyzer
    FACTOR_ANALYZER_IMPORTED = True
except ImportError:
    st.warning("factor_analyzerå¯¼å…¥å¤±è´¥ï¼Œå› å­åˆ†æåŠŸèƒ½å—é™")

# ---------------------- 2. æ ¸å¿ƒå·¥å…·å‡½æ•° ----------------------
def load_and_clean_data(file):
    encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312']
    seps = [',', '\t', ';']
    try:
        file_content = file.read()
        file.seek(0)
        df = None
        if file.name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        if encoding == 'utf-16':
                            content = file_content.decode(encoding, errors='replace')
                            df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip')
                        else:
                            df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        break
                    except:
                        continue
                if df is not None:
                    break
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
        df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

def identify_variable_types(df):
    numeric_cols = []
    categorical_cols = []
    binary_categorical_cols = []
    datetime_cols = []
    for col in df.columns:
        if any(fmt in col.lower() for fmt in ['date', 'time', '2016', '2017', '2018']):
            try:
                df[col] = pd.to_datetime(df[col])
                datetime_cols.append(col)
                continue
            except:
                pass
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            numeric_cols.append(col)
        except:
            categorical_cols.append(col)
            if df[col].nunique() == 2:
                binary_categorical_cols.append(col)
    return {'numeric': numeric_cols, 'categorical': categorical_cols, 'binary_categorical': binary_categorical_cols, 'datetime': datetime_cols}

# ---------------------- 3. é¡µé¢æ¸²æŸ“é€»è¾‘ï¼ˆæ ¸å¿ƒä¿®å¤ï¼‰ ----------------------
# å…ˆæ¸²æŸ“æ ‡é¢˜å’Œä¾èµ–çŠ¶æ€ï¼Œç¡®ä¿è¿™éƒ¨åˆ†å¿«é€Ÿå®Œæˆ
st.title("ğŸ”¬ ç§‘ç ”æ•°æ®åˆ†æå¹³å°ï¼ˆSPSSæ ¸å¿ƒåŠŸèƒ½ç‰ˆï¼‰")
st.divider()

# ç¯å¢ƒä¾èµ–çŠ¶æ€ï¼ˆæ”¾åœ¨æœ€å‰é¢ï¼Œå¿«é€Ÿæ¸²æŸ“ï¼‰
st.markdown("### ğŸ› ï¸ ç¯å¢ƒä¾èµ–çŠ¶æ€")
status_col1, status_col2 = st.columns(2)
with status_col1:
    st.write(f"- scipyï¼ˆç»Ÿè®¡æ ¸å¿ƒï¼‰ï¼š{'âœ… æ ¸å¿ƒå‡½æ•°å·²å¯¼å…¥' if SCIPY_CORE_IMPORTED else 'âŒ æœªå¯¼å…¥'}")
    st.write(f"- statsmodelsï¼ˆæ–¹å·®åˆ†æï¼‰ï¼š{'âœ… å·²å¯¼å…¥' if STATSMODELS_IMPORTED else 'âŒ æœªå¯¼å…¥'}")
with status_col2:
    st.write(f"- sklearnï¼ˆèšç±»/å›å½’ï¼‰ï¼š{'âœ… å·²å¯¼å…¥' if SKLEARN_IMPORTED else 'âŒ æœªå¯¼å…¥'}")
    st.write(f"- factor_analyzerï¼ˆå› å­åˆ†æï¼‰ï¼š{'âœ… å·²å¯¼å…¥' if FACTOR_ANALYZER_IMPORTED else 'âŒ æœªå¯¼å…¥'}")
st.divider()

# ---------------------- 4. ä¾§è¾¹æ ï¼ˆç¡®ä¿å§‹ç»ˆæ¸²æŸ“ï¼‰ ----------------------
with st.sidebar:
    st.markdown("### ğŸ“¥ æ•°æ®ä¸Šä¼ ")
    uploaded_files = st.file_uploader(
        "æ”¯æŒCSV/Excelï¼ˆå¯ä¼ å¤šä¸ªï¼‰",
        type=["xlsx", "csv"],
        accept_multiple_files=True,
        key="file_uploader"  # å›ºå®škeyé¿å…æ¸²æŸ“å¼‚å¸¸
    )
    
    df = None
    if uploaded_files:
        st.markdown("### ğŸ“‹ é€‰æ‹©åˆ†ææ–‡ä»¶")
        selected_file_names = st.multiselect(
            "å‹¾é€‰æ–‡ä»¶",
            [f.name for f in uploaded_files],
            default=[uploaded_files[0].name] if uploaded_files else [],
            key="file_selector"
        )
        selected_files = [f for f in uploaded_files if f.name in selected_file_names]
        
        df_dict = {}
        for file in selected_files:
            df_temp = load_and_clean_data(file)
            if df_temp is not None:
                df_dict[file.name] = df_temp
                st.success(f"âœ… {file.name} ({len(df_temp)}è¡ŒÃ—{len(df_temp.columns)}åˆ—)")
        
        if len(df_dict) >= 2:
            st.markdown("### ğŸ”— æ•°æ®åˆå¹¶")
            base_file = st.selectbox("åŸºç¡€æ–‡ä»¶", list(df_dict.keys()), key="base_file")
            df = df_dict[base_file]
            for other_file in [f for f in df_dict.keys() if f != base_file]:
                df_other = df_dict[other_file]
                common_cols = [col for col in df.columns if col in df_other.columns]
                base_key = st.selectbox(f"åŸºç¡€æ–‡ä»¶å…³è”å­—æ®µ", common_cols if common_cols else df.columns, key=f"base_key_{other_file}")
                join_key = st.selectbox(f"å…³è”æ–‡ä»¶å…³è”å­—æ®µ", common_cols if common_cols else df_other.columns, key=f"join_key_{other_file}")
                join_type = st.selectbox(f"åˆå¹¶æ–¹å¼", ['å·¦è¿æ¥', 'å³è¿æ¥', 'å†…è¿æ¥', 'å¤–è¿æ¥'], key=f"join_type_{other_file}")
                join_map = {'å·¦è¿æ¥':'left', 'å³è¿æ¥':'right', 'å†…è¿æ¥':'inner', 'å¤–è¿æ¥':'outer'}
                if st.button(f"åˆå¹¶{other_file}", key=f"merge_btn_{other_file}"):
                    df = pd.merge(df, df_other, left_on=base_key, right_on=join_key, how=join_map[join_type], suffixes=("", f"_{other_file.split('.')[0]}"))
                    st.success(f"âœ… åˆå¹¶åï¼š{len(df)}è¡ŒÃ—{len(df.columns)}åˆ—")
        else:
            df = df_dict[list(df_dict.keys())[0]] if df_dict else None
        
        if df is not None:
            var_types = identify_variable_types(df)
            st.markdown("### ğŸ“Š æ•°æ®æ¦‚å†µ")
            st.write(f"è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            st.write(f"æ•°å€¼å‹ï¼š{len(var_types['numeric'])}ä¸ª")
            st.write(f"åˆ†ç±»å‹ï¼š{len(var_types['categorical'])}ä¸ª")

# ---------------------- 5. ä¸»å†…å®¹åŒºï¼ˆå¤„ç†æ— æ•°æ®æƒ…å†µï¼‰ ----------------------
if df is not None:
    var_types = identify_variable_types(df)
    col1, col2 = st.columns([3, 2])
    with col1:
        st.subheader("ğŸ” æ•°æ®é¢„è§ˆ")
        st.dataframe(df.head(10), use_container_width=True, height=300)
    with col2:
        st.subheader("ğŸ“‹ å˜é‡ç±»å‹")
        st.write(f"â° æ—¶é—´å‹ï¼š{', '.join(var_types['datetime']) if var_types['datetime'] else 'æ— '}")
        st.write(f"ğŸ”¢ äºŒåˆ†ç±»ï¼š{', '.join(var_types['binary_categorical']) if var_types['binary_categorical'] else 'æ— '}")
    
    # åç»­åˆ†ææ ‡ç­¾é¡µï¼ˆçœç•¥ï¼Œä¿æŒåŸæœ‰é€»è¾‘ï¼‰
    tab1, tab2, tab3 = st.tabs(["æ•°æ®å¤„ç†", "åŸºæœ¬ç»Ÿè®¡", "å¯è§†åŒ–åˆ†æ"])
    with tab1:
        st.markdown("#### ğŸ”§ æ•°æ®å¤„ç†åŠŸèƒ½")
        st.info("è¯·ä¸Šä¼ æ•°æ®åä½¿ç”¨æ•°æ®æ’åºã€ç­›é€‰ç­‰åŠŸèƒ½")
else:
    # æ— æ•°æ®æ—¶çš„æ˜ç¡®æç¤ºï¼Œé¿å…å¡ä½
    st.info("ğŸ’¡ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSV/Excelæ–‡ä»¶ï¼Œä¸Šä¼ åå³å¯ä½¿ç”¨æ‰€æœ‰åˆ†æåŠŸèƒ½")
    st.markdown("#### ğŸ¯ åŠŸèƒ½é¢„è§ˆ")
    st.write("- æ”¯æŒæ•°æ®ä¸Šä¼ ã€å¤šæ–‡ä»¶åˆå¹¶ã€æ•°æ®æ¸…æ´—")
    st.write("- åŒ…å«é¢‘æ•°åˆ†æã€tæ£€éªŒã€æ–¹å·®åˆ†æã€å›å½’åˆ†æç­‰SPSSæ ¸å¿ƒåŠŸèƒ½")
    st.write("- æä¾›å¯è§†åŒ–å›¾è¡¨ç”Ÿæˆä¸æŠ¥å‘Šå¯¼å‡º")
