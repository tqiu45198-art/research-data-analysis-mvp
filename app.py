import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
from scipy.stats import chi2_contingency, ttest_1samp, ttest_ind, ttest_rel, binom_test, ks_2samp, mannwhitneyu, kruskal, friedmanchisquare, wilcoxon
from statsmodels.stats.proportion import binom_test as sm_binom_test
from statsmodels.stats.contingency_tables import mcnemar
from statsmodels.formula.api import ols, glm
from statsmodels.stats.anova import anova_lm
from statsmodels.stats.multicomp import pairwise_tukeyhsd
from statsmodels.stats.correlation_tools import corr_nearest
from statsmodels.stats.outliers_influence import variance_inflation_factor
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.discriminant_analysis import LinearDiscriminantAnalysis
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.metrics import r2_score, classification_report
from factor_analyzer import FactorAnalyzer
from scipy.cluster.hierarchy import dendrogram, linkage
import warnings
import io
import re
import os
from datetime import datetime

warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
st.set_page_config(page_title="ç§‘ç ”æ•°æ®åˆ†æå¹³å°ï¼ˆSPSSæ ¸å¿ƒåŠŸèƒ½ç‰ˆï¼‰", page_icon="ğŸ”¬ğŸ“Š", layout="wide", initial_sidebar_state="expanded")

def load_and_clean_data(file):
    encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312']
    seps = [',', '\t', ';']
    try:
        file_content = file.read()
        file.seek(0)
        df = None
        if file.name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        if encoding == 'utf-16':
                            content = file_content.decode(encoding, errors='replace')
                            df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip')
                        else:
                            df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        break
                    except:
                        continue
                if df is not None:
                    break
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
        df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

def identify_variable_types(df):
    numeric_cols = []
    categorical_cols = []
    binary_categorical_cols = []
    datetime_cols = []
    for col in df.columns:
        if any(fmt in col.lower() for fmt in ['date', 'time', '2016', '2017', '2018', '2019', '2020']):
            try:
                df[col] = pd.to_datetime(df[col])
                datetime_cols.append(col)
                continue
            except:
                pass
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            numeric_cols.append(col)
        except:
            categorical_cols.append(col)
            if df[col].nunique() == 2:
                binary_categorical_cols.append(col)
    return {'numeric': numeric_cols, 'categorical': categorical_cols, 'binary_categorical': binary_categorical_cols, 'datetime': datetime_cols}

def frequency_analysis(df, categorical_cols):
    freq_dict = {}
    for col in categorical_cols:
        freq = df[col].value_counts()
        freq_pct = df[col].value_counts(normalize=True) * 100
        freq_df = pd.DataFrame({'é¢‘æ•°': freq, 'é¢‘ç‡(%)': freq_pct.round(2)})
        freq_dict[col] = freq_df
    return freq_dict

def descriptive_analysis(df, numeric_cols):
    desc_df = df[numeric_cols].describe().T
    desc_df['ç¼ºå¤±å€¼'] = df[numeric_cols].isnull().sum()
    desc_df['ç¼ºå¤±ç‡(%)'] = (desc_df['ç¼ºå¤±å€¼'] / len(df) * 100).round(2)
    desc_df['ååº¦'] = df[numeric_cols].skew().round(3)
    desc_df['å³°åº¦'] = df[numeric_cols].kurt().round(3)
    return desc_df

def explore_analysis(df, numeric_col):
    q1 = df[numeric_col].quantile(0.25)
    q3 = df[numeric_col].quantile(0.75)
    iqr = q3 - q1
    lower = q1 - 1.5 * iqr
    upper = q3 + 1.5 * iqr
    outliers = df[(df[numeric_col] < lower) | (df[numeric_col] > upper)][numeric_col]
    normality = stats.shapiro(df[numeric_col].dropna())
    return {
        'å››åˆ†ä½è·': iqr.round(2),
        'å¼‚å¸¸å€¼æ•°é‡': len(outliers),
        'Shapiro-Wilkæ­£æ€æ€§æ£€éªŒ': {'Wå€¼': normality[0].round(3), 'på€¼': normality[1].round(4)},
        'æœ€å°å€¼': df[numeric_col].min(),
        'æœ€å¤§å€¼': df[numeric_col].max(),
        'ä¸­ä½æ•°': df[numeric_col].median(),
        'å‡å€¼': df[numeric_col].mean().round(2),
        'æ ‡å‡†å·®': df[numeric_col].std().round(2)
    }

def contingency_table_analysis(df, col1, col2):
    cont_table = pd.crosstab(df[col1], df[col2])
    chi2, p, dof, expected = chi2_contingency(cont_table)
    cramers_v = np.sqrt(chi2 / (len(df) * min(cont_table.shape[0]-1, cont_table.shape[1]-1)))
    return {
        'è”åˆ—è¡¨': cont_table,
        'å¡æ–¹å€¼': chi2.round(3),
        'på€¼': p.round(4),
        'è‡ªç”±åº¦': dof,
        'å…‹è±å§†Vç³»æ•°': cramers_v.round(3)
    }

def t_test_onesample(df, numeric_col, popmean):
    data = df[numeric_col].dropna()
    t_stat, p_value = ttest_1samp(data, popmean)
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), 'å‡å€¼': data.mean().round(2), 'æ ·æœ¬é‡': len(data)}

def t_test_independent(df, numeric_col, group_col):
    groups = df[group_col].unique()
    if len(groups) != 2:
        return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
    group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
    group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
    t_stat, p_value = ttest_ind(group1, group2, equal_var=False)
    return {
        'tå€¼': t_stat.round(3),
        'på€¼': p_value.round(4),
        f'{groups[0]}å‡å€¼': group1.mean().round(2),
        f'{groups[1]}å‡å€¼': group2.mean().round(2),
        f'{groups[0]}æ ·æœ¬é‡': len(group1),
        f'{groups[1]}æ ·æœ¬é‡': len(group2)
    }

def t_test_paired(df, col1, col2):
    paired_data = df[[col1, col2]].dropna()
    t_stat, p_value = ttest_rel(paired_data[col1], paired_data[col2])
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), 'å·®å€¼å‡å€¼': (paired_data[col1]-paired_data[col2]).mean().round(2), 'æ ·æœ¬é‡': len(paired_data)}

def nonparametric_test(df, test_type, numeric_col, group_col=None):
    if test_type == 'å•æ ·æœ¬K-Sæ£€éªŒ':
        data = df[numeric_col].dropna()
        ks_stat, p_value = stats.kstest(data, 'norm', args=(data.mean(), data.std()))
        return {'KSç»Ÿè®¡é‡': ks_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ':
        groups = df[group_col].unique()
        if len(groups) != 2:
            return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
        group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
        group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
        u_stat, p_value = mannwhitneyu(group1, group2)
        return {'Uå€¼': u_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'å¤šç‹¬ç«‹æ ·æœ¬Kruskal-Wallis Hæ£€éªŒ':
        groups_data = [df[df[group_col] == g][numeric_col].dropna() for g in df[group_col].unique()]
        h_stat, p_value = kruskal(*groups_data)
        return {'Hå€¼': h_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'ä¸¤é…å¯¹æ ·æœ¬Wilcoxonæ£€éªŒ':
        paired_data = df[[numeric_col, group_col]].dropna()
        w_stat, p_value = wilcoxon(paired_data[numeric_col], paired_data[group_col])
        return {'Wå€¼': w_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'å¤šé…å¯¹æ ·æœ¬Friedmanæ£€éªŒ':
        cols = [col for col in df.columns if col in [numeric_col, group_col]] if group_col else df.select_dtypes(include=np.number).columns[:3]
        friedman_stat, p_value = friedmanchisquare(*[df[col].dropna() for col in cols])
        return {'Friedmanç»Ÿè®¡é‡': friedman_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ':
        data = df[numeric_col].dropna()
        success = sum(data == 1)
        n = len(data)
        p_value = binom_test(success, n, p=0.5)
        return {'æˆåŠŸæ¬¡æ•°': success, 'æ€»æ¬¡æ•°': n, 'på€¼': p_value.round(4)}
    return {'error': 'æ— æ•ˆæ£€éªŒç±»å‹'}

def anova_analysis(df, formula, anova_type):
    model = ols(formula, data=df).fit()
    if anova_type == 'å•å› ç´ æ–¹å·®åˆ†æ':
        anova_result = anova_lm(model, typ=2)
    elif anova_type == 'å¤šå› ç´ æ–¹å·®åˆ†æ':
        anova_result = anova_lm(model, typ=3)
    elif anova_type == 'åæ–¹å·®åˆ†æ':
        anova_result = anova_lm(model, typ=2)
    else:
        return {'error': 'æ— æ•ˆæ–¹å·®åˆ†æç±»å‹'}
    tukey = pairwise_tukeyhsd(df[formula.split('~')[0]], df[formula.split('~')[1].split('+')[0]], alpha=0.05)
    return {'æ–¹å·®åˆ†æè¡¨': anova_result, 'äº‹åæ£€éªŒ(Tukey)': tukey.summary()}

def correlation_analysis(df, cols, corr_type='pearson'):
    corr_df = df[cols].dropna()
    if corr_type == 'pearson':
        corr_matrix = corr_df.corr(method='pearson')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.pearsonr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    elif corr_type == 'spearman':
        corr_matrix = corr_df.corr(method='spearman')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.spearmanr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    elif corr_type == 'partial':
        from statsmodels.stats.correlation_tools import partial_corr
        corr_matrix = partial_corr(corr_df).round(3)
        p_matrix = None
    return {'ç›¸å…³çŸ©é˜µ': corr_matrix.round(3), 'på€¼çŸ©é˜µ': p_matrix}

def regression_analysis(df, target, features, reg_type):
    X = df[features].dropna()
    y = df[target][X.index].dropna()
    X = X.loc[y.index]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    if reg_type == 'çº¿æ€§å›å½’':
        model = LinearRegression().fit(X_scaled, y)
        y_pred = model.predict(X_scaled)
        r2 = r2_score(y, y_pred)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_.round(3), 'æˆªè·': [model.intercept_.round(3)]*len(features)})
        return {'RÂ²': r2.round(3), 'ç³»æ•°è¡¨': coef, 'æ¨¡å‹': model}
    elif reg_type == 'äºŒåˆ†ç±»Logisticå›å½’':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        model = LogisticRegression(max_iter=1000).fit(X_scaled, y_encoded)
        y_pred = model.predict(X_scaled)
        report = classification_report(y_encoded, y_pred, output_dict=True)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_[0].round(3), 'æˆªè·': [model.intercept_[0].round(3)]*len(features)})
        return {'åˆ†ç±»æŠ¥å‘Š': report, 'ç³»æ•°è¡¨': coef, 'æ¨¡å‹': model}
    return {'error': 'æ— æ•ˆå›å½’ç±»å‹'}

def cluster_analysis(df, cols, cluster_type, n_clusters=3):
    X = df[cols].dropna()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    if cluster_type == 'å¿«é€Ÿèšç±»(KMeans)':
        kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_scaled)
        df_cluster = X.copy()
        df_cluster['èšç±»ç»“æœ'] = kmeans.labels_
        centroids = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=cols).round(2)
        return {'èšç±»ç»“æœ': df_cluster, 'èšç±»ä¸­å¿ƒ': centroids}
    elif cluster_type == 'ç³»ç»Ÿèšç±»':
        Z = linkage(X_scaled, method='ward')
        fig, ax = plt.subplots(figsize=(10, 6))
        dendrogram(Z, labels=X.index, ax=ax)
        plt.title('ç³»ç»Ÿèšç±»æ ‘çŠ¶å›¾')
        plt.tight_layout()
        buf = io.BytesIO()
        plt.savefig(buf, format='png', dpi=300)
        buf.seek(0)
        return {'æ ‘çŠ¶å›¾': buf, 'é“¾æ¥çŸ©é˜µ': Z}
    return {'error': 'æ— æ•ˆèšç±»ç±»å‹'}

def factor_analysis(df, cols, n_factors=3):
    X = df[cols].dropna()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    fa = FactorAnalyzer(n_factors=n_factors, rotation='varimax', method='principal')
    fa.fit(X_scaled)
    loadings = pd.DataFrame(fa.loadings_, index=cols, columns=[f'å› å­{i+1}' for i in range(n_factors)]).round(3)
    eigen_values = fa.get_eigenvalues()[0]
    variance = fa.get_factor_variance()
    variance_df = pd.DataFrame({
        'å› å­': [f'å› å­{i+1}' for i in range(n_factors)],
        'æ–¹å·®è´¡çŒ®ç‡': variance[1].round(3),
        'ç´¯è®¡æ–¹å·®è´¡çŒ®ç‡': variance[2].round(3)
    })
    return {'å› å­è½½è·çŸ©é˜µ': loadings, 'ç‰¹å¾å€¼': eigen_values.round(3), 'æ–¹å·®è´¡çŒ®ç‡': variance_df}

def reliability_analysis(df, cols):
    cronbach_alpha = stats.stats.cronbach_alpha(df[cols].dropna())[0].round(3)
    item_total_corr = []
    for col in cols:
        temp_cols = [c for c in cols if c != col]
        corr = df[col].corr(df[temp_cols].sum(axis=1))
        item_total_corr.append(corr.round(3))
    reliability_df = pd.DataFrame({'é¡¹ç›®': cols, 'é¡¹ç›®-æ€»åˆ†ç›¸å…³': item_total_corr})
    return {'å…‹æœ—å·´å“ˆÎ±ç³»æ•°': cronbach_alpha, 'é¡¹ç›®-æ€»åˆ†ç›¸å…³': reliability_df}

def plot_chart(df, plot_type, x_col, y_col=None, group_col=None):
    if plot_type == 'æ¡å½¢å›¾':
        fig = px.bar(df, x=x_col, y=y_col, color=group_col, barmode='group', title=f'{x_col} - {y_col} æ¡å½¢å›¾')
    elif plot_type == 'æŠ˜çº¿å›¾':
        fig = px.line(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col} æŠ˜çº¿å›¾')
    elif plot_type == 'é¢ç§¯å›¾':
        fig = px.area(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col} é¢ç§¯å›¾')
    elif plot_type == 'é¥¼å›¾':
        fig = px.pie(df, names=x_col, values=y_col, title=f'{x_col} é¥¼å›¾')
    elif plot_type == 'ç®±å›¾':
        fig = px.box(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col} ç®±å›¾')
    elif plot_type == 'é«˜ä½å›¾':
        fig = go.Figure()
        fig.add_trace(go.Bar(x=df[x_col], y=df[y_col], name='é«˜å€¼'))
        fig.add_trace(go.Bar(x=df[x_col], y=df[group_col], name='ä½å€¼'))
        fig.update_layout(barmode='group', title=f'{x_col} é«˜ä½å›¾')
    fig.update_layout(width=800, height=500)
    return fig

st.title("ğŸ”¬ ç§‘ç ”æ•°æ®åˆ†æå¹³å°ï¼ˆSPSSæ ¸å¿ƒåŠŸèƒ½ç‰ˆï¼‰")
st.divider()

with st.sidebar:
    st.markdown("### æ•°æ®ä¸Šä¼ ")
    uploaded_files = st.file_uploader("æ”¯æŒCSV/Excelï¼ˆå¯ä¼ å¤šä¸ªï¼‰", type=["xlsx", "csv"], accept_multiple_files=True)
    df = None
    if uploaded_files:
        st.markdown("### é€‰æ‹©åˆ†ææ–‡ä»¶")
        selected_file_names = st.multiselect("å‹¾é€‰æ–‡ä»¶", [f.name for f in uploaded_files], default=[uploaded_files[0].name])
        selected_files = [f for f in uploaded_files if f.name in selected_file_names]
        df_dict = {}
        for file in selected_files:
            df_temp = load_and_clean_data(file)
            if df_temp is not None:
                df_dict[file.name] = df_temp
                st.success(f"âœ… {file.name} ({len(df_temp)}è¡ŒÃ—{len(df_temp.columns)}åˆ—)")
        if len(df_dict) >= 2:
            st.markdown("### æ•°æ®åˆå¹¶")
            base_file = st.selectbox("åŸºç¡€æ–‡ä»¶", list(df_dict.keys()))
            df = df_dict[base_file]
            for other_file in [f for f in df_dict.keys() if f != base_file]:
                df_other = df_dict[other_file]
                common_cols = [col for col in df.columns if col in df_other.columns]
                base_key = st.selectbox(f"åŸºç¡€æ–‡ä»¶å…³è”å­—æ®µ", common_cols if common_cols else df.columns, key=f"base_{other_file}")
                join_key = st.selectbox(f"å…³è”æ–‡ä»¶å…³è”å­—æ®µ", common_cols if common_cols else df_other.columns, key=f"join_{other_file}")
                join_type = st.selectbox(f"åˆå¹¶æ–¹å¼", ['å·¦è¿æ¥', 'å³è¿æ¥', 'å†…è¿æ¥', 'å¤–è¿æ¥'], key=f"type_{other_file}")
                join_map = {'å·¦è¿æ¥':'left', 'å³è¿æ¥':'right', 'å†…è¿æ¥':'inner', 'å¤–è¿æ¥':'outer'}
                if st.button(f"åˆå¹¶{other_file}", key=f"btn_{other_file}"):
                    df = pd.merge(df, df_other, left_on=base_key, right_on=join_key, how=join_map[join_type], suffixes=("", f"_{other_file.split('.')[0]}"))
                    st.success(f"âœ… åˆå¹¶åï¼š{len(df)}è¡ŒÃ—{len(df.columns)}åˆ—")
        else:
            df = df_dict[list(df_dict.keys())[0]]
        if df is not None:
            var_types = identify_variable_types(df)
            st.markdown("### æ•°æ®æ¦‚å†µ")
            st.write(f"ğŸ“Š è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            st.write(f"ğŸ“ˆ æ•°å€¼å‹ï¼š{len(var_types['numeric'])}ä¸ª")
            st.write(f"ğŸ·ï¸ åˆ†ç±»å‹ï¼š{len(var_types['categorical'])}ä¸ª")
            st.write(f"âŒ ç¼ºå¤±å€¼ï¼š{df.isnull().sum().sum()}ä¸ª")

if df is not None:
    var_types = identify_variable_types(df)
    col1, col2 = st.columns([3, 2])
    with col1:
        st.subheader("æ•°æ®é¢„è§ˆ")
        st.dataframe(df.head(10), use_container_width=True, height=300)
    with col2:
        st.subheader("å˜é‡ç±»å‹")
        st.write(f"â° æ—¶é—´å‹ï¼š{', '.join(var_types['datetime']) if var_types['datetime'] else 'æ— '}")
        st.write(f"ğŸ”¢ äºŒåˆ†ç±»ï¼š{', '.join(var_types['binary_categorical']) if var_types['binary_categorical'] else 'æ— '}")
    
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "æ•°æ®å¤„ç†", "åŸºæœ¬ç»Ÿè®¡", "å‡å€¼æ£€éªŒ", "æ–¹å·®åˆ†æ", "ç›¸å…³åˆ†æ", "å›å½’åˆ†æ", "é«˜çº§åˆ†æ"
    ])
    
    with tab1:
        st.subheader("æ•°æ®å¤„ç†")
        process_tab1, process_tab2, process_tab3 = st.tabs(["æ•°æ®ç¼–è¾‘", "æ•°æ®å˜æ¢", "æ–‡ä»¶æ“ä½œ"])
        with process_tab1:
            st.markdown("#### æ•°æ®æ’åº")
            sort_col = st.selectbox("æ’åºå­—æ®µ", df.columns)
            sort_asc = st.radio("æ’åºæ–¹å¼", ['å‡åº', 'é™åº'])
            if st.button("æ‰§è¡Œæ’åº"):
                df_sorted = df.sort_values(by=sort_col, ascending=(sort_asc=='å‡åº'))
                st.dataframe(df_sorted.head(10), use_container_width=True)
            
            st.markdown("#### é€‰æ‹©ä¸ªæ¡ˆ")
            filter_col = st.selectbox("ç­›é€‰å­—æ®µ", df.columns)
            filter_op = st.selectbox("è¿ç®—ç¬¦", ['>', '<', '>=', '<=', '==', '!='])
            filter_val = st.text_input("ç­›é€‰å€¼")
            if st.button("æ‰§è¡Œç­›é€‰"):
                try:
                    if df[filter_col].dtype in [np.int64, np.float64]:
                        filter_val = float(filter_val)
                    df_filtered = df.query(f"`{filter_col}` {filter_op} {filter_val}")
                    st.success(f"ç­›é€‰åï¼š{len(df_filtered)}è¡Œ")
                    st.dataframe(df_filtered.head(10), use_container_width=True)
                except:
                    st.error("ç­›é€‰æ¡ä»¶é”™è¯¯")
            
            st.markdown("#### ä¸ªæ¡ˆåŠ æƒ")
            weight_col = st.selectbox("åŠ æƒå­—æ®µ", var_types['numeric'], key='weight')
            if st.button("åº”ç”¨åŠ æƒ"):
                df_weighted = df.copy()
                df_weighted['æƒé‡'] = df_weighted[weight_col] / df_weighted[weight_col].sum()
                st.dataframe(df_weighted[['æƒé‡'] + df.columns.tolist()].head(10), use_container_width=True)
        
        with process_tab2:
            st.markdown("#### è®¡ç®—æ–°å˜é‡")
            new_var_name = st.text_input("æ–°å˜é‡å")
            formula = st.text_input("è®¡ç®—å…¬å¼ï¼ˆä¾‹ï¼šcol1+col2 æˆ– col1*0.5ï¼‰")
            if st.button("ç”Ÿæˆæ–°å˜é‡"):
                try:
                    df_new = df.copy()
                    df_new[new_var_name] = df_new.eval(formula)
                    st.success(f"âœ… ç”Ÿæˆæ–°å˜é‡ï¼š{new_var_name}")
                    st.dataframe(df_new[[new_var_name]].head(10), use_container_width=True)
                    df = df_new
                    var_types = identify_variable_types(df)
                except:
                    st.error("å…¬å¼é”™è¯¯")
            
            st.markdown("#### å˜é‡é‡æ–°ç¼–ç ")
            recode_col = st.selectbox("å¾…ç¼–ç å­—æ®µ", var_types['numeric'], key='recode')
            bins = st.slider("åˆ†ç»„æ•°", 2, 10, 5)
            labels = [f'ç»„{i+1}' for i in range(bins)]
            if st.button("æ‰§è¡Œé‡ç¼–ç "):
                df_recode = df.copy()
                df_recode[f'{recode_col}_ç¼–ç '] = pd.cut(df_recode[recode_col], bins=bins, labels=labels)
                st.dataframe(df_recode[[recode_col, f'{recode_col}_ç¼–ç ']].head(10), use_container_width=True)
            
            st.markdown("#### ä¸ªæ¡ˆç­‰çº§æ’åº")
            rank_col = st.selectbox("æ’åºå­—æ®µ", var_types['numeric'], key='rank')
            if st.button("æ‰§è¡Œç­‰çº§æ’åº"):
                df_rank = df.copy()
                df_rank[f'{rank_col}_ç­‰çº§'] = df_rank[rank_col].rank(ascending=False)
                st.dataframe(df_rank[[rank_col, f'{rank_col}_ç­‰çº§']].head(10), use_container_width=True)
        
        with process_tab3:
            st.markdown("#### æ•°æ®è½¬ç½®")
            if st.button("æ‰§è¡Œè½¬ç½®"):
                df_trans = df.set_index(df.columns[0]).T
                st.dataframe(df_trans.head(10), use_container_width=True)
            
            st.markdown("#### åˆ†ç±»æ±‡æ€»")
            group_col = st.selectbox("åˆ†ç»„å­—æ®µ", var_types['categorical'], key='group')
            agg_col = st.selectbox("æ±‡æ€»å­—æ®µ", var_types['numeric'], key='agg')
            agg_func = st.selectbox("æ±‡æ€»æ–¹å¼", ['å‡å€¼', 'æ±‚å’Œ', 'è®¡æ•°', 'æœ€å¤§å€¼', 'æœ€å°å€¼'])
            agg_map = {'å‡å€¼':'mean', 'æ±‚å’Œ':'sum', 'è®¡æ•°':'count', 'æœ€å¤§å€¼':'max', 'æœ€å°å€¼':'min'}
            if st.button("æ‰§è¡Œæ±‡æ€»"):
                df_agg = df.groupby(group_col)[agg_col].agg(agg_map[agg_func]).round(2)
                st.dataframe(df_agg, use_container_width=True)
            
            st.markdown("#### æ–‡ä»¶æ‹†åˆ†")
            split_col = st.selectbox("æ‹†åˆ†å­—æ®µ", var_types['categorical'], key='split')
            if st.button("æ‰§è¡Œæ‹†åˆ†"):
                split_dict = {g: df[df[split_col]==g] for g in df[split_col].unique()}
                for g, d in split_dict.items():
                    st.write(f"ğŸ“ åˆ†ç»„ {g}ï¼š{len(d)}è¡Œ")
                    st.dataframe(d.head(5), use_container_width=True)
    
    with tab2:
        st.subheader("åŸºæœ¬ç»Ÿè®¡åˆ†æ")
        basic_tab1, basic_tab2, basic_tab3 = st.tabs(["é¢‘æ•°åˆ†æ", "æè¿°ç»Ÿè®¡", "æ¢ç´¢æ€§åˆ†æ"])
        with basic_tab1:
            if var_types['categorical']:
                freq_cols = st.multiselect("é€‰æ‹©åˆ†ç±»å‹å˜é‡", var_types['categorical'])
                if freq_cols and st.button("æ‰§è¡Œé¢‘æ•°åˆ†æ"):
                    freq_dict = frequency_analysis(df, freq_cols)
                    for col in freq_cols:
                        st.markdown(f"#### {col} é¢‘æ•°åˆ†æ")
                        st.dataframe(freq_dict[col], use_container_width=True)
        
        with basic_tab2:
            if var_types['numeric']:
                desc_cols = st.multiselect("é€‰æ‹©æ•°å€¼å‹å˜é‡", var_types['numeric'])
                if desc_cols and st.button("æ‰§è¡Œæè¿°ç»Ÿè®¡"):
                    desc_df = descriptive_analysis(df, desc_cols)
                    st.dataframe(desc_df, use_container_width=True)
        
        with basic_tab3:
            if var_types['numeric']:
                explore_col = st.selectbox("é€‰æ‹©æ•°å€¼å‹å˜é‡", var_types['numeric'])
                if st.button("æ‰§è¡Œæ¢ç´¢æ€§åˆ†æ"):
                    explore_res = explore_analysis(df, explore_col)
                    st.markdown("#### æ¢ç´¢æ€§åˆ†æç»“æœ")
                    for k, v in explore_res.items():
                        if isinstance(v, dict):
                            st.write(f"{k}ï¼šWå€¼={v['Wå€¼']}, på€¼={v['på€¼']}")
                        else:
                            st.write(f"{k}ï¼š{v}")
                    fig = px.box(df, y=explore_col, title=f'{explore_col} ç®±çº¿å›¾ï¼ˆå¼‚å¸¸å€¼æ£€æµ‹ï¼‰')
                    st.plotly_chart(fig, use_container_width=True)
            
            st.markdown("#### è”åˆ—è¡¨åˆ†æ")
            if var_types['categorical'] and len(var_types['categorical'])>=2:
                cont_col1 = st.selectbox("è¡Œå˜é‡", var_types['categorical'], key='cont1')
                cont_col2 = st.selectbox("åˆ—å˜é‡", var_types['categorical'], key='cont2')
                if st.button("æ‰§è¡Œè”åˆ—è¡¨åˆ†æ"):
                    cont_res = contingency_table_analysis(df, cont_col1, cont_col2)
                    st.markdown("#### è”åˆ—è¡¨")
                    st.dataframe(cont_res['è”åˆ—è¡¨'], use_container_width=True)
                    st.write(f"å¡æ–¹å€¼ï¼š{cont_res['å¡æ–¹å€¼']}, på€¼ï¼š{cont_res['på€¼']}, å…‹è±å§†Vç³»æ•°ï¼š{cont_res['å…‹è±å§†Vç³»æ•°']}")
    
    with tab3:
        st.subheader("å‡å€¼æ£€éªŒ")
        test_tab1, test_tab2 = st.tabs(["tæ£€éªŒ", "éå‚æ•°æ£€éªŒ"])
        with test_tab1:
            st.markdown("#### å•æ ·æœ¬tæ£€éªŒ")
            if var_types['numeric']:
                onesamp_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='onesamp')
                popmean = st.number_input("æ€»ä½“å‡å€¼", value=0.0)
                if st.button("æ‰§è¡Œå•æ ·æœ¬tæ£€éªŒ"):
                    onesamp_res = t_test_onesample(df, onesamp_col, popmean)
                    st.write(f"tå€¼ï¼š{onesamp_res['tå€¼']}, på€¼ï¼š{onesamp_res['på€¼']}, æ ·æœ¬å‡å€¼ï¼š{onesamp_res['å‡å€¼']}")
            
            st.markdown("#### ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ")
            if var_types['numeric'] and var_types['categorical']:
                ind_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='ind')
                ind_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='ind_group')
                if st.button("æ‰§è¡Œä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ"):
                    ind_res = t_test_independent(df, ind_col, ind_group)
                    if 'error' in ind_res:
                        st.error(ind_res['error'])
                    else:
                        st.write(f"tå€¼ï¼š{ind_res['tå€¼']}, på€¼ï¼š{ind_res['på€¼']}")
                        st.write(f"{list(ind_res.keys())[2]}ï¼š{ind_res[list(ind_res.keys())[2]]}")
                        st.write(f"{list(ind_res.keys())[3]}ï¼š{ind_res[list(ind_res.keys())[3]]}")
            
            st.markdown("#### é…å¯¹æ ·æœ¬tæ£€éªŒ")
            if var_types['numeric'] and len(var_types['numeric'])>=2:
                pair_col1 = st.selectbox("é…å¯¹å˜é‡1", var_types['numeric'], key='pair1')
                pair_col2 = st.selectbox("é…å¯¹å˜é‡2", var_types['numeric'], key='pair2')
                if st.button("æ‰§è¡Œé…å¯¹æ ·æœ¬tæ£€éªŒ"):
                    pair_res = t_test_paired(df, pair_col1, pair_col2)
                    st.write(f"tå€¼ï¼š{pair_res['tå€¼']}, på€¼ï¼š{pair_res['på€¼']}, å·®å€¼å‡å€¼ï¼š{pair_res['å·®å€¼å‡å€¼']}")
        
        with test_tab2:
            st.markdown("#### éå‚æ•°æ£€éªŒ")
            test_type = st.selectbox("æ£€éªŒç±»å‹", ['å•æ ·æœ¬K-Sæ£€éªŒ', 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ', 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ', 'å¤šç‹¬ç«‹æ ·æœ¬Kruskal-Wallis Hæ£€éªŒ', 'ä¸¤é…å¯¹æ ·æœ¬Wilcoxonæ£€éªŒ', 'å¤šé…å¯¹æ ·æœ¬Friedmanæ£€éªŒ'])
            if test_type in ['å•æ ·æœ¬K-Sæ£€éªŒ', 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ']:
                np_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='np1')
                if st.button("æ‰§è¡Œéå‚æ•°æ£€éªŒ"):
                    np_res = nonparametric_test(df, test_type, np_col)
                    if 'error' in np_res:
                        st.error(np_res['error'])
                    else:
                        for k, v in np_res.items():
                            st.write(f"{k}ï¼š{v}")
            elif test_type in ['ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ', 'å¤šç‹¬ç«‹æ ·æœ¬Kruskal-Wallis Hæ£€éªŒ']:
                np_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='np2')
                np_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='np_group')
                if st.button("æ‰§è¡Œéå‚æ•°æ£€éªŒ"):
                    np_res = nonparametric_test(df, test_type, np_col, np_group)
                    if 'error' in np_res:
                        st.error(np_res['error'])
                    else:
                        for k, v in np_res.items():
                            st.write(f"{k}ï¼š{v}")
            else:
                np_col1 = st.selectbox("é…å¯¹å˜é‡1", var_types['numeric'], key='np3')
                np_col2 = st.selectbox("é…å¯¹å˜é‡2", var_types['numeric'], key='np4')
                if st.button("æ‰§è¡Œéå‚æ•°æ£€éªŒ"):
                    np_res = nonparametric_test(df, test_type, np_col1, np_col2)
                    if 'error' in np_res:
                        st.error(np_res['error'])
                    else:
                        for k, v in np_res.items():
                            st.write(f"{k}ï¼š{v}")
    
    with tab4:
        st.subheader("æ–¹å·®åˆ†æ")
        anova_type = st.selectbox("æ–¹å·®åˆ†æç±»å‹", ['å•å› ç´ æ–¹å·®åˆ†æ', 'å¤šå› ç´ æ–¹å·®åˆ†æ', 'åæ–¹å·®åˆ†æ'])
        if var_types['numeric'] and var_types['categorical']:
            anova_target = st.selectbox("å› å˜é‡", var_types['numeric'], key='anova_target')
            anova_factor = st.selectbox("å› ç´ å˜é‡", var_types['categorical'], key='anova_factor')
            if anova_type == 'å¤šå› ç´ æ–¹å·®åˆ†æ':
                anova_factor2 = st.selectbox("ç¬¬äºŒä¸ªå› ç´ å˜é‡", var_types['categorical'], key='anova_factor2')
                formula = f"{anova_target} ~ C({anova_factor}) + C({anova_factor2})"
            elif anova_type == 'åæ–¹å·®åˆ†æ':
                anova_covar = st.selectbox("åå˜é‡", var_types['numeric'], key='anova_covar')
                formula = f"{anova_target} ~ C({anova_factor}) + {anova_covar}"
            else:
                formula = f"{anova_target} ~ C({anova_factor})"
            if st.button("æ‰§è¡Œæ–¹å·®åˆ†æ"):
                anova_res = anova_analysis(df, formula, anova_type)
                if 'error' in anova_res:
                    st.error(anova_res['error'])
                else:
                    st.markdown("#### æ–¹å·®åˆ†æè¡¨")
                    st.dataframe(anova_res['æ–¹å·®åˆ†æè¡¨'], use_container_width=True)
                    st.markdown("#### äº‹åæ£€éªŒ")
                    st.text(anova_res['äº‹åæ£€éªŒ(Tukey)'])
    
    with tab5:
        st.subheader("ç›¸å…³åˆ†æ")
        corr_type = st.selectbox("ç›¸å…³ç±»å‹", ['pearson', 'spearman', 'partial'])
        if var_types['numeric'] and len(var_types['numeric'])>=2:
            corr_cols = st.multiselect("é€‰æ‹©å˜é‡", var_types['numeric'])
            if corr_cols and len(corr_cols)>=2 and st.button("æ‰§è¡Œç›¸å…³åˆ†æ"):
                corr_res = correlation_analysis(df, corr_cols, corr_type)
                st.markdown("#### ç›¸å…³çŸ©é˜µ")
                st.dataframe(corr_res['ç›¸å…³çŸ©é˜µ'], use_container_width=True)
                if corr_res['på€¼çŸ©é˜µ'] is not None:
                    st.markdown("#### på€¼çŸ©é˜µ")
                    st.dataframe(corr_res['på€¼çŸ©é˜µ'], use_container_width=True)
                fig, ax = plt.subplots(figsize=(10, 8))
                im = ax.imshow(corr_res['ç›¸å…³çŸ©é˜µ'], cmap='RdBu_r', vmin=-1, vmax=1)
                ax.set_xticks(np.arange(len(corr_cols)))
                ax.set_yticks(np.arange(len(corr_cols)))
                ax.set_xticklabels(corr_cols, rotation=45, ha='right')
                ax.set_yticklabels(corr_cols)
                for i in range(len(corr_cols)):
                    for j in range(len(corr_cols)):
                        text = ax.text(j, i, corr_res['ç›¸å…³çŸ©é˜µ'].iloc[i, j], ha="center", va="center", color="black")
                cbar = ax.figure.colorbar(im, ax=ax)
                ax.set_title(f'{corr_type}ç›¸å…³ç³»æ•°çƒ­åŠ›å›¾')
                plt.tight_layout()
                st.pyplot(fig)
    
    with tab6:
        st.subheader("å›å½’åˆ†æ")
        reg_type = st.selectbox("å›å½’ç±»å‹", ['çº¿æ€§å›å½’', 'äºŒåˆ†ç±»Logisticå›å½’'])
        if var_types['numeric'] and len(var_types['numeric'])>=2:
            reg_target = st.selectbox("å› å˜é‡", var_types['numeric'] if reg_type=='çº¿æ€§å›å½’' else var_types['binary_categorical'], key='reg_target')
            reg_features = st.multiselect("è‡ªå˜é‡", [col for col in var_types['numeric'] if col != reg_target], key='reg_features')
            if reg_features and st.button("æ‰§è¡Œå›å½’åˆ†æ"):
                reg_res = regression_analysis(df, reg_target, reg_features, reg_type)
                if 'error' in reg_res:
                    st.error(reg_res['error'])
                else:
                    st.markdown("#### æ¨¡å‹ç»“æœ")
                    if reg_type == 'çº¿æ€§å›å½’':
                        st.write(f"RÂ²ï¼š{reg_res['RÂ²']}")
                    else:
                        st.write(f"å‡†ç¡®ç‡ï¼š{reg_res['åˆ†ç±»æŠ¥å‘Š']['accuracy']:.3f}")
                    st.markdown("#### ç³»æ•°è¡¨")
                    st.dataframe(reg_res['ç³»æ•°è¡¨'], use_container_width=True)
    
    with tab7:
        st.subheader("é«˜çº§åˆ†æ")
        advanced_tab1, advanced_tab2, advanced_tab3 = st.tabs(["èšç±»åˆ†æ", "å› å­åˆ†æ", "ä¿¡åº¦åˆ†æ"])
        with advanced_tab1:
            cluster_type = st.selectbox("èšç±»ç±»å‹", ['å¿«é€Ÿèšç±»(KMeans)', 'ç³»ç»Ÿèšç±»'])
            if var_types['numeric'] and len(var_types['numeric'])>=2:
                cluster_cols = st.multiselect("é€‰æ‹©èšç±»å˜é‡", var_types['numeric'])
                n_clusters = st.slider("èšç±»æ•°", 2, 10, 3)
                if cluster_cols and st.button("æ‰§è¡Œèšç±»åˆ†æ"):
                    cluster_res = cluster_analysis(df, cluster_cols, cluster_type, n_clusters)
                    if 'error' in cluster_res:
                        st.error(cluster_res['error'])
                    else:
                        if cluster_type == 'å¿«é€Ÿèšç±»(KMeans)':
                            st.markdown("#### èšç±»ç»“æœ")
                            st.dataframe(cluster_res['èšç±»ç»“æœ'].head(10), use_container_width=True)
                            st.markdown("#### èšç±»ä¸­å¿ƒ")
                            st.dataframe(cluster_res['èšç±»ä¸­å¿ƒ'], use_container_width=True)
                        else:
                            st.markdown("#### ç³»ç»Ÿèšç±»æ ‘çŠ¶å›¾")
                            st.image(cluster_res['æ ‘çŠ¶å›¾'], use_container_width=True)
        
        with advanced_tab2:
            if var_types['numeric'] and len(var_types['numeric'])>=3:
                factor_cols = st.multiselect("é€‰æ‹©å› å­åˆ†æå˜é‡", var_types['numeric'])
                n_factors = st.slider("å› å­æ•°", 2, 5, 3)
                if factor_cols and st.button("æ‰§è¡Œå› å­åˆ†æ"):
                    factor_res = factor_analysis(df, factor_cols, n_factors)
                    st.markdown("#### å› å­è½½è·çŸ©é˜µ")
                    st.dataframe(factor_res['å› å­è½½è·çŸ©é˜µ'], use_container_width=True)
                    st.markdown("#### æ–¹å·®è´¡çŒ®ç‡")
                    st.dataframe(factor_res['æ–¹å·®è´¡çŒ®ç‡'], use_container_width=True)
        
        with advanced_tab3:
            if var_types['numeric'] and len(var_types['numeric'])>=3:
                reli_cols = st.multiselect("é€‰æ‹©ä¿¡åº¦åˆ†æå˜é‡", var_types['numeric'])
                if reli_cols and st.button("æ‰§è¡Œä¿¡åº¦åˆ†æ"):
                    reli_res = reliability_analysis(df, reli_cols)
                    st.write(f"å…‹æœ—å·´å“ˆÎ±ç³»æ•°ï¼š{reli_res['å…‹æœ—å·´å“ˆÎ±ç³»æ•°']}")
                    st.markdown("#### é¡¹ç›®-æ€»åˆ†ç›¸å…³")
                    st.dataframe(reli_res['é¡¹ç›®-æ€»åˆ†ç›¸å…³'], use_container_width=True)
    
    st.divider()
    st.subheader("å¯è§†åŒ–åˆ†æ")
    plot_type = st.selectbox("å›¾è¡¨ç±»å‹", ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'é¢ç§¯å›¾', 'é¥¼å›¾', 'é«˜ä½å›¾', 'ç®±å›¾'])
    if plot_type in ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'é¢ç§¯å›¾', 'ç®±å›¾', 'é«˜ä½å›¾']:
        x_col = st.selectbox("Xè½´å˜é‡", df.columns, key='plot_x')
        y_col = st.selectbox("Yè½´å˜é‡", var_types['numeric'], key='plot_y')
        group_col = st.selectbox("åˆ†ç»„å˜é‡ï¼ˆå¯é€‰ï¼‰", [None] + var_types['categorical'], key='plot_group')
    else:
        x_col = st.selectbox("ç±»åˆ«å˜é‡", var_types['categorical'], key='plot_x_pie')
        y_col = st.selectbox("æ•°å€¼å˜é‡", var_types['numeric'], key='plot_y_pie')
        group_col = None
    if st.button("ç”Ÿæˆå›¾è¡¨"):
        fig = plot_chart(df, plot_type, x_col, y_col, group_col)
        st.plotly_chart(fig, use_container_width=True)
    
    st.divider()
    st.subheader("å¯¼å‡ºåˆ†ææŠ¥å‘Š")
    report_content = f"""# ç§‘ç ”æ•°æ®åˆ†ææŠ¥å‘Š
## ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
## æ•°æ®æ¦‚å†µ
- è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—
- æ•°å€¼å‹å˜é‡ï¼š{', '.join(var_types['numeric'])}
- åˆ†ç±»å‹å˜é‡ï¼š{', '.join(var_types['categorical'])}
- ç¼ºå¤±å€¼æ€»æ•°ï¼š{df.isnull().sum().sum()}ä¸ª

## åˆ†æç»“è®º
ï¼ˆæ ¹æ®ä¸Šè¿°åˆ†æç»“æœæ‰‹åŠ¨å¡«å†™ï¼‰
"""
    st.download_button(
        label="ğŸ“¥ ä¸‹è½½æŠ¥å‘Šï¼ˆMarkdownï¼‰",
        data=report_content,
        file_name=f"SPSSåˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d%H%M')}.md",
        mime="text/markdown"
    )

else:
    st.info("ğŸ’¡ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSV/Excelæ–‡ä»¶ï¼Œæ”¯æŒå¤šæ–‡ä»¶åˆå¹¶åˆ†æ")

