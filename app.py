import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from scipy import stats
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
import warnings
import io
import re
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="æ˜“æ‡‚ç‰ˆç§‘ç ”æ•°æ®åˆ†æåŠ©æ‰‹",
    page_icon="ğŸ“Š",
    layout="wide"
)
st.title("ğŸ“Š æ˜“æ‡‚ç‰ˆç§‘ç ”æ•°æ®åˆ†æåŠ©æ‰‹")
st.markdown("**å…¨ç¨‹å¤§ç™½è¯è¯´æ˜+æ•°æ®å«ä¹‰æ˜ç¤º+ç»“æœé€šä¿—è§£è¯»**")
st.divider()

# ---------------------- ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ–‡ä»¶ï¼ˆæ˜ç¡®æ•°æ®åˆ—å«ä¹‰ï¼‰----------------------
st.subheader("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒCSV/Excelï¼Œå¯ä¼ å¤šä¸ªï¼‰")
st.write("ğŸ’¡ æ”¯æŒä½ æä¾›çš„æ‰€æœ‰èµ›é¢˜æ–‡ä»¶ï¼ˆå¦‚df_customer.csvã€df_order.csvç­‰ï¼‰ï¼Œä¸Šä¼ åè‡ªåŠ¨è¯†åˆ«åˆ—å«ä¹‰")
uploaded_files = st.file_uploader(
    "é€‰æ‹©è¦åˆ†æçš„æ–‡ä»¶ï¼ˆå¯å¤šé€‰ï¼‰", 
    type=["xlsx", "csv"],
    accept_multiple_files=True
)

if not uploaded_files:
    st.info("ğŸ“Œ ç¤ºä¾‹ï¼šä¸Šä¼ df_order.csvï¼ˆè®¢å•æ•°æ®ï¼‰ã€df_proc.csvï¼ˆä»“åº“æˆæœ¬æ•°æ®ï¼‰ç­‰ï¼Œä¸Šä¼ åä¼šè‡ªåŠ¨è¯´æ˜æ¯åˆ—æ˜¯å•¥æ„æ€")
    st.stop()

# é¢„è®¾èµ›é¢˜æ–‡ä»¶åˆ—å«ä¹‰ï¼ˆè‡ªåŠ¨åŒ¹é…è¯´æ˜ï¼‰
COL_MEANING = {
    "Name": "åç§°ï¼ˆé—¨åº—/ä»“åº“/è®¾æ–½åï¼Œæ¯”å¦‚an-shan-shiæ˜¯éå±±é—¨åº—ï¼‰",
    "Type": "ç±»å‹ï¼ˆé—¨åº—=Customer/ä»“åº“=CDC/RDC/å•†å“=dm/imï¼‰",
    "Location": "åŸå¸‚ï¼ˆæ¯”å¦‚he-zeæ˜¯èæ³½ï¼Œji-ningæ˜¯æµå®ï¼‰",
    "ä¸­æ–‡åç§°": "åŸå¸‚ä¸­æ–‡åç§°ï¼ˆæ¯”å¦‚èæ³½ã€æµå®ï¼‰",
    "qty": "è®¢å•éœ€æ±‚é‡ï¼ˆå•ä½ï¼šå¨ï¼Œæ¯”å¦‚37.6å°±æ˜¯37.6å¨æµ·é²œï¼‰",
    "SKU": "å•†å“ç±»å‹ï¼ˆdm=å›½äº§æµ·é²œï¼Œim=è¿›å£æµ·é²œï¼‰",
    "Capacity": "ä»“åº“æœ€å¤§å¤„ç†é‡ï¼ˆå•ä½ï¼šå¨ï¼Œæ¯”å¦‚3000å°±æ˜¯æœ€å¤šå¤„ç†3000å¨ï¼‰",
    "Processing_fee": "å¤„ç½®æˆæœ¬ï¼ˆå•ä½ï¼šä¸‡å…ƒ/å¨ï¼Œæ¯”å¦‚0.007å°±æ˜¯æ¯å¨æˆæœ¬70å…ƒï¼‰",
    "Opening_fee": "å¼€ä»“æˆæœ¬ï¼ˆå•ä½ï¼šä¸‡å…ƒï¼Œæ¯”å¦‚25å°±æ˜¯å»ºä»“åº“è¦èŠ±25ä¸‡å…ƒï¼‰",
    "Distance": "è¿è¾“è·ç¦»ï¼ˆå•ä½ï¼šå…¬é‡Œï¼Œæ¯”å¦‚2506å°±æ˜¯2506å…¬é‡Œï¼‰",
    "Duration": "è¿è¾“æ—¶é—´ï¼ˆå•ä½ï¼šåˆ†é’Ÿï¼Œæ¯”å¦‚1639å°±æ˜¯çº¦27å°æ—¶ï¼‰",
    "Longitude": "ç»åº¦ï¼ˆåŸå¸‚åœ°ç†åæ ‡ï¼‰",
    "Latitude": "çº¬åº¦ï¼ˆåŸå¸‚åœ°ç†åæ ‡ï¼‰",
    "city_area": "åŸå¸‚æ€»é¢ç§¯ï¼ˆå•ä½ï¼šå¹³æ–¹å…¬é‡Œï¼‰",
    "resident_pop": "åŸå¸‚äººå£ï¼ˆå•ä½ï¼šä¸‡äººï¼‰",
    "gdp": "åŸå¸‚GDPï¼ˆå•ä½ï¼šäº¿å…ƒï¼‰"
}

# è¯»å–æ–‡ä»¶+è‡ªåŠ¨è¯´æ˜åˆ—å«ä¹‰
df_list = []
file_names = []
encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312', 'big5', 'utf-16', 'gb18030', 'latin-1']
seps = [',', '\t', ';', '|', ' ', ':', '\s+']

def clean_column_names(df):
    df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
    df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
    return df

for file in uploaded_files:
    try:
        file_content = file.read()
        if len(file_content) == 0:
            st.warning(f"âš ï¸ {file.name} æ˜¯ç©ºæ–‡ä»¶ï¼Œè·³è¿‡")
            continue
        file.seek(0)
        df = None
        file_name = file.name
        
        # CSVè¯»å–
        if file_name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        if encoding in ['utf-16']:
                            content = file_content.decode(encoding, errors='replace')
                            df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip')
                        else:
                            df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        df = clean_column_names(df)
                        break
                    except:
                        continue
                if df is not None:
                    break
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
                df = clean_column_names(df)
        # Excelè¯»å–
        else:
            df = pd.read_excel(file, engine='openpyxl')
            df = clean_column_names(df)
        
        if df is not None and len(df) > 0:
            df_list.append(df)
            file_names.append(file_name)
            # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯+åˆ—å«ä¹‰è¯´æ˜
            st.success(f"âœ… æˆåŠŸè¯»å–ï¼š{file_name}ï¼ˆ{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—ï¼‰")
            st.write(f"ğŸ“‹ è¯¥æ–‡ä»¶åˆ—å«ä¹‰ï¼š")
            for col in df.columns[:5]:  # æ˜¾ç¤ºå‰5åˆ—ï¼Œé¿å…è¿‡é•¿
                meaning = COL_MEANING.get(col, f"å…¶ä»–æ•°æ®åˆ—ï¼ˆ{col}ï¼‰")
                st.write(f"- {col}ï¼š{meaning}")
            if len(df.columns) > 5:
                st.write(f"- è¿˜æœ‰{len(df.columns)-5}åˆ—ï¼Œåç»­æ­¥éª¤ä¼šè¯¦ç»†è¯´æ˜")
        else:
            st.warning(f"âš ï¸ {file_name} æ— æœ‰æ•ˆæ•°æ®ï¼Œè·³è¿‡")
    except Exception as e:
        st.error(f"âŒ è¯»å–{file_name}å¤±è´¥ï¼š{str(e)}")

if not df_list:
    st.error("âŒ æ²¡æœ‰å¯åˆ†æçš„æœ‰æ•ˆæ–‡ä»¶ï¼Œè¯·æ£€æŸ¥æ–‡ä»¶å†…å®¹")
    st.stop()

# ---------------------- ç¬¬äºŒæ­¥ï¼šé€‰æ‹©è¦åˆ†æçš„æ–‡ä»¶ï¼ˆæ˜ç¡®é€‰æ‹©é€»è¾‘ï¼‰----------------------
st.subheader("ç¬¬äºŒæ­¥ï¼šé€‰æ‹©æœ¬æ¬¡è¦åˆ†æçš„æ–‡ä»¶")
st.write("ğŸ’¡ ä¸Šä¼ äº†å¤šä¸ªæ–‡ä»¶ï¼Ÿåªé€‰éœ€è¦çš„ï¼Œæ¯”å¦‚æƒ³åˆ†æè®¢å•é‡å°±é€‰df_order.csv")
selected_file_idxs = st.multiselect(
    "å‹¾é€‰è¦å‚ä¸åˆ†æçš„æ–‡ä»¶",
    range(len(file_names)),
    default=[0],
    format_func=lambda x: file_names[x]
)

if len(selected_file_idxs) == 0:
    st.error("âŒ è‡³å°‘é€‰1ä¸ªæ–‡ä»¶")
    st.stop()

selected_dfs = [df_list[i] for i in selected_file_idxs]
selected_file_names = [file_names[i] for i in selected_file_idxs]

# ---------------------- ç¬¬ä¸‰æ­¥ï¼šé€‰æ‹©åˆ†ææ¨¡å¼ï¼ˆé€šä¿—è¯´æ˜ï¼‰----------------------
st.subheader("ç¬¬ä¸‰æ­¥ï¼šé€‰æ‹©åˆ†ææ–¹å¼")
if len(selected_file_idxs) == 1:
    analysis_mode = "å•æ–‡ä»¶åˆ†æ"
    st.write(f"ğŸ“Œ è‡ªåŠ¨é€‰å•æ–‡ä»¶åˆ†æï¼š{selected_file_names[0]}ï¼ˆåªæœ‰1ä¸ªæ–‡ä»¶å¯é€‰ï¼‰")
    df = selected_dfs[0]
else:
    analysis_mode = st.radio(
        "é€‰å¤šä¸ªæ–‡ä»¶äº†ï¼Œæƒ³æ€ä¹ˆåˆ†æï¼Ÿ",
        options=["å•æ–‡ä»¶åˆ†æï¼ˆåªåˆ†æå…¶ä¸­1ä¸ªï¼‰", "å¤šæ–‡ä»¶å…³è”åˆ†æï¼ˆæ¯”å¦‚è®¢å•æ•°æ®+ä»“åº“æ•°æ®åˆå¹¶åˆ†æï¼‰"]
    )

    if analysis_mode == "å•æ–‡ä»¶åˆ†æï¼ˆåªåˆ†æå…¶ä¸­1ä¸ªï¼‰":
        selected_idx = st.selectbox(
            "é€‰1ä¸ªè¦æ·±å…¥åˆ†æçš„æ–‡ä»¶",
            range(len(selected_file_names)),
            format_func=lambda x: selected_file_names[x]
        )
        df = selected_dfs[selected_idx]
        st.success(f"âœ… å·²é€‰ï¼š{selected_file_names[selected_idx]}")
    
    else:
        st.write("ğŸ“Œ å¤šæ–‡ä»¶å…³è”ï¼šæŠŠå¤šä¸ªæ–‡ä»¶æŒ‰å…±åŒå­—æ®µåˆå¹¶ï¼ˆæ¯”å¦‚æŒ‰ã€ŒåŸå¸‚ã€åˆå¹¶è®¢å•å’Œä»“åº“æ•°æ®ï¼‰")
        base_idx = st.selectbox(
            "é€‰1ä¸ªåŸºç¡€æ–‡ä»¶ï¼ˆæ¯”å¦‚è®¢å•æ•°æ®ï¼‰",
            range(len(selected_file_names)),
            format_func=lambda x: selected_file_names[x]
        )
        df = selected_dfs[base_idx]
        base_name = selected_file_names[base_idx]
        remaining_idxs = [i for i in range(len(selected_file_names)) if i != base_idx]
        å…³è”è®¡æ•°å™¨ = 0

        while len(remaining_idxs) > 0:
            å…³è”è®¡æ•°å™¨ += 1
            remaining_dfs = [selected_dfs[i] for i in remaining_idxs]
            remaining_names = [selected_file_names[i] for i in remaining_idxs]

            st.markdown(f"#### åˆå¹¶ç¬¬{å…³è”è®¡æ•°å™¨}ä¸ªæ–‡ä»¶")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                join_select_idx = st.selectbox(
                    f"è¦åˆå¹¶å“ªä¸ªæ–‡ä»¶ï¼Ÿ",
                    range(len(remaining_idxs)),
                    format_func=lambda x: remaining_names[x],
                    key=f"join_file_{å…³è”è®¡æ•°å™¨}"
                )
                join_idx = remaining_idxs[join_select_idx]
                join_df = remaining_dfs[join_select_idx]
                join_name = remaining_names[join_select_idx]
            
            with col2:
                base_key = st.selectbox(
                    f"åŸºç¡€æ–‡ä»¶ç”¨å“ªä¸ªå­—æ®µåˆå¹¶ï¼Ÿï¼ˆæ¯”å¦‚æŒ‰åŸå¸‚åˆå¹¶å°±é€‰Locationï¼‰",
                    df.columns.tolist(),
                    key=f"base_key_{å…³è”è®¡æ•°å™¨}"
                )
                st.write(f"â„¹ï¸ è¯¥å­—æ®µå«ä¹‰ï¼š{COL_MEANING.get(base_key, 'ç”¨äºåˆå¹¶çš„å…±åŒå­—æ®µ')}")
            
            with col3:
                join_key = st.selectbox(
                    f"è¦åˆå¹¶çš„æ–‡ä»¶ç”¨å“ªä¸ªå­—æ®µå¯¹åº”ï¼Ÿï¼ˆè¦å’Œå·¦è¾¹å­—æ®µå«ä¹‰ä¸€è‡´ï¼‰",
                    join_df.columns.tolist(),
                    key=f"join_key_{å…³è”è®¡æ•°å™¨}"
                )
                st.write(f"â„¹ï¸ è¯¥å­—æ®µå«ä¹‰ï¼š{COL_MEANING.get(join_key, 'ç”¨äºåˆå¹¶çš„å…±åŒå­—æ®µ')}")
            
            join_type = st.radio(
                f"åˆå¹¶æ–¹å¼ï¼Ÿ",
                options=["åªä¿ç•™ä¸¤è¾¹éƒ½æœ‰çš„æ•°æ®ï¼ˆæ¨èï¼‰", "ä¿ç•™åŸºç¡€æ–‡ä»¶æ‰€æœ‰æ•°æ®"],
                key=f"join_type_{å…³è”è®¡æ•°å™¨}"
            )
            join_map = {"åªä¿ç•™ä¸¤è¾¹éƒ½æœ‰çš„æ•°æ®ï¼ˆæ¨èï¼‰": "inner", "ä¿ç•™åŸºç¡€æ–‡ä»¶æ‰€æœ‰æ•°æ®": "left"}

            if base_key not in df.columns or join_key not in join_df.columns:
                st.error("âŒ é€‰çš„å­—æ®µåœ¨æ–‡ä»¶é‡Œæ²¡æœ‰ï¼Œè¯·é‡æ–°é€‰")
                st.stop()

            # é‡å‘½åå†²çªå­—æ®µ
            join_suffix = f"_{join_name.split('.')[0]}"
            join_df_renamed = join_df.rename(
                columns={col: f"{col}{join_suffix}" for col in join_df.columns if col != join_key and col in df.columns}
            )

            try:
                df = pd.merge(df, join_df_renamed, left_on=base_key, right_on=join_key, how=join_map[join_type])
                st.success(f"âœ… åˆå¹¶å®Œæˆï¼ç°åœ¨æ•°æ®æœ‰{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            except Exception as e:
                st.error(f"âŒ åˆå¹¶å¤±è´¥ï¼š{str(e)}")
                st.stop()

            remaining_idxs.pop(join_select_idx)

# ---------------------- ç¬¬å››æ­¥ï¼šå˜é‡è¯†åˆ«ï¼ˆæ˜ç¡®æ¯åˆ—å«ä¹‰ï¼‰----------------------
st.subheader("ç¬¬å››æ­¥ï¼šæ•°æ®å˜é‡è¯´æ˜ï¼ˆè¿™äº›æ•°æ®èƒ½åˆ†æå•¥ï¼‰")
numeric_cols = []  # æ•°å€¼å‹ï¼ˆèƒ½ç®—è´¦çš„ï¼Œæ¯”å¦‚è®¢å•é‡ã€æˆæœ¬ï¼‰
categorical_cols = []  # åˆ†ç±»å‹ï¼ˆèƒ½åˆ†ç»„çš„ï¼Œæ¯”å¦‚å•†å“ç±»å‹ã€åŸå¸‚ï¼‰
binary_categorical_cols = []  # äºŒåˆ†ç±»ï¼ˆåªæœ‰2ç§é€‰é¡¹çš„ï¼Œæ¯”å¦‚å›½äº§/è¿›å£ï¼‰

for col in df.columns:
    try:
        df[col] = pd.to_numeric(df[col], errors='raise')
        numeric_cols.append(col)
    except:
        categorical_cols.append(col)
        if df[col].nunique() == 2:
            binary_categorical_cols.append(col)

# é€šä¿—å±•ç¤ºå˜é‡
st.write("ğŸ“ˆ èƒ½ç®—è´¦çš„æ•°å€¼å‹æ•°æ®ï¼ˆæ¯”å¦‚è®¢å•é‡ã€æˆæœ¬ã€è·ç¦»ï¼‰ï¼š")
for col in numeric_cols:
    meaning = COL_MEANING.get(col, f"æ•°å€¼æ•°æ®ï¼ˆ{col}ï¼‰")
    st.write(f"- {col}ï¼š{meaning}")

st.write("ğŸ·ï¸ èƒ½åˆ†ç»„çš„åˆ†ç±»å‹æ•°æ®ï¼ˆæ¯”å¦‚å•†å“ç±»å‹ã€åŸå¸‚ï¼‰ï¼š")
for col in categorical_cols:
    meaning = COL_MEANING.get(col, f"åˆ†ç±»æ•°æ®ï¼ˆ{col}ï¼‰")
    unique_vals = df[col].unique()[:3]  # æ˜¾ç¤ºå‰3ä¸ªé€‰é¡¹
    st.write(f"- {col}ï¼š{meaning}ï¼ˆé€‰é¡¹ï¼š{', '.join(map(str, unique_vals))}{'...' if len(df[col].unique())>3 else ''}ï¼‰")

if not numeric_cols:
    st.error("âŒ æ²¡æœ‰èƒ½ç®—è´¦çš„æ•°æ®ï¼ˆæ¯”å¦‚è®¢å•é‡ã€æˆæœ¬ï¼‰ï¼Œæ— æ³•åˆ†æ")
    st.stop()

# ---------------------- ç¬¬äº”æ­¥ï¼šæ¨èåˆ†æç±»å‹ï¼ˆé€šä¿—åŒ–ï¼‰----------------------
st.subheader("ç¬¬äº”æ­¥ï¼šé€‰æ‹©è¦åšçš„åˆ†æï¼ˆçœ‹å¤§ç™½è¯é€‰ï¼‰")
st.write("ğŸ’¡ ç³»ç»Ÿè‡ªåŠ¨åˆ¤æ–­èƒ½åšå•¥åˆ†æï¼Œä¸èƒ½åšçš„ä¼šè¯´æ˜åŸå› ")

def get_supported_analyses():
    supported = []
    reasons = {}

    # 1. æè¿°æ€§ç»Ÿè®¡ï¼ˆçœ‹æ•°æ®åˆ†å¸ƒã€å¹³å‡æ°´å¹³ï¼‰
    supported.append("1. çœ‹æ•°æ®æ¦‚å†µï¼ˆæ¯”å¦‚è®¢å•é‡å¹³å‡å¤šå°‘ã€æˆæœ¬æœ€é«˜å¤šå°‘ï¼‰")
    reasons["1. çœ‹æ•°æ®æ¦‚å†µï¼ˆæ¯”å¦‚è®¢å•é‡å¹³å‡å¤šå°‘ã€æˆæœ¬æœ€é«˜å¤šå°‘ï¼‰"] = "âœ… æœ‰èƒ½ç®—è´¦çš„æ•°æ®ï¼Œæ”¯æŒçœ‹å¹³å‡å€¼ã€åˆ†å¸ƒ"

    # 2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼ˆæ¯”å¦‚å›½äº§å’Œè¿›å£æµ·é²œçš„è®¢å•é‡è°å¤šï¼‰
    t_test_support = len(categorical_cols) >= 1 and len(numeric_cols) >= 1
    if t_test_support:
        multi_group_cats = [col for col in categorical_cols if df[col].nunique() >= 2]
        if len(multi_group_cats) == 0:
            t_test_support = False
            reasons["2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼ˆæ¯”å¦‚å›½äº§å’Œè¿›å£æµ·é²œçš„è®¢å•é‡è°å¤šï¼‰"] = "âŒ æ²¡æœ‰èƒ½åˆ†ç»„çš„å­—æ®µï¼ˆæ¯”å¦‚å•†å“ç±»å‹ã€åŸå¸‚ï¼‰ï¼Œæ²¡æ³•å¯¹æ¯”"
        else:
            reasons["2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼ˆæ¯”å¦‚å›½äº§å’Œè¿›å£æµ·é²œçš„è®¢å•é‡è°å¤šï¼‰"] = "âœ… èƒ½åˆ†ç»„ä¹Ÿèƒ½ç®—è´¦ï¼Œæ”¯æŒå¯¹æ¯”å·®å¼‚"
    else:
        reasons["2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼ˆæ¯”å¦‚å›½äº§å’Œè¿›å£æµ·é²œçš„è®¢å•é‡è°å¤šï¼‰"] = "âŒ ç¼ºå°‘åˆ†ç»„å­—æ®µæˆ–ç®—è´¦æ•°æ®"
    
    if t_test_support:
        supported.append("2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼ˆæ¯”å¦‚å›½äº§å’Œè¿›å£æµ·é²œçš„è®¢å•é‡è°å¤šï¼‰")

    # 3. å¤šå› ç´ å½±å“åˆ†æï¼ˆæ¯”å¦‚å•†å“ç±»å‹+åŸå¸‚å¯¹è®¢å•é‡çš„å…±åŒå½±å“ï¼‰
    anova_support = len(categorical_cols) >= 1 and len(numeric_cols) >= 1
    if anova_support:
        reasons["3. å¤šå› ç´ å½±å“åˆ†æï¼ˆæ¯”å¦‚å•†å“ç±»å‹+åŸå¸‚å¯¹è®¢å•é‡çš„å…±åŒå½±å“ï¼‰"] = "âœ… æ”¯æŒçœ‹å¤šä¸ªæ¡ä»¶å¯¹ç»“æœçš„å½±å“"
        supported.append("3. å¤šå› ç´ å½±å“åˆ†æï¼ˆæ¯”å¦‚å•†å“ç±»å‹+åŸå¸‚å¯¹è®¢å•é‡çš„å…±åŒå½±å“ï¼‰")
    else:
        reasons["3. å¤šå› ç´ å½±å“åˆ†æï¼ˆæ¯”å¦‚å•†å“ç±»å‹+åŸå¸‚å¯¹è®¢å•é‡çš„å…±åŒå½±å“ï¼‰"] = "âŒ ç¼ºå°‘åˆ†ç»„å­—æ®µæˆ–ç®—è´¦æ•°æ®"

    # 4. å˜é‡å…³ç³»åˆ†æï¼ˆæ¯”å¦‚è®¢å•é‡è¶Šå¤šï¼Œæˆæœ¬æ˜¯ä¸æ˜¯è¶Šé«˜ï¼‰
    regression_support = len(numeric_cols) >= 2
    if regression_support:
        reasons["4. å˜é‡å…³ç³»åˆ†æï¼ˆæ¯”å¦‚è®¢å•é‡è¶Šå¤šï¼Œæˆæœ¬æ˜¯ä¸æ˜¯è¶Šé«˜ï¼‰"] = "âœ… æœ‰å¤šä¸ªç®—è´¦æ•°æ®ï¼Œæ”¯æŒçœ‹å…³ç³»"
        supported.append("4. å˜é‡å…³ç³»åˆ†æï¼ˆæ¯”å¦‚è®¢å•é‡è¶Šå¤šï¼Œæˆæœ¬æ˜¯ä¸æ˜¯è¶Šé«˜ï¼‰")
    else:
        reasons["4. å˜é‡å…³ç³»åˆ†æï¼ˆæ¯”å¦‚è®¢å•é‡è¶Šå¤šï¼Œæˆæœ¬æ˜¯ä¸æ˜¯è¶Šé«˜ï¼‰"] = "âŒ è‡³å°‘éœ€è¦2ä¸ªç®—è´¦æ•°æ®ï¼ˆæ¯”å¦‚è®¢å•é‡+æˆæœ¬ï¼‰"

    # 5. åˆ†ç±»é¢„æµ‹ï¼ˆæ¯”å¦‚æ ¹æ®åŸå¸‚å’Œäººå£ï¼Œé¢„æµ‹æ˜¯å›½äº§è¿˜æ˜¯è¿›å£æµ·é²œï¼‰
    logistic_support = len(binary_categorical_cols) >= 1 and len(numeric_cols) >= 1
    if logistic_support:
        reasons["5. åˆ†ç±»é¢„æµ‹ï¼ˆæ¯”å¦‚æ ¹æ®åŸå¸‚å’Œäººå£ï¼Œé¢„æµ‹æ˜¯å›½äº§è¿˜æ˜¯è¿›å£æµ·é²œï¼‰"] = "âœ… æœ‰äºŒåˆ†ç±»æ•°æ®ï¼ˆæ¯”å¦‚å›½äº§/è¿›å£ï¼‰å’Œç®—è´¦æ•°æ®ï¼Œæ”¯æŒé¢„æµ‹"
        supported.append("5. åˆ†ç±»é¢„æµ‹ï¼ˆæ¯”å¦‚æ ¹æ®åŸå¸‚å’Œäººå£ï¼Œé¢„æµ‹æ˜¯å›½äº§è¿˜æ˜¯è¿›å£æµ·é²œï¼‰")
    else:
        reasons["5. åˆ†ç±»é¢„æµ‹ï¼ˆæ¯”å¦‚æ ¹æ®åŸå¸‚å’Œäººå£ï¼Œé¢„æµ‹æ˜¯å›½äº§è¿˜æ˜¯è¿›å£æµ·é²œï¼‰"] = "âŒ ç¼ºå°‘äºŒåˆ†ç±»æ•°æ®ï¼ˆæ¯”å¦‚åªæœ‰1ç§å•†å“ç±»å‹ï¼‰æˆ–ç®—è´¦æ•°æ®"

    # 6. æ•°æ®åˆ†ç¾¤ï¼ˆæ¯”å¦‚æŠŠåŸå¸‚æŒ‰è®¢å•é‡åˆ†æˆé«˜ã€ä¸­ã€ä½ä¸‰ç»„ï¼‰
    kmeans_support = len(numeric_cols) >= 2
    if kmeans_support:
        reasons["6. æ•°æ®åˆ†ç¾¤ï¼ˆæ¯”å¦‚æŠŠåŸå¸‚æŒ‰è®¢å•é‡åˆ†æˆé«˜ã€ä¸­ã€ä½ä¸‰ç»„ï¼‰"] = "âœ… æœ‰å¤šä¸ªç®—è´¦æ•°æ®ï¼Œæ”¯æŒåˆ†ç»„"
        supported.append("6. æ•°æ®åˆ†ç¾¤ï¼ˆæ¯”å¦‚æŠŠåŸå¸‚æŒ‰è®¢å•é‡åˆ†æˆé«˜ã€ä¸­ã€ä½ä¸‰ç»„ï¼‰")
    else:
        reasons["6. æ•°æ®åˆ†ç¾¤ï¼ˆæ¯”å¦‚æŠŠåŸå¸‚æŒ‰è®¢å•é‡åˆ†æˆé«˜ã€ä¸­ã€ä½ä¸‰ç»„ï¼‰"] = "âŒ è‡³å°‘éœ€è¦2ä¸ªç®—è´¦æ•°æ®ï¼ˆæ¯”å¦‚è®¢å•é‡+äººå£ï¼‰"

    return supported, reasons

supported_analyses, analysis_reasons = get_supported_analyses()

# æ˜¾ç¤ºä¸æ”¯æŒçš„åŸå› 
st.write("âŒ æš‚æ—¶ä¸èƒ½åšçš„åˆ†æåŠåŸå› ï¼š")
for analysis in [
    "1. çœ‹æ•°æ®æ¦‚å†µï¼ˆæ¯”å¦‚è®¢å•é‡å¹³å‡å¤šå°‘ã€æˆæœ¬æœ€é«˜å¤šå°‘ï¼‰",
    "2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼ˆæ¯”å¦‚å›½äº§å’Œè¿›å£æµ·é²œçš„è®¢å•é‡è°å¤šï¼‰",
    "3. å¤šå› ç´ å½±å“åˆ†æï¼ˆæ¯”å¦‚å•†å“ç±»å‹+åŸå¸‚å¯¹è®¢å•é‡çš„å…±åŒå½±å“ï¼‰",
    "4. å˜é‡å…³ç³»åˆ†æï¼ˆæ¯”å¦‚è®¢å•é‡è¶Šå¤šï¼Œæˆæœ¬æ˜¯ä¸æ˜¯è¶Šé«˜ï¼‰",
    "5. åˆ†ç±»é¢„æµ‹ï¼ˆæ¯”å¦‚æ ¹æ®åŸå¸‚å’Œäººå£ï¼Œé¢„æµ‹æ˜¯å›½äº§è¿˜æ˜¯è¿›å£æµ·é²œï¼‰",
    "6. æ•°æ®åˆ†ç¾¤ï¼ˆæ¯”å¦‚æŠŠåŸå¸‚æŒ‰è®¢å•é‡åˆ†æˆé«˜ã€ä¸­ã€ä½ä¸‰ç»„ï¼‰"
]:
    if analysis not in supported_analyses:
        st.write(f"- {analysis_reasons[analysis]}")

if not supported_analyses:
    st.error("âŒ æ²¡æœ‰èƒ½åšçš„åˆ†æï¼Œè¯·æ£€æŸ¥æ•°æ®")
    st.stop()

analysis_type = st.radio(
    "é€‰æ‹©è¦åšçš„åˆ†æï¼ˆé€‰ä¸€ä¸ªä½ å…³å¿ƒçš„ï¼‰",
    options=supported_analyses
)

# æ˜ å°„åˆ†æç±»å‹
type_map = {
    "1. çœ‹æ•°æ®æ¦‚å†µï¼ˆæ¯”å¦‚è®¢å•é‡å¹³å‡å¤šå°‘ã€æˆæœ¬æœ€é«˜å¤šå°‘ï¼‰": "descriptive",
    "2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼ˆæ¯”å¦‚å›½äº§å’Œè¿›å£æµ·é²œçš„è®¢å•é‡è°å¤šï¼‰": "t_test",
    "3. å¤šå› ç´ å½±å“åˆ†æï¼ˆæ¯”å¦‚å•†å“ç±»å‹+åŸå¸‚å¯¹è®¢å•é‡çš„å…±åŒå½±å“ï¼‰": "anova",
    "4. å˜é‡å…³ç³»åˆ†æï¼ˆæ¯”å¦‚è®¢å•é‡è¶Šå¤šï¼Œæˆæœ¬æ˜¯ä¸æ˜¯è¶Šé«˜ï¼‰": "regression",
    "5. åˆ†ç±»é¢„æµ‹ï¼ˆæ¯”å¦‚æ ¹æ®åŸå¸‚å’Œäººå£ï¼Œé¢„æµ‹æ˜¯å›½äº§è¿˜æ˜¯è¿›å£æµ·é²œï¼‰": "logistic_reg",
    "6. æ•°æ®åˆ†ç¾¤ï¼ˆæ¯”å¦‚æŠŠåŸå¸‚æŒ‰è®¢å•é‡åˆ†æˆé«˜ã€ä¸­ã€ä½ä¸‰ç»„ï¼‰": "kmeans"
}
target_analysis = type_map[analysis_type]

# ---------------------- ç¬¬å…­æ­¥ï¼šé…ç½®å‚æ•°ï¼ˆé€šä¿—è¯´æ˜ï¼‰----------------------
st.subheader("ç¬¬å…­æ­¥ï¼šè®¾ç½®åˆ†æç»†èŠ‚ï¼ˆè·Ÿç€æç¤ºé€‰å°±è¡Œï¼‰")
params = {}
st.markdown("### ğŸ¨ å›¾è¡¨æ ·å¼ï¼ˆå¯é€‰ï¼Œé»˜è®¤å°±è¡Œï¼‰")
params["chart_color"] = st.color_picker("å›¾è¡¨é¢œè‰²", value="#1f77b4")
params["chart_width"] = st.slider("å›¾è¡¨å®½åº¦", 600, 1200, 800)
params["chart_height"] = st.slider("å›¾è¡¨é«˜åº¦", 400, 800, 500)

# æŒ‰åˆ†æç±»å‹é…ç½®å‚æ•°ï¼ˆé€šä¿—åŒ–é€‰é¡¹ï¼‰
if target_analysis == "kmeans":
    params["n_clusters"] = st.slider("åˆ†å‡ ç»„ï¼Ÿï¼ˆæ¯”å¦‚é«˜ã€ä¸­ã€ä½å°±é€‰3ï¼‰", 2, 10, 3)

elif target_analysis == "descriptive":
    params["target_col"] = st.selectbox(
        "æƒ³çœ‹å“ªä¸ªæ•°æ®çš„æ¦‚å†µï¼Ÿï¼ˆæ¯”å¦‚è®¢å•é‡qtyï¼‰",
        numeric_cols,
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'æ•°å€¼æ•°æ®')}ï¼‰"
    )
    params["chart_type"] = st.radio("æƒ³çœ‹åˆ†å¸ƒï¼ˆæ¯”å¦‚è®¢å•é‡é›†ä¸­åœ¨å“ªä¸ªåŒºé—´ï¼‰è¿˜æ˜¯å‡å€¼ï¼ˆæ¯”å¦‚å¹³å‡è®¢å•é‡ï¼‰ï¼Ÿ", ["ç›´æ–¹å›¾ï¼ˆçœ‹åˆ†å¸ƒï¼‰", "æŸ±çŠ¶å›¾ï¼ˆçœ‹å‡å€¼ï¼‰"])

elif target_analysis == "t_test":
    valid_group_cols = [col for col in categorical_cols if df[col].nunique() >= 2]
    params["group_col"] = st.selectbox(
        "æŒ‰ä»€ä¹ˆåˆ†ç»„å¯¹æ¯”ï¼Ÿï¼ˆæ¯”å¦‚å•†å“ç±»å‹SKUï¼‰",
        valid_group_cols,
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'åˆ†ç±»æ•°æ®')}ï¼‰"
    )
    params["result_col"] = st.selectbox(
        "å¯¹æ¯”å“ªä¸ªæ•°æ®ï¼Ÿï¼ˆæ¯”å¦‚è®¢å•é‡qtyï¼‰",
        numeric_cols,
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'æ•°å€¼æ•°æ®')}ï¼‰"
    )
    group_counts = df[params["group_col"]].nunique()
    if group_counts != 2:
        st.warning(f"âš ï¸ è¿™ä¸ªåˆ†ç»„æœ‰{group_counts}ä¸ªé€‰é¡¹ï¼Œç³»ç»Ÿè‡ªåŠ¨é€‰æ ·æœ¬æœ€å¤šçš„2ä¸ªæ¥å¯¹æ¯”")
        top2_groups = df[params["group_col"]].value_counts().nlargest(2).index.tolist()
        df = df[df[params["group_col"]].isin(top2_groups)]

elif target_analysis == "anova":
    params["factor_cols"] = st.multiselect(
        "å“ªäº›æ¡ä»¶ä¼šå½±å“ç»“æœï¼Ÿï¼ˆæ¯”å¦‚å•†å“ç±»å‹+åŸå¸‚ï¼‰",
        categorical_cols,
        default=categorical_cols[0],
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'åˆ†ç±»æ•°æ®')}ï¼‰"
    )
    params["result_col"] = st.selectbox(
        "å…³æ³¨å“ªä¸ªç»“æœï¼Ÿï¼ˆæ¯”å¦‚è®¢å•é‡qtyï¼‰",
        numeric_cols,
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'æ•°å€¼æ•°æ®')}ï¼‰"
    )
    params["formula"] = f"{params['result_col']} ~ {' + '.join(params['factor_cols'])}"

elif target_analysis == "regression":
    params["x_col"] = st.selectbox(
        "å“ªä¸ªæ•°æ®æ˜¯åŸå› ï¼Ÿï¼ˆæ¯”å¦‚è®¢å•é‡ï¼‰",
        numeric_cols,
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'æ•°å€¼æ•°æ®')}ï¼‰"
    )
    params["y_col"] = st.selectbox(
        "å“ªä¸ªæ•°æ®æ˜¯ç»“æœï¼Ÿï¼ˆæ¯”å¦‚æˆæœ¬ï¼‰",
        [col for col in numeric_cols if col != params["x_col"]],
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'æ•°å€¼æ•°æ®')}ï¼‰"
    )

elif target_analysis == "logistic_reg":
    params["target_col"] = st.selectbox(
        "è¦é¢„æµ‹ä»€ä¹ˆï¼Ÿï¼ˆæ¯”å¦‚å•†å“ç±»å‹æ˜¯å›½äº§è¿˜æ˜¯è¿›å£ï¼‰",
        binary_categorical_cols,
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'äºŒåˆ†ç±»æ•°æ®')}ï¼‰"
    )
    params["feature_cols"] = st.multiselect(
        "æ ¹æ®å“ªäº›æ•°æ®é¢„æµ‹ï¼Ÿï¼ˆæ¯”å¦‚åŸå¸‚äººå£+GDPï¼‰",
        numeric_cols,
        default=numeric_cols[:2],
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'æ•°å€¼æ•°æ®')}ï¼‰"
    )
    df[params["target_col"] + "_encoded"] = LabelEncoder().fit_transform(df[params["target_col"]])

elif target_analysis == "kmeans":
    params["feature_cols"] = st.multiselect(
        "æ ¹æ®å“ªäº›æ•°æ®åˆ†ç¾¤ï¼Ÿï¼ˆæ¯”å¦‚è®¢å•é‡+äººå£ï¼‰",
        numeric_cols,
        default=numeric_cols[:2],
        format_func=lambda x: f"{x}ï¼ˆ{COL_MEANING.get(x, 'æ•°å€¼æ•°æ®')}ï¼‰"
    )
    df_cluster = df[params["feature_cols"]].dropna()
    if len(df_cluster) < params["n_clusters"]:
        st.error(f"âŒ æœ‰æ•ˆæ•°æ®åªæœ‰{len(df_cluster)}æ¡ï¼Œåˆ†ä¸äº†{params['n_clusters']}ç»„ï¼Œè¯·å‡å°‘åˆ†ç»„æ•°")
        st.stop()

# ---------------------- ç¬¬ä¸ƒæ­¥ï¼šæ‰§è¡Œåˆ†æ+ç»“æœè§£è¯»----------------------
st.divider()
st.subheader("ç¬¬ä¸ƒæ­¥ï¼šåˆ†æç»“æœ+é€šä¿—è§£è¯»")

if st.button("ğŸš€ å¼€å§‹åˆ†æ"):
    try:
        with st.spinner("åˆ†æä¸­..."):
            report = ""
            interpretation = ""  # ç»“æœè§£è¯»
            # 1. æè¿°æ€§ç»Ÿè®¡
            if target_analysis == "descriptive":
                col = params["target_col"]
                stats_result = df[col].describe()
                st.subheader("ğŸ“Š æ•°æ®æ¦‚å†µç»“æœ")
                st.dataframe(stats_result.to_frame(), use_container_width=True)
                
                fig = px.histogram(df, x=col, title=f"{col}çš„{'åˆ†å¸ƒ' if params['chart_type']=='ç›´æ–¹å›¾ï¼ˆçœ‹åˆ†å¸ƒï¼‰' else 'å‡å€¼'}",
                                  color_discrete_sequence=[params["chart_color"]], width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                # é€šä¿—è§£è¯»
                mean_val = stats_result['mean']
                std_val = stats_result['std']
                min_val = stats_result['min']
                max_val = stats_result['max']
                interpretation = f"""
                ğŸ“ ç»“æœè§£è¯»ï¼š
                1. ã€Œ{col}ã€çš„å¹³å‡æ°´å¹³æ˜¯{mean_val:.2f}ï¼ˆ{COL_MEANING.get(col, 'å•ä½')}ï¼‰ï¼›
                2. æ•°æ®{'æ¯”è¾ƒé›†ä¸­' if std_val < mean_val*0.3 else 'æ¯”è¾ƒåˆ†æ•£'}ï¼Œå¤§éƒ¨åˆ†æ•°æ®åœ¨{mean_val-std_val:.2f}åˆ°{mean_val+std_val:.2f}ä¹‹é—´ï¼›
                3. æœ€å°æ˜¯{min_val:.2f}ï¼Œæœ€å¤§æ˜¯{max_val:.2f}ï¼Œå·®è·{'ä¸å¤§' if max_val-min_val < mean_val*1 else 'è¾ƒå¤§'}ï¼›
                4. æ¯”å¦‚å¦‚æœæ˜¯è®¢å•é‡ï¼Œè¯´æ˜å¹³å‡æ¯ä¸ªé—¨åº—è¦{mean_val:.2f}å¨ï¼Œæœ€å¤šçš„è¦{max_val:.2f}å¨ï¼Œæœ€å°‘çš„åªè¦{min_val:.2f}å¨ã€‚
                """

            # 2. ä¸¤ç»„å·®å¼‚å¯¹æ¯”
            elif target_analysis == "t_test":
                group_col, result_col = params["group_col"], params["result_col"]
                group1, group2 = df[group_col].unique()[:2]
                data1, data2 = df[df[group_col]==group1][result_col].dropna(), df[df[group_col]==group2][result_col].dropna()
                t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=False)
                
                st.subheader("ğŸ” ä¸¤ç»„å·®å¼‚å¯¹æ¯”ç»“æœ")
                st.write(f"{group1}çš„{result_col}å‡å€¼ï¼š{data1.mean():.2f}ï¼ˆ{COL_MEANING.get(result_col, 'å•ä½')}ï¼‰")
                st.write(f"{group2}çš„{result_col}å‡å€¼ï¼š{data2.mean():.2f}ï¼ˆ{COL_MEANING.get(result_col, 'å•ä½')}ï¼‰")
                st.write(f"ç»Ÿè®¡æ˜¾è‘—æ€§på€¼ï¼š{p_value:.4f}ï¼ˆp<0.05è¯´æ˜å·®å¼‚çœŸçš„å­˜åœ¨ï¼Œä¸æ˜¯å·§åˆï¼‰")
                
                fig = px.box(df, x=group_col, y=result_col, color_discrete_sequence=[params["chart_color"]],
                           title=f"{group_col}å¯¹{result_col}çš„å½±å“", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                # é€šä¿—è§£è¯»
                diff_val = abs(data1.mean() - data2.mean())
                if p_value < 0.05:
                    diff_desc = "å­˜åœ¨æ˜¾è‘—å·®å¼‚"
                    reason = "è¯´æ˜è¿™ç§å·®å¼‚ä¸æ˜¯å¶ç„¶çš„ï¼Œæ˜¯ä¸¤ç»„æœ¬èº«çš„åŒºåˆ«"
                else:
                    diff_desc = "æ²¡æœ‰æ˜¾è‘—å·®å¼‚"
                    reason = "è¯´æ˜ä¸¤ç»„çš„åŒºåˆ«å¯èƒ½æ˜¯å¶ç„¶çš„ï¼Œæ²¡æœ‰æœ¬è´¨ä¸åŒ"
                interpretation = f"""
                ğŸ“ ç»“æœè§£è¯»ï¼š
                1. {group1}å’Œ{group2}åœ¨{result_col}ä¸Š{diff_desc}ï¼ˆp={p_value:.4f}ï¼‰ï¼›
                2. {group1}æ¯”{group2} {'é«˜' if data1.mean()>data2.mean() else 'ä½'} {diff_val:.2f}ï¼ˆ{COL_MEANING.get(result_col, 'å•ä½')}ï¼‰ï¼›
                3. {reason}ï¼›
                4. æ¯”å¦‚å¦‚æœæ˜¯å›½äº§ï¼ˆdmï¼‰å’Œè¿›å£ï¼ˆimï¼‰æµ·é²œçš„è®¢å•é‡å¯¹æ¯”ï¼Œè¯´æ˜è¿›å£æµ·é²œè®¢å•é‡ç¡®å®æ›´é«˜ï¼Œé—¨åº—æ›´å€¾å‘é‡‡è´­è¿›å£æµ·é²œã€‚
                """

            # 3. å¤šå› ç´ å½±å“åˆ†æ
            elif target_analysis == "anova":
                model = ols(params["formula"], data=df).fit()
                anova_result = anova_lm(model, typ=2)
                st.subheader("ğŸ“Š å¤šå› ç´ å½±å“åˆ†æç»“æœ")
                st.dataframe(anova_result, use_container_width=True)
                
                fig = px.box(df, x=params["factor_cols"][0], y=params["result_col"],
                           color=params["factor_cols"][1] if len(params["factor_cols"])>1 else None,
                           title=f"å„æ¡ä»¶å¯¹{params['result_col']}çš„å½±å“", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                significant = [idx for idx, p in anova_result["PR(>F)"].items() if p<0.05]
                # é€šä¿—è§£è¯»
                if significant:
                    sig_desc = f"ã€Œ{', '.join(significant)}ã€å¯¹ç»“æœæœ‰æ˜¾è‘—å½±å“"
                    reason = "è¯´æ˜è¿™äº›æ¡ä»¶çœŸçš„ä¼šæ”¹å˜ç»“æœï¼Œä¸æ˜¯å·§åˆ"
                else:
                    sig_desc = "æ²¡æœ‰æ¡ä»¶å¯¹ç»“æœæœ‰æ˜¾è‘—å½±å“"
                    reason = "è¯´æ˜è¿™äº›æ¡ä»¶çš„å˜åŒ–ä¸ä¼šæœ¬è´¨æ”¹å˜ç»“æœ"
                interpretation = f"""
                ğŸ“ ç»“æœè§£è¯»ï¼š
                1. åˆ†æçš„æ¡ä»¶æ˜¯ï¼š{', '.join(params['factor_cols'])}ï¼Œå…³æ³¨çš„ç»“æœæ˜¯ï¼š{params['result_col']}ï¼›
                2. {sig_desc}ï¼ˆp<0.05ä¸ºæ˜¾è‘—ï¼‰ï¼›
                3. {reason}ï¼›
                4. æ¯”å¦‚å¦‚æœå•†å“ç±»å‹ï¼ˆSKUï¼‰æ˜¾è‘—å½±å“è®¢å•é‡ï¼Œè¯´æ˜ä¸åŒç±»å‹çš„æµ·é²œï¼Œé—¨åº—çš„é‡‡è´­é‡ç¡®å®ä¸ä¸€æ ·ã€‚
                """

            # 4. å˜é‡å…³ç³»åˆ†æ
            elif target_analysis == "regression":
                x_col, y_col = params["x_col"], params["y_col"]
                df_reg = df[[x_col, y_col]].dropna()
                model = ols(f"{y_col} ~ {x_col}", data=df_reg).fit()
                
                st.subheader("ğŸ“ˆ å˜é‡å…³ç³»åˆ†æç»“æœ")
                st.write(f"å…³ç³»å…¬å¼ï¼š{y_col} = {model.params[0]:.2f} + {model.params[x_col]:.4f}Ã—{x_col}")
                st.write(f"æ‹Ÿåˆåº¦RÂ²ï¼š{model.rsquared:.4f}ï¼ˆè¶Šæ¥è¿‘1ï¼Œå…³ç³»è¶Šç´§å¯†ï¼‰")
                st.write(f"æ˜¾è‘—æ€§på€¼ï¼š{model.pvalues[x_col]:.4f}ï¼ˆp<0.05è¯´æ˜å…³ç³»çœŸçš„å­˜åœ¨ï¼‰")
                
                fig = px.scatter(df_reg, x=x_col, y=y_col, trendline="ols", color_discrete_sequence=[params["chart_color"]],
                               title=f"{x_col}å¯¹{y_col}çš„å½±å“", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                # é€šä¿—è§£è¯»
                coef = model.params[x_col]
                r2 = model.rsquared
                if model.pvalues[x_col] < 0.05:
                    rel_desc = "å­˜åœ¨æ˜¾è‘—çš„çº¿æ€§å…³ç³»"
                    if coef > 0:
                        trend = "å¢åŠ "
                    else:
                        trend = "å‡å°‘"
                    trend_desc = f"{x_col}æ¯å¢åŠ 1{COL_MEANING.get(x_col, 'å•ä½')}ï¼Œ{y_col}å°±{trend} {abs(coef):.4f}{COL_MEANING.get(y_col, 'å•ä½')}"
                else:
                    rel_desc = "æ²¡æœ‰æ˜¾è‘—çš„çº¿æ€§å…³ç³»"
                    trend_desc = "ä¸¤è€…çš„å˜åŒ–æ²¡æœ‰æ˜æ˜¾çš„è§„å¾‹"
                interpretation = f"""
                ğŸ“ ç»“æœè§£è¯»ï¼š
                1. {x_col}å’Œ{y_col}ä¹‹é—´{rel_desc}ï¼ˆp={model.pvalues[x_col]:.4f}ï¼‰ï¼›
                2. {trend_desc}ï¼›
                3. æ‹Ÿåˆåº¦RÂ²={r2:.4f}ï¼Œè¯´æ˜{y_col}çš„å˜åŒ–ä¸­ï¼Œæœ‰{r2*100:.1f}%èƒ½é€šè¿‡{x_col}çš„å˜åŒ–æ¥è§£é‡Šï¼›
                4. æ¯”å¦‚å¦‚æœè®¢å•é‡ï¼ˆqtyï¼‰å’Œæˆæœ¬ï¼ˆProcessing_feeï¼‰æ­£ç›¸å…³ï¼Œè¯´æ˜è®¢å•é‡è¶Šå¤§ï¼Œå¤„ç½®æˆæœ¬è¶Šé«˜ï¼Œç¬¦åˆå®é™…è¿è¥é€»è¾‘ã€‚
                """

            # 5. åˆ†ç±»é¢„æµ‹
            elif target_analysis == "logistic_reg":
                target_col, feature_cols = params["target_col"], params["feature_cols"]
                df_log = df[[*feature_cols, target_col + "_encoded"]].dropna()
                model = LogisticRegression()
                model.fit(df_log[feature_cols], df_log[target_col + "_encoded"])
                accuracy = model.score(df_log[feature_cols], df_log[target_col + "_encoded"])
                coefs = dict(zip(feature_cols, model.coef_[0]))
                
                st.subheader("ğŸ”® åˆ†ç±»é¢„æµ‹ç»“æœ")
                st.write(f"é¢„æµ‹å‡†ç¡®ç‡ï¼š{accuracy:.4f}ï¼ˆæ¯”å¦‚0.85å°±æ˜¯85%çš„æƒ…å†µèƒ½é¢„æµ‹å¯¹ï¼‰")
                st.write("å“ªäº›æ•°æ®å¯¹é¢„æµ‹å½±å“å¤§ï¼Ÿï¼ˆç³»æ•°è¶Šå¤§ï¼Œå½±å“è¶Šå¼ºï¼‰")
                st.dataframe(pd.DataFrame({"ç”¨äºé¢„æµ‹çš„æ•°æ®": coefs.keys(), "å½±å“å¼ºåº¦ï¼ˆç³»æ•°ï¼‰": coefs.values()}), use_container_width=True)
                
                fig = px.bar(x=coefs.keys(), y=coefs.values(), color_discrete_sequence=[params["chart_color"]],
                           title="å„æ•°æ®çš„é¢„æµ‹å½±å“å¼ºåº¦", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                # é€šä¿—è§£è¯»
                top_feature = max(coefs, key=coefs.get)
                accuracy_desc = "å¾ˆé«˜" if accuracy > 0.8 else "ä¸­ç­‰" if accuracy > 0.6 else "è¾ƒä½"
                interpretation = f"""
                ğŸ“ ç»“æœè§£è¯»ï¼š
                1. ç”¨{', '.join(feature_cols)}é¢„æµ‹{target_col}ï¼Œå‡†ç¡®ç‡{accuracy:.2f}ï¼Œå±äº{accuracy_desc}æ°´å¹³ï¼›
                2. å½±å“æœ€å¤§çš„æ˜¯{top_feature}ï¼ˆå½±å“å¼ºåº¦ï¼š{coefs[top_feature]:.4f}ï¼‰ï¼›
                3. æ­£ç³»æ•°è¯´æ˜è¿™ä¸ªæ•°æ®è¶Šå¤§ï¼Œè¶Šå€¾å‘äºé¢„æµ‹ä¸ºæŸä¸€ç±»ï¼ˆæ¯”å¦‚å€¾å‘äºè¿›å£æµ·é²œï¼‰ï¼Œè´Ÿç³»æ•°åˆ™ç›¸åï¼›
                4. æ¯”å¦‚é¢„æµ‹å•†å“ç±»å‹æ—¶ï¼ŒåŸå¸‚äººå£ï¼ˆresident_popï¼‰å½±å“æœ€å¤§ï¼Œè¯´æ˜äººå£å¤šçš„åŸå¸‚æ›´å¯èƒ½é‡‡è´­è¿›å£æµ·é²œã€‚
                """

            # 6. æ•°æ®åˆ†ç¾¤
            elif target_analysis == "kmeans":
                feature_cols = params["feature_cols"]
                df_cluster = df[feature_cols].dropna()
                kmeans = KMeans(n_clusters=params["n_clusters"], random_state=42).fit(df_cluster)
                df["åˆ†ç¾¤æ ‡ç­¾"] = kmeans.labels_
                
                st.subheader("ğŸŒ€ æ•°æ®åˆ†ç¾¤ç»“æœ")
                st.write(f"å…±åˆ†æˆ{params['n_clusters']}ç»„ï¼Œæ¯ç»„çš„æ•°é‡ï¼š")
                st.dataframe(df["åˆ†ç¾¤æ ‡ç­¾"].value_counts(), use_container_width=True)
                st.write("æ¯ç»„çš„æ ¸å¿ƒç‰¹å¾ï¼ˆæ¯”å¦‚å¹³å‡è®¢å•é‡ã€å¹³å‡äººå£ï¼‰ï¼š")
                centers = pd.DataFrame(kmeans.cluster_centers_, columns=feature_cols)
                st.dataframe(centers, use_container_width=True)
                
                fig = px.scatter(df_cluster, x=feature_cols[0], y=feature_cols[1], color=kmeans.labels_,
                               color_discrete_sequence=[params["chart_color"], "#ff7f0e", "#2ca02c", "#d62728"][:params["n_clusters"]],
                               title=f"æ•°æ®åˆ†ç¾¤ç»“æœï¼ˆå…±{params['n_clusters']}ç»„ï¼‰", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                # é€šä¿—è§£è¯»
                cluster_desc = []
                for i in range(params["n_clusters"]):
                    center = centers.iloc[i]
                    desc = f"ç¬¬{i}ç»„ï¼š"
                    for col in feature_cols:
                        desc += f"{col}å¹³å‡{center[col]:.2f}ï¼ˆ{COL_MEANING.get(col, 'å•ä½')}ï¼‰ï¼Œ"
                    cluster_desc.append(desc[:-1])
                interpretation = f"""
                ğŸ“ ç»“æœè§£è¯»ï¼š
                1. æ•°æ®æŒ‰{', '.join(feature_cols)}åˆ†æˆäº†{params['n_clusters']}ç»„ï¼Œæ¯ç»„æ•°é‡åˆ†åˆ«æ˜¯{dict(df['åˆ†ç¾¤æ ‡ç­¾'].value_counts())}ï¼›
                2. å„ç»„ç‰¹å¾ï¼š
                   - {cluster_desc[0]}
                   - {cluster_desc[1]}
                   {'- ' + cluster_desc[2] if params['n_clusters']>=3 else ''}
                3. æ¯”å¦‚æŒ‰è®¢å•é‡å’Œäººå£åˆ†ç¾¤ï¼Œç¬¬0ç»„æ˜¯â€œäººå£å¤šã€è®¢å•é‡å¤§â€çš„åŸå¸‚ï¼Œç¬¬1ç»„æ˜¯â€œäººå£å°‘ã€è®¢å•é‡å°â€çš„åŸå¸‚ï¼Œå¯é’ˆå¯¹æ€§åˆ¶å®šä¾›åº”é“¾ç­–ç•¥ã€‚
                """

            # æ˜¾ç¤ºç»“æœ+è§£è¯»
            st.divider()
            st.markdown("### ğŸ“ æ ¸å¿ƒç»“è®º+é€šä¿—è§£è¯»")
            st.markdown(interpretation)
            
            # ä¸‹è½½æŠ¥å‘Š
            full_report = f"# åˆ†ææŠ¥å‘Š\n## åˆ†æç±»å‹ï¼š{analysis_type}\n## æ ¸å¿ƒç»“æœ\n{report}\n## é€šä¿—è§£è¯»\n{interpretation}"
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½å®Œæ•´æŠ¥å‘Šï¼ˆå«è§£è¯»ï¼‰",
                data=full_report,
                file_name=f"æ˜“æ‡‚ç‰ˆåˆ†ææŠ¥å‘Š_{analysis_type.replace('ã€', '').replace('ï¼ˆ', '').replace('ï¼‰', '')}.md",
                mime="text/markdown"
            )
            
    except Exception as e:
        st.error(f"âŒ åˆ†æå¤±è´¥ï¼š{str(e)}")
        st.info("ğŸ’¡ å¯èƒ½åŸå› ï¼šæ•°æ®å¤ªå°‘ã€é€‰çš„å­—æ®µä¸å¯¹ã€éƒ¨åˆ†æ•°æ®ç¼ºå¤±å¤ªå¤š")
