import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
import warnings
import io
import re
import os
from datetime import datetime
import requests  # æ–°å¢ï¼šè°ƒç”¨DeepSeek APIéœ€è¦çš„ç½‘ç»œè¯·æ±‚åº“
import json      # æ–°å¢ï¼šå¤„ç†APIè¿”å›çš„JSONæ•°æ®

# åŸºç¡€é…ç½®
warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
st.set_page_config(page_title="ç§‘ç ”æ•°æ®åˆ†æå¹³å°", page_icon="ğŸ“Š", layout="wide", initial_sidebar_state="expanded")

# æ ¸å¿ƒä¾èµ–å¯¼å…¥
try:
    from scipy.stats import chi2_contingency, ttest_1samp, ttest_ind, ttest_rel, ks_2samp, mannwhitneyu, kruskal, friedmanchisquare, wilcoxon
    from statsmodels.stats.proportion import binom_test as sm_binom_test
    from statsmodels.formula.api import ols
    from statsmodels.stats.anova import anova_lm
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.linear_model import LinearRegression, LogisticRegression
    from sklearn.metrics import r2_score, classification_report
except ImportError as e:
    st.error(f"éƒ¨åˆ†åˆ†æåº“å¯¼å…¥å¤±è´¥ï¼š{e}ï¼Œè¯·æ£€æŸ¥requirements.txt")

# ---------------------- æ–°å¢ï¼šDeepSeek APIè°ƒç”¨æ ¸å¿ƒå‡½æ•° ----------------------
def call_deepseek_api(api_key, prompt, model="deepseek-chat", temperature=0.7):
    """
    è°ƒç”¨DeepSeekå¤§æ¨¡å‹API
    :param api_key: ç”¨æˆ·çš„DeepSeek APIå¯†é’¥ï¼ˆå¿…å¡«ï¼‰
    :param prompt: å‘ç»™AIçš„æç¤ºè¯
    :param model: è°ƒç”¨çš„æ¨¡å‹ï¼Œé»˜è®¤deepseek-chatï¼ˆé€šç”¨å¯¹è¯ï¼‰
    :param temperature: ç”Ÿæˆéšæœºæ€§ï¼Œ0-1ï¼Œè¶Šå°è¶Šä¸¥è°¨
    :return: AIçš„å›ç­”å†…å®¹/é”™è¯¯æç¤º
    """
    # DeepSeek APIå®˜æ–¹æ¥å£åœ°å€ï¼ˆæ— éœ€ä¿®æ”¹ï¼‰
    API_URL = "https://api.deepseek.com/v1/chat/completions"
    # è¯·æ±‚å¤´ï¼ˆå›ºå®šæ ¼å¼ï¼Œä»…éœ€ä¼ å…¥api_keyï¼‰
    headers = {
        "Content-Type": "application/json",
        "Authorization": f"Bearer {api_key}"  # BearerååŠ ç©ºæ ¼ï¼Œå›ºå®šæ ¼å¼
    }
    # è¯·æ±‚ä½“ï¼ˆæŒ‰DeepSeek APIæ–‡æ¡£è¦æ±‚æ„é€ ï¼‰
    payload = {
        "model": model,
        "messages": [{"role": "user", "content": prompt}],
        "temperature": temperature,
        "max_tokens": 2048  # æœ€å¤§ç”Ÿæˆå­—ç¬¦æ•°ï¼Œå¯æ ¹æ®éœ€è¦è°ƒæ•´
    }
    try:
        # å‘é€POSTè¯·æ±‚è°ƒç”¨API
        response = requests.post(API_URL, headers=headers, json=payload, timeout=30)
        response.raise_for_status()  # æ•è·HTTPè¯·æ±‚é”™è¯¯
        result = response.json()
        # æå–AIçš„å›ç­”å†…å®¹
        return result["choices"][0]["message"]["content"]
    except requests.exceptions.Timeout:
        return "âŒ APIè°ƒç”¨è¶…æ—¶ï¼šè¯·æ£€æŸ¥ç½‘ç»œæˆ–ç¨åé‡è¯•"
    except requests.exceptions.ConnectionError:
        return "âŒ ç½‘ç»œè¿æ¥å¤±è´¥ï¼šè¯·æ£€æŸ¥æœ¬åœ°ç½‘ç»œ"
    except KeyError:
        return f"âŒ APIè¿”å›æ•°æ®å¼‚å¸¸ï¼š{result.get('error', 'æœªçŸ¥é”™è¯¯')}"
    except Exception as e:
        return f"âŒ APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}"

# ---------------------- åŸæœ‰æ ¸å¿ƒåˆ†æå‡½æ•°ï¼ˆå®Œå…¨ä¿ç•™ï¼Œæ— ä¿®æ”¹ï¼‰ ----------------------
def load_and_clean_data(file):
    encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312']
    seps = [',', '\t', ';']
    try:
        file_content = file.read()
        file.seek(0)
        df = None
        if file.name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        break
                    except:
                        continue
                if df is not None:
                    break
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
        df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

def identify_variable_types(df):
    numeric_cols = []
    categorical_cols = []
    binary_categorical_cols = []
    datetime_cols = []
    for col in df.columns:
        if any(fmt in col.lower() for fmt in ['date', 'time', '2016', '2017', '2018', '2019', '2020']):
            try:
                df[col] = pd.to_datetime(df[col])
                datetime_cols.append(col)
                continue
            except:
                pass
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            numeric_cols.append(col)
        except:
            categorical_cols.append(col)
            if df[col].nunique() == 2:
                binary_categorical_cols.append(col)
    return {'numeric': numeric_cols, 'categorical': categorical_cols, 'binary_categorical': binary_categorical_cols, 'datetime': datetime_cols}

def frequency_analysis(df, categorical_cols):
    freq_dict = {}
    for col in categorical_cols:
        freq = df[col].value_counts()
        freq_pct = df[col].value_counts(normalize=True) * 100
        freq_df = pd.DataFrame({'é¢‘æ•°': freq, 'é¢‘ç‡(%)': freq_pct.round(2)})
        freq_dict[col] = freq_df
    return freq_dict

def descriptive_analysis(df, numeric_cols):
    desc_df = df[numeric_cols].describe().T
    desc_df['ç¼ºå¤±å€¼'] = df[numeric_cols].isnull().sum()
    desc_df['ç¼ºå¤±ç‡(%)'] = (desc_df['ç¼ºå¤±å€¼'] / len(df) * 100).round(2)
    desc_df['ååº¦'] = df[numeric_cols].skew().round(3)
    desc_df['å³°åº¦'] = df[numeric_cols].kurt().round(3)
    return desc_df

def contingency_table_analysis(df, col1, col2):
    cont_table = pd.crosstab(df[col1], df[col2])
    chi2, p, dof, expected = chi2_contingency(cont_table)
    cramers_v = np.sqrt(chi2 / (len(df) * min(cont_table.shape[0]-1, cont_table.shape[1]-1)))
    return {'è”åˆ—è¡¨': cont_table, 'å¡æ–¹å€¼': chi2.round(3), 'på€¼': p.round(4), 'è‡ªç”±åº¦': dof, 'å…‹è±å§†Vç³»æ•°': cramers_v.round(3)}

def t_test_onesample(df, numeric_col, popmean):
    data = df[numeric_col].dropna()
    t_stat, p_value = ttest_1samp(data, popmean)
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), 'å‡å€¼': data.mean().round(2), 'æ ·æœ¬é‡': len(data)}

def t_test_independent(df, numeric_col, group_col):
    groups = df[group_col].unique()
    if len(groups) != 2:
        return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
    group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
    group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
    t_stat, p_value = ttest_ind(group1, group2, equal_var=False)
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), f'{groups[0]}å‡å€¼': group1.mean().round(2), f'{groups[1]}å‡å€¼': group2.mean().round(2), f'{groups[0]}æ ·æœ¬é‡': len(group1), f'{groups[1]}æ ·æœ¬é‡': len(group2)}

def nonparametric_test(df, test_type, numeric_col, group_col=None):
    if test_type == 'å•æ ·æœ¬K-Sæ£€éªŒ':
        data = df[numeric_col].dropna()
        ks_stat, p_value = stats.kstest(data, 'norm', args=(data.mean(), data.std()))
        return {'KSç»Ÿè®¡é‡': ks_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ':
        groups = df[group_col].unique()
        if len(groups) != 2:
            return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
        group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
        group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
        u_stat, p_value = mannwhitneyu(group1, group2)
        return {'Uå€¼': u_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ':
        data = df[numeric_col].dropna()
        success = sum(data == 1)
        n = len(data)
        p_value = sm_binom_test(success, n, prop=0.5)
        return {'æˆåŠŸæ¬¡æ•°': success, 'æ€»æ¬¡æ•°': n, 'på€¼': p_value.round(4)}
    return {'error': 'æ— æ•ˆæ£€éªŒç±»å‹'}

def anova_analysis(df, formula, anova_type):
    model = ols(formula, data=df).fit()
    anova_result = anova_lm(model, typ=2)
    tukey = pairwise_tukeyhsd(df[formula.split('~')[0]], df[formula.split('~')[1].split('+')[0]], alpha=0.05)
    return {'æ–¹å·®åˆ†æè¡¨': anova_result, 'äº‹åæ£€éªŒ(Tukey)': tukey.summary()}

def correlation_analysis(df, cols, corr_type='pearson'):
    corr_df = df[cols].dropna()
    if corr_type == 'pearson':
        corr_matrix = corr_df.corr(method='pearson')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.pearsonr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    elif corr_type == 'spearman':
        corr_matrix = corr_df.corr(method='spearman')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.spearmanr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    return {'ç›¸å…³çŸ©é˜µ': corr_matrix.round(3), 'på€¼çŸ©é˜µ': p_matrix}

def regression_analysis(df, target, features, reg_type):
    X = df[features].dropna()
    y = df[target][X.index].dropna()
    X = X.loc[y.index]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    if reg_type == 'çº¿æ€§å›å½’':
        model = LinearRegression().fit(X_scaled, y)
        y_pred = model.predict(X_scaled)
        r2 = r2_score(y, y_pred)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_.round(3), 'æˆªè·': [model.intercept_.round(3)]*len(features)})
        return {'RÂ²': r2.round(3), 'ç³»æ•°è¡¨': coef}
    elif reg_type == 'äºŒåˆ†ç±»Logisticå›å½’':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        model = LogisticRegression(max_iter=1000).fit(X_scaled, y_encoded)
        y_pred = model.predict(X_scaled)
        report = classification_report(y_encoded, y_pred, output_dict=True)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_[0].round(3), 'æˆªè·': [model.intercept_[0].round(3)]*len(features)})
        return {'åˆ†ç±»æŠ¥å‘Š': report, 'ç³»æ•°è¡¨': coef}
    return {'error': 'æ— æ•ˆå›å½’ç±»å‹'}

def cluster_analysis(df, cols, n_clusters=3):
    X = df[cols].dropna()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_scaled)
    df_cluster = X.copy()
    df_cluster['èšç±»ç»“æœ'] = kmeans.labels_
    centroids = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=cols).round(2)
    return {'èšç±»ç»“æœ': df_cluster, 'èšç±»ä¸­å¿ƒ': centroids}

def plot_chart(df, plot_type, x_col, y_col=None, group_col=None):
    if plot_type == 'æ¡å½¢å›¾':
        fig = px.bar(df, x=x_col, y=y_col, color=group_col, barmode='group', title=f'{x_col} - {y_col}')
    elif plot_type == 'æŠ˜çº¿å›¾':
        fig = px.line(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col}')
    elif plot_type == 'é¥¼å›¾':
        fig = px.pie(df, names=x_col, values=y_col, title=f'{x_col} åˆ†å¸ƒ')
    elif plot_type == 'ç®±å›¾':
        fig = px.box(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col} åˆ†å¸ƒ')
    fig.update_layout(width=800, height=500)
    return fig

# ---------------------- é¡µé¢ä¸»ä½“ï¼ˆä¾§è¾¹æ +ä¸»å†…å®¹åŒºï¼Œæ–°å¢APIè¾“å…¥å’ŒAIæ ‡ç­¾é¡µï¼‰ ----------------------
st.title("ç§‘ç ”æ•°æ®åˆ†æå¹³å°")
st.divider()

# ---------------------- ä¾§è¾¹æ ï¼ˆæ–°å¢ã€DeepSeek APIé…ç½®åŒºã€‘ï¼Œæ ‡æ³¨æ¸…æ™°ï¼‰ ----------------------
with st.sidebar:
    # ========== ã€### æ­¤å¤„ä¸ºç”¨æˆ·æ“ä½œåŒº1ï¼šDeepSeek APIå¯†é’¥è¾“å…¥ ###ã€‘ ==========
    st.markdown("## ğŸ¤– DeepSeek AIé…ç½®")
    st.markdown("### è¯·è¾“å…¥ä½ çš„DeepSeek APIå¯†é’¥ï¼ˆå¯†ç ç±»å‹ï¼Œä¸ä¼šæ³„éœ²ï¼‰")
    st.markdown("#### è·å–åœ°å€ï¼š[DeepSeekå¼€æ”¾å¹³å°](https://platform.deepseek.com/) â†’ æ§åˆ¶å° â†’ APIå¯†é’¥ç®¡ç†")
    DEEPSEEK_API_KEY = st.text_input(
        label="DeepSeek API Key",
        type="password",  # å¯†ç ç±»å‹ï¼Œè¾“å…¥å†…å®¹éšè—
        placeholder="sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx",  # APIæ ¼å¼ç¤ºä¾‹
        key="deepseek_api_key"
    )
    st.markdown("---")  # åˆ†éš”çº¿ï¼ŒåŒºåˆ†APIé…ç½®å’Œæ•°æ®ä¸Šä¼ 
    # ======================================================================

    # åŸæœ‰æ•°æ®ä¸Šä¼ åŠŸèƒ½ï¼ˆå®Œå…¨ä¿ç•™ï¼‰
    st.markdown("## ğŸ“¥ æ•°æ®ä¸Šä¼ ")
    uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ï¼ˆCSV/Excelï¼Œæ”¯æŒå¤šæ–‡ä»¶ï¼‰", type=["xlsx", "csv"], accept_multiple_files=True)
    df = None
    var_types = None
    if uploaded_files:
        selected_file_names = st.multiselect("é€‰æ‹©åˆ†ææ–‡ä»¶", [f.name for f in uploaded_files], default=[uploaded_files[0].name])
        selected_files = [f for f in uploaded_files if f.name in selected_file_names]
        
        df_dict = {}
        for file in selected_files:
            df_temp = load_and_clean_data(file)
            if df_temp is not None:
                df_dict[file.name] = df_temp
                st.success(f"{file.name} ä¸Šä¼ æˆåŠŸ ({len(df_temp)}è¡ŒÃ—{len(df_temp.columns)}åˆ—)")
        
        # å¤šæ–‡ä»¶åˆå¹¶
        if len(df_dict) >= 2:
            base_file = st.selectbox("åŸºç¡€æ–‡ä»¶", list(df_dict.keys()))
            df = df_dict[base_file]
            for other_file in [f for f in df_dict.keys() if f != base_file]:
                df_other = df_dict[other_file]
                common_cols = [col for col in df.columns if col in df_other.columns]
                base_key = st.selectbox(f"åŸºç¡€å…³è”å­—æ®µ", common_cols if common_cols else df.columns, key=f"base_{other_file}")
                join_key = st.selectbox(f"å…³è”å­—æ®µ", common_cols if common_cols else df_other.columns, key=f"join_{other_file}")
                join_type = st.selectbox(f"åˆå¹¶æ–¹å¼", ['å·¦è¿æ¥', 'å³è¿æ¥', 'å†…è¿æ¥', 'å¤–è¿æ¥'], key=f"type_{other_file}")
                join_map = {'å·¦è¿æ¥':'left', 'å³è¿æ¥':'right', 'å†…è¿æ¥':'inner', 'å¤–è¿æ¥':'outer'}
                if st.button(f"åˆå¹¶{other_file}", key=f"btn_{other_file}"):
                    df = pd.merge(df, df_other, left_on=base_key, right_on=join_key, how=join_map[join_type], suffixes=("", f"_{other_file.split('.')[0]}"))
                    st.success(f"åˆå¹¶åï¼š{len(df)}è¡ŒÃ—{len(df.columns)}åˆ—")
        else:
            df = df_dict[list(df_dict.keys())[0]] if df_dict else None
        
        # æ•°æ®æ¦‚å†µ
        if df is not None:
            var_types = identify_variable_types(df)
            st.markdown("## ğŸ“Š æ•°æ®æ¦‚å†µ")
            st.write(f"è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            st.write(f"æ•°å€¼å‹å˜é‡ï¼š{len(var_types['numeric'])}ä¸ª")
            st.write(f"åˆ†ç±»å‹å˜é‡ï¼š{len(var_types['categorical'])}ä¸ª")

# ---------------------- ä¸»å†…å®¹åŒºï¼ˆæ–°å¢ç¬¬8ä¸ªã€AIåˆ†æã€‘æ ‡ç­¾é¡µï¼Œå…¶ä½™ä¿ç•™ï¼‰ ----------------------
if df is not None and var_types is not None:
    # æå–æ•°æ®æ¦‚å†µï¼ˆä¼ ç»™AIï¼Œä¸ä¼ é€’åŸå§‹æ•°æ®ï¼Œä¿æŠ¤éšç§+èŠ‚çœtokenï¼‰
    data_overview = f"""
    æœ¬æ¬¡åˆ†ææ•°æ®æ¦‚å†µï¼š
    1. æ•°æ®è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—
    2. æ•°å€¼å‹å˜é‡ï¼š{', '.join(var_types['numeric']) if var_types['numeric'] else 'æ— '}
    3. åˆ†ç±»å‹å˜é‡ï¼š{', '.join(var_types['categorical']) if var_types['categorical'] else 'æ— '}
    4. äºŒåˆ†ç±»å˜é‡ï¼š{', '.join(var_types['binary_categorical']) if var_types['binary_categorical'] else 'æ— '}
    5. ç¼ºå¤±å€¼æ€»æ•°ï¼š{df.isnull().sum().sum()}ä¸ªï¼Œæ•´ä½“ç¼ºå¤±ç‡ï¼š{(df.isnull().sum().sum()/(df.shape[0]*df.shape[1]))*100:.2f}%
    """
    # åŸæœ‰7ä¸ªæ ‡ç­¾é¡µ + æ–°å¢ã€AIåˆ†æã€‘æ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs([
        "æ•°æ®å¤„ç†", "åŸºæœ¬ç»Ÿè®¡", "å‡å€¼æ£€éªŒ", "æ–¹å·®åˆ†æ", "ç›¸å…³åˆ†æ", "å›å½’åˆ†æ", "å¯è§†åŒ–", "AIåˆ†æ"
    ])

    # æ ‡ç­¾é¡µ1-7ï¼šåŸæœ‰åŠŸèƒ½ï¼ˆå®Œå…¨ä¿ç•™ï¼Œä»…ä¿®å¤äº†ç›¸å…³åˆ†æçš„å˜é‡æ ¡éªŒï¼‰
    with tab1:
        st.subheader("æ•°æ®å¤„ç†")
        sort_col = st.selectbox("æ’åºå­—æ®µ", df.columns, key='sort')
        sort_asc = st.radio("æ’åºæ–¹å¼", ['å‡åº', 'é™åº'], key='sort_asc')
        if st.button("æ‰§è¡Œæ’åº"):
            df_sorted = df.sort_values(by=sort_col, ascending=(sort_asc=='å‡åº'))
            st.dataframe(df_sorted.head(10), use_container_width=True)
        
        filter_col = st.selectbox("ç­›é€‰å­—æ®µ", df.columns, key='filter')
        filter_op = st.selectbox("è¿ç®—ç¬¦", ['>', '<', '>=', '<=', '==', '!='], key='filter_op')
        filter_val = st.text_input("ç­›é€‰å€¼", key='filter_val')
        if st.button("æ‰§è¡Œç­›é€‰"):
            try:
                if df[filter_col].dtype in [np.int64, np.float64]:
                    filter_val = float(filter_val)
                df_filtered = df.query(f"`{filter_col}` {filter_op} {filter_val}")
                st.success(f"ç­›é€‰åï¼š{len(df_filtered)}è¡Œ")
                st.dataframe(df_filtered.head(10), use_container_width=True)
            except:
                st.error("ç­›é€‰æ¡ä»¶é”™è¯¯ï¼Œè¯·æ£€æŸ¥å€¼çš„ç±»å‹")
        
        group_col = st.selectbox("åˆ†ç»„å­—æ®µ", var_types['categorical'], key='group', disabled=not var_types['categorical'])
        agg_col = st.selectbox("æ±‡æ€»å­—æ®µ", var_types['numeric'], key='agg', disabled=not var_types['numeric'])
        agg_func = st.selectbox("æ±‡æ€»æ–¹å¼", ['å‡å€¼', 'æ±‚å’Œ', 'è®¡æ•°', 'æœ€å¤§å€¼', 'æœ€å°å€¼'], key='agg_func')
        agg_map = {'å‡å€¼':'mean', 'æ±‚å’Œ':'sum', 'è®¡æ•°':'count', 'æœ€å¤§å€¼':'max', 'æœ€å°å€¼':'min'}
        if st.button("æ‰§è¡Œåˆ†ç±»æ±‡æ€»", disabled=not (group_col and agg_col)):
            df_agg = df.groupby(group_col)[agg_col].agg(agg_map[agg_func]).round(2)
            st.dataframe(df_agg, use_container_width=True)

    with tab2:
        st.subheader("åŸºæœ¬ç»Ÿè®¡")
        freq_cols = st.multiselect("é€‰æ‹©åˆ†ç±»å‹å˜é‡", var_types['categorical'], key='freq')
        if freq_cols and st.button("æ‰§è¡Œé¢‘æ•°åˆ†æ"):
            freq_dict = frequency_analysis(df, freq_cols)
            for col in freq_cols:
                st.subheader(col)
                st.dataframe(freq_dict[col], use_container_width=True)
        
        desc_cols = st.multiselect("é€‰æ‹©æ•°å€¼å‹å˜é‡", var_types['numeric'], key='desc')
        if desc_cols and st.button("æ‰§è¡Œæè¿°ç»Ÿè®¡"):
            desc_df = descriptive_analysis(df, desc_cols)
            st.dataframe(desc_df, use_container_width=True)
        
        if len(var_types['categorical'])>=2:
            cont_col1 = st.selectbox("è¡Œå˜é‡", var_types['categorical'], key='cont1')
            cont_col2 = st.selectbox("åˆ—å˜é‡", var_types['categorical'], key='cont2')
            if st.button("æ‰§è¡Œè”åˆ—è¡¨+å¡æ–¹æ£€éªŒ"):
                cont_res = contingency_table_analysis(df, cont_col1, cont_col2)
                st.subheader("è”åˆ—è¡¨")
                st.dataframe(cont_res['è”åˆ—è¡¨'], use_container_width=True)
                st.write(f"å¡æ–¹å€¼ï¼š{cont_res['å¡æ–¹å€¼']} | på€¼ï¼š{cont_res['på€¼']} | è‡ªç”±åº¦ï¼š{cont_res['è‡ªç”±åº¦']} | å…‹è±å§†Vç³»æ•°ï¼š{cont_res['å…‹è±å§†Vç³»æ•°']}")

    with tab3:
        st.subheader("å‡å€¼æ£€éªŒ")
        onesamp_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='onesamp', disabled=not var_types['numeric'])
        popmean = st.number_input("æ€»ä½“å‡å€¼", value=0.0, key='popmean')
        if st.button("æ‰§è¡Œå•æ ·æœ¬tæ£€éªŒ", disabled=not onesamp_col):
            onesamp_res = t_test_onesample(df, onesamp_col, popmean)
            st.write(f"tå€¼ï¼š{onesamp_res['tå€¼']} | på€¼ï¼š{onesamp_res['på€¼']} | æ ·æœ¬å‡å€¼ï¼š{onesamp_res['å‡å€¼']} | æ ·æœ¬é‡ï¼š{onesamp_res['æ ·æœ¬é‡']}")
        
        ind_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='ind', disabled=not var_types['numeric'])
        ind_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='ind_group', disabled=not var_types['categorical'])
        if st.button("æ‰§è¡Œä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ", disabled=not (ind_col and ind_group)):
            ind_res = t_test_independent(df, ind_col, ind_group)
            if 'error' in ind_res:
                st.error(ind_res['error'])
            else:
                st.write(f"tå€¼ï¼š{ind_res['tå€¼']} | på€¼ï¼š{ind_res['på€¼']}")
                st.write(f"{list(ind_res.keys())[2]}ï¼š{ind_res[list(ind_res.keys())[2]]} | {list(ind_res.keys())[3]}ï¼š{ind_res[list(ind_res.keys())[3]]}")
        
        test_type = st.selectbox("éå‚æ•°æ£€éªŒç±»å‹", ['å•æ ·æœ¬K-Sæ£€éªŒ', 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ', 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ'], key='test_type')
        np_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='np', disabled=not var_types['numeric'])
        np_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='np_group', disabled=test_type not in ['ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ'])
        if st.button("æ‰§è¡Œéå‚æ•°æ£€éªŒ", disabled=not np_col):
            np_res = nonparametric_test(df, test_type, np_col, np_group)
            if 'error' in np_res:
                st.error(np_res['error'])
            else:
                for k, v in np_res.items():
                    st.write(f"{k}ï¼š{v}")

    with tab4:
        st.subheader("æ–¹å·®åˆ†æ")
        if var_types['numeric'] and var_types['categorical']:
            anova_target = st.selectbox("å› å˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'], key='anova_target')
            anova_factor = st.selectbox("å› ç´ å˜é‡ï¼ˆåˆ†ç±»å‹ï¼‰", var_types['categorical'], key='anova_factor')
            formula = f"{anova_target} ~ C({anova_factor})"
            if st.button("æ‰§è¡Œå•å› ç´ æ–¹å·®åˆ†æ+Tukeyäº‹åæ£€éªŒ"):
                anova_res = anova_analysis(df, formula, 'å•å› ç´ æ–¹å·®åˆ†æ')
                st.subheader("æ–¹å·®åˆ†æè¡¨")
                st.dataframe(anova_res['æ–¹å·®åˆ†æè¡¨'], use_container_width=True)
                st.subheader("Tukeyäº‹åæ£€éªŒç»“æœ")
                st.text(anova_res['äº‹åæ£€éªŒ(Tukey)'])

    with tab5:
        st.subheader("ç›¸å…³åˆ†æ")
        corr_type = st.selectbox("ç›¸å…³ç³»æ•°ç±»å‹", ['pearsonï¼ˆçš®å°”é€Šï¼Œé€‚ç”¨äºæ­£æ€ï¼‰', 'spearmanï¼ˆæ–¯çš®å°”æ›¼ï¼Œéå‚æ•°ï¼‰'], key='corr_type')
        corr_type_map = {'pearsonï¼ˆçš®å°”é€Šï¼Œé€‚ç”¨äºæ­£æ€ï¼‰':'pearson', 'spearmanï¼ˆæ–¯çš®å°”æ›¼ï¼Œéå‚æ•°ï¼‰':'spearman'}
        corr_cols = st.multiselect("é€‰æ‹©æ•°å€¼å‹å˜é‡ï¼ˆè‡³å°‘2ä¸ªï¼‰", var_types['numeric'], key='corr_cols')
        if len(corr_cols) < 2:
            st.warning("âš ï¸ è¯·é€‰æ‹©è‡³å°‘2ä¸ªæ•°å€¼å‹å˜é‡")
            st.button("æ‰§è¡Œç›¸å…³åˆ†æ", disabled=True)
        else:
            if st.button("æ‰§è¡Œç›¸å…³åˆ†æï¼ˆå«çƒ­åŠ›å›¾ï¼‰"):
                corr_res = correlation_analysis(df, corr_cols, corr_type_map[corr_type])
                st.subheader("ç›¸å…³ç³»æ•°çŸ©é˜µ")
                st.dataframe(corr_res['ç›¸å…³çŸ©é˜µ'], use_container_width=True)
                st.subheader("på€¼çŸ©é˜µ")
                st.dataframe(corr_res['på€¼çŸ©é˜µ'], use_container_width=True)
                
                fig, ax = plt.subplots(figsize=(10, 8))
                im = ax.imshow(corr_res['ç›¸å…³çŸ©é˜µ'], cmap='RdBu_r', vmin=-1, vmax=1)
                ax.set_xticks(np.arange(len(corr_cols)))
                ax.set_yticks(np.arange(len(corr_cols)))
                ax.set_xticklabels(corr_cols, rotation=45, ha='right')
                ax.set_yticklabels(corr_cols)
                for i in range(len(corr_cols)):
                    for j in range(len(corr_cols)):
                        text = ax.text(j, i, corr_res['ç›¸å…³çŸ©é˜µ'].iloc[i, j], ha="center", va="center", color="black")
                cbar = ax.figure.colorbar(im, ax=ax)
                plt.tight_layout()
                st.pyplot(fig)

    with tab6:
        st.subheader("å›å½’åˆ†æ")
        reg_type = st.selectbox("å›å½’ç±»å‹", ['çº¿æ€§å›å½’', 'äºŒåˆ†ç±»Logisticå›å½’'], key='reg_type')
        reg_target = st.selectbox("å› å˜é‡", var_types['numeric'] if reg_type=='çº¿æ€§å›å½’' else var_types['binary_categorical'], key='reg_target')
        reg_features = st.multiselect("è‡ªå˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", [col for col in var_types['numeric'] if col != reg_target], key='reg_features')
        if st.button("æ‰§è¡Œå›å½’åˆ†æ", disabled=not (reg_target and reg_features)):
            reg_res = regression_analysis(df, reg_target, reg_features, reg_type)
            if 'error' in reg_res:
                st.error(reg_res['error'])
            else:
                if reg_type == 'çº¿æ€§å›å½’':
                    st.write(f"ğŸ“Š æ¨¡å‹æ‹Ÿåˆåº¦ RÂ²ï¼š{reg_res['RÂ²']}")
                else:
                    st.write(f"ğŸ“Š æ¨¡å‹å‡†ç¡®ç‡ï¼š{reg_res['åˆ†ç±»æŠ¥å‘Š']['accuracy']:.3f}")
                st.subheader("ç³»æ•°è¡¨")
                st.dataframe(reg_res['ç³»æ•°è¡¨'], use_container_width=True)

    with tab7:
        st.subheader("å¯è§†åŒ–åˆ†æ")
        plot_type = st.selectbox("å›¾è¡¨ç±»å‹", ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'é¥¼å›¾', 'ç®±å›¾'], key='plot_type')
        if plot_type in ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'ç®±å›¾']:
            x_col = st.selectbox("Xè½´å˜é‡", df.columns, key='plot_x')
            y_col = st.selectbox("Yè½´å˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'], key='plot_y')
            group_col = st.selectbox("åˆ†ç»„å˜é‡ï¼ˆå¯é€‰ï¼‰", [None] + var_types['categorical'], key='plot_group')
        else:
            x_col = st.selectbox("ç±»åˆ«å˜é‡", var_types['categorical'], key='plot_x_pie')
            y_col = st.selectbox("æ•°å€¼å˜é‡ï¼ˆç”¨äºå æ¯”ï¼‰", var_types['numeric'], key='plot_y_pie')
            group_col = None
        if st.button("ç”Ÿæˆå›¾è¡¨"):
            fig = plot_chart(df, plot_type, x_col, y_col, group_col)
            st.plotly_chart(fig, use_container_width=True)

    # ---------------------- æ–°å¢ï¼šæ ‡ç­¾é¡µ8 - AIåˆ†æï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰ ----------------------
    with tab8:
        st.subheader("ğŸ¤– DeepSeek AI æ™ºèƒ½åˆ†æ")
        # å…ˆæ ¡éªŒAPIå¯†é’¥
        if not DEEPSEEK_API_KEY or not DEEPSEEK_API_KEY.startswith("sk-"):
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€å·¦ä¾§è¾¹æ ã€‘è¾“å…¥**æœ‰æ•ˆçš„DeepSeek APIå¯†é’¥**ï¼ˆä»¥sk-å¼€å¤´ï¼‰ï¼Œå†ä½¿ç”¨AIåŠŸèƒ½")
        else:
            st.success("âœ… APIå¯†é’¥å·²é…ç½®ï¼Œå¯ä½¿ç”¨æ‰€æœ‰AIåˆ†æåŠŸèƒ½")
            st.markdown("---")
            # AIåŠŸèƒ½1ï¼šè‡ªåŠ¨æ•°æ®åˆ†æï¼ˆåŸºäºä¸Šä¼ çš„æ•°æ®ï¼Œç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Šï¼‰
            with st.expander("ğŸ“‘ AIè‡ªåŠ¨æ•°æ®åˆ†æï¼ˆç”Ÿæˆå®Œæ•´åˆ†ææŠ¥å‘Šï¼‰", expanded=True):
                st.markdown("åŸºäºä½ çš„æ•°æ®ï¼ŒAIè‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ–¹æ³•ï¼Œç”Ÿæˆ**å¯ç›´æ¥ç”¨äºè®ºæ–‡/æŠ¥å‘Š**çš„åˆ†æç»“æœ")
                if st.button("ğŸš€ å¼€å§‹AIè‡ªåŠ¨åˆ†æ"):
                    with st.spinner("AIæ­£åœ¨åˆ†ææ•°æ®ï¼Œè¯·ç¨å€™..."):
                        # æ„é€ AIæç¤ºè¯ï¼ˆç»“åˆæ•°æ®æ¦‚å†µ+åˆ†æè¦æ±‚ï¼‰
                        prompt = f"""
                        ä½ æ˜¯ä¸€åèµ„æ·±ç»Ÿè®¡åˆ†æå¸ˆï¼Œæ“…é•¿ç§‘ç ”æ•°æ®åˆ†æï¼Œç°åœ¨éœ€è¦å¯¹ä»¥ä¸‹æ•°æ®è¿›è¡Œ**å…¨é¢çš„ç»Ÿè®¡åˆ†æ**ï¼Œè¦æ±‚å¦‚ä¸‹ï¼š
                        1. å…ˆæ€»ç»“æ•°æ®æ¦‚å†µï¼ŒæŒ‡å‡ºæ•°æ®ç‰¹ç‚¹ã€ç¼ºå¤±å€¼æƒ…å†µï¼›
                        2. é€‰æ‹©åˆé€‚çš„ç»Ÿè®¡æ–¹æ³•ï¼ˆå¦‚æè¿°ç»Ÿè®¡ã€ç›¸å…³åˆ†æã€tæ£€éªŒ/æ–¹å·®åˆ†æã€å›å½’åˆ†æç­‰ï¼‰è¿›è¡Œåˆ†æï¼Œéœ€ç»“åˆæ•°æ®ç±»å‹é€‰æ‹©ï¼›
                        3. åˆ†æç»“æœè¦åŒ…å«**ç»Ÿè®¡é‡ã€på€¼ã€ä¸“ä¸šè§£è¯»**ï¼Œé¿å…è¿‡äºä¸“ä¸šçš„æœ¯è¯­ï¼Œå°½é‡é€šä¿—ï¼›
                        4. æœ€åç”Ÿæˆ**åˆ†æç»“è®ºå’Œç ”ç©¶å»ºè®®**ï¼Œé€‚ç”¨äºç§‘ç ”è®ºæ–‡ï¼›
                        5. è¾“å‡ºæ ¼å¼æ¸…æ™°ï¼Œç”¨æ ‡é¢˜ã€åˆ†ç‚¹æ’ç‰ˆï¼Œä¸è¦å†—ä½™å†…å®¹ã€‚

                        æ•°æ®æ¦‚å†µï¼š
                        {data_overview}
                        """
                        # è°ƒç”¨DeepSeek API
                        ai_result = call_deepseek_api(DEEPSEEK_API_KEY, prompt)
                        st.markdown("### AIè‡ªåŠ¨åˆ†æç»“æœ")
                        st.markdown(ai_result)
            
            # AIåŠŸèƒ½2ï¼šç»Ÿè®¡é—®é¢˜é—®ç­”ï¼ˆé’ˆå¯¹æ•°æ®ï¼Œè§£ç­”ä¸ªæ€§åŒ–ç»Ÿè®¡é—®é¢˜ï¼‰
            with st.expander("â“ AIç»Ÿè®¡é—®ç­”ï¼ˆè§£ç­”ä½ çš„ä¸ªæ€§åŒ–é—®é¢˜ï¼‰", expanded=False):
                user_question = st.text_area(
                    "è¯·è¾“å…¥ä½ çš„é—®é¢˜ï¼ˆç»“åˆå½“å‰æ•°æ®ï¼‰",
                    placeholder="ç¤ºä¾‹ï¼š1. åˆ†ædemand_mwå’Œpriceçš„ç›¸å…³æ€§å¹¶è§£è¯»ï¼›2. ç”¨tæ£€éªŒæ¯”è¾ƒä¸¤ç»„æ•°æ®çš„å‡å€¼å·®å¼‚ï¼›3. å¦‚ä½•æ„å»ºçº¿æ€§å›å½’æ¨¡å‹é¢„æµ‹demand_mwï¼Ÿ",
                    height=100
                )
                if st.button("ğŸ’¬ å‘é€é—®é¢˜") and user_question:
                    with st.spinner("AIæ­£åœ¨è§£ç­”ï¼Œè¯·ç¨å€™..."):
                        prompt = f"""
                        ä½ æ˜¯èµ„æ·±ç»Ÿè®¡åˆ†æå¸ˆï¼ŒåŸºäºä»¥ä¸‹æ•°æ®æ¦‚å†µï¼Œè§£ç­”æˆ‘çš„é—®é¢˜ï¼Œè¦æ±‚ï¼š
                        1. ç»“åˆæ•°æ®ç±»å‹ç»™å‡º**å…·ä½“çš„ç»Ÿè®¡æ–¹æ³•å’Œæ“ä½œæ­¥éª¤**ï¼›
                        2. ç»™å‡º**ç»“æœè§£è¯»çš„æ€è·¯**ï¼Œå¦‚æœæ¶‰åŠç»Ÿè®¡é‡éœ€è¯´æ˜åˆ¤æ–­æ ‡å‡†ï¼ˆå¦‚p<0.05ä¸ºæ˜¾è‘—ï¼‰ï¼›
                        3. å›ç­”ç®€æ´æ˜äº†ï¼Œè´´åˆç§‘ç ”æ•°æ®åˆ†æåœºæ™¯ã€‚

                        æ•°æ®æ¦‚å†µï¼š{data_overview}
                        æˆ‘çš„é—®é¢˜ï¼š{user_question}
                        """
                        ai_answer = call_deepseek_api(DEEPSEEK_API_KEY, prompt)
                        st.markdown("### AIè§£ç­”ç»“æœ")
                        st.markdown(ai_answer)
            
            # AIåŠŸèƒ½3ï¼šåˆ†æç»“æœè§£è¯»ï¼ˆç²˜è´´å…¶ä»–åˆ†æç»“æœï¼Œè®©AIè§£è¯»ï¼‰
            with st.expander("ğŸ“ˆ AIç»“æœè§£è¯»ï¼ˆè§£è¯»å·²æœ‰ç»Ÿè®¡ç»“æœï¼‰", expanded=False):
                user_result = st.text_area(
                    "ç²˜è´´ä½ çš„ç»Ÿè®¡åˆ†æç»“æœï¼ˆå¦‚å¡æ–¹æ£€éªŒp=0.02ï¼ŒRÂ²=0.85ç­‰ï¼‰",
                    placeholder="ç¤ºä¾‹ï¼š1. ç›¸å…³åˆ†æï¼šdemand_mwå’Œpriceçš„çš®å°”é€Šç›¸å…³ç³»æ•°ä¸º0.78ï¼Œp=0.001ï¼›2. çº¿æ€§å›å½’RÂ²=0.82ï¼Œp<0.001ï¼›3. ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒt=2.35ï¼Œp=0.02",
                    height=100
                )
                if st.button("ğŸ” è§£è¯»ç»“æœ") and user_result:
                    with st.spinner("AIæ­£åœ¨è§£è¯»ï¼Œè¯·ç¨å€™..."):
                        prompt = f"""
                        ä½ æ˜¯èµ„æ·±ç»Ÿè®¡åˆ†æå¸ˆï¼Œè´Ÿè´£è§£è¯»ç§‘ç ”æ•°æ®åˆ†æç»“æœï¼Œè¦æ±‚ï¼š
                        1. å¯¹æ¯ä¸ªç»Ÿè®¡ç»“æœè¿›è¡Œ**ä¸“ä¸šè§£è¯»**ï¼Œè¯´æ˜ç»Ÿè®¡æ„ä¹‰ï¼ˆå¦‚p<0.05ä»£è¡¨ä»€ä¹ˆï¼‰ï¼›
                        2. ç»“åˆæ•°æ®åˆ†æ**å®é™…ç ”ç©¶æ„ä¹‰**ï¼Œé¿å…çº¯ç†è®ºè§£è¯»ï¼›
                        3. è¾“å‡ºæ ¼å¼æ¸…æ™°ï¼Œåˆ†ç‚¹å¯¹åº”æˆ‘çš„è¾“å…¥å†…å®¹ã€‚

                        æˆ‘çš„ç»Ÿè®¡ç»“æœï¼š{user_result}
                        æ•°æ®æ¦‚å†µï¼š{data_overview}
                        """
                        ai_interpret = call_deepseek_api(DEEPSEEK_API_KEY, prompt)
                        st.markdown("### AIç»“æœè§£è¯»")
                        st.markdown(ai_interpret)

# æ— æ•°æ®æ—¶çš„æç¤º
else:
    st.info("ğŸ’¡ è¯·åœ¨ã€å·¦ä¾§è¾¹æ ã€‘ä¸Šä¼ CSV/Excelæ•°æ®æ–‡ä»¶ï¼Œå³å¯å¼€å§‹åˆ†æ")
    st.markdown("#### ğŸ“Œ åŠŸèƒ½è¯´æ˜")
    st.markdown("- åŒ…å«SPSSæ ¸å¿ƒç»Ÿè®¡åˆ†æåŠŸèƒ½ï¼Œæ“ä½œæ¯”SPSSæ›´ç®€æ˜“")
    st.markdown("- æ¥å…¥DeepSeek AIï¼Œæ”¯æŒ**è‡ªåŠ¨åˆ†æã€ç»Ÿè®¡é—®ç­”ã€ç»“æœè§£è¯»**")
    st.markdown("- æ‰€æœ‰åˆ†æç»“æœå¯ç›´æ¥å¤åˆ¶ï¼Œæ”¯æŒç”Ÿæˆå¯è§†åŒ–å›¾è¡¨")
