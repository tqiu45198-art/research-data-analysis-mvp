import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
import warnings
import io
import re
from datetime import datetime
from openai import OpenAI

warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
st.set_page_config(page_title="ç§‘ç ”æ•°æ®åˆ†æå¹³å°", page_icon="ğŸ“Š", layout="wide", initial_sidebar_state="expanded")

try:
    from scipy.stats import chi2_contingency, ttest_1samp, ttest_ind, ttest_rel, ks_2samp, mannwhitneyu, kruskal, friedmanchisquare, wilcoxon
    from statsmodels.stats.proportion import binom_test as sm_binom_test
    from statsmodels.formula.api import ols
    from statsmodels.stats.anova import anova_lm
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.linear_model import LinearRegression, LogisticRegression
    from sklearn.metrics import r2_score, classification_report
except ImportError as e:
    st.error(f"åˆ†æåº“å¯¼å…¥å¤±è´¥ï¼š{e}")

def call_deepseek_api(prompt, model="deepseek-chat", temperature=0.2):
    if "DEEPSEEK_API_KEY" not in st.secrets:
        return iter(["âŒ æœªé…ç½®APIå¯†é’¥ï¼šè¯·åœ¨Streamlit Cloud â†’ Settings â†’ Secretsä¸­æ·»åŠ  DEEPSEEK_API_KEY = 'ä½ çš„å¯†é’¥'"])
    api_key = st.secrets["DEEPSEEK_API_KEY"]
    try:
        client = OpenAI(
            api_key=api_key,
            base_url="https://api.deepseek.com/v1"
        )
    except Exception as e:
        return iter([f"âŒ å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}"])
    try:
        response = client.chat.completions.create(
            model=model,
            messages=[{"role": "user", "content": prompt}],
            temperature=temperature,
            max_tokens=3072,
            stream=True
        )
        def stream_generator():
            for chunk in response:
                if chunk.choices[0].delta.content:
                    yield chunk.choices[0].delta.content
        return stream_generator()
    except client.BadRequestError as e:
        if "model_not_found" in str(e):
            return iter(["âŒ æ¨¡å‹ä¸å­˜åœ¨ï¼šä¸»æµæ¨¡å‹ä¸º deepseek-chat / deepseek-reasoner"])
        return iter([f"âŒ è¯·æ±‚å‚æ•°é”™è¯¯ï¼š{str(e)}"])
    except client.UnauthorizedError:
        return iter(["âŒ APIå¯†é’¥æ— æ•ˆï¼šè¯·æ£€æŸ¥å¯†é’¥æ˜¯å¦æ­£ç¡®/æœªè¿‡æœŸ"])
    except client.ServiceUnavailableError:
        return iter(["âŒ DeepSeekæœåŠ¡å™¨ç¹å¿™ï¼šå»ºè®®ç¨åé‡è¯•"])
    except TimeoutError:
        return iter(["âŒ ç½‘ç»œè¶…æ—¶ï¼šå»ºè®®ç¨åé‡è¯•"])
    except Exception as e:
        return iter([f"âŒ APIè°ƒç”¨å¤±è´¥ï¼š{str(e)}"])

def load_and_clean_data(file):
    encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312']
    seps = [',', '\t', ';']
    try:
        file_content = file.read()
        file.seek(0)
        df = None
        if file.name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        break
                    except:
                        continue
                if df is not None:
                    break
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
        df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

def identify_variable_types(df):
    numeric_cols = []
    categorical_cols = []
    binary_categorical_cols = []
    datetime_cols = []
    for col in df.columns:
        if any(fmt in col.lower() for fmt in ['date', 'time', '2016', '2017', '2018', '2019', '2020']):
            try:
                df[col] = pd.to_datetime(df[col])
                datetime_cols.append(col)
                continue
            except:
                pass
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            numeric_cols.append(col)
        except:
            categorical_cols.append(col)
            if df[col].nunique() == 2:
                binary_categorical_cols.append(col)
    return {'numeric': numeric_cols, 'categorical': categorical_cols, 'binary_categorical': binary_categorical_cols, 'datetime': datetime_cols}

def frequency_analysis(df, categorical_cols):
    freq_dict = {}
    for col in categorical_cols:
        freq = df[col].value_counts()
        freq_pct = df[col].value_counts(normalize=True) * 100
        freq_df = pd.DataFrame({'é¢‘æ•°': freq, 'é¢‘ç‡(%)': freq_pct.round(2)})
        freq_dict[col] = freq_df
    return freq_dict

def descriptive_analysis(df, numeric_cols):
    desc_df = df[numeric_cols].describe().T
    desc_df['ç¼ºå¤±å€¼'] = df[numeric_cols].isnull().sum()
    desc_df['ç¼ºå¤±ç‡(%)'] = (desc_df['ç¼ºå¤±å€¼'] / len(df) * 100).round(2)
    desc_df['ååº¦'] = df[numeric_cols].skew().round(3)
    desc_df['å³°åº¦'] = df[numeric_cols].kurt().round(3)
    return desc_df

def contingency_table_analysis(df, col1, col2):
    cont_table = pd.crosstab(df[col1], df[col2])
    chi2, p, dof, expected = chi2_contingency(cont_table)
    cramers_v = np.sqrt(chi2 / (len(df) * min(cont_table.shape[0]-1, cont_table.shape[1]-1)))
    return {'è”åˆ—è¡¨': cont_table, 'å¡æ–¹å€¼': chi2.round(3), 'på€¼': p.round(4), 'è‡ªç”±åº¦': dof, 'å…‹è±å§†Vç³»æ•°': cramers_v.round(3)}

def t_test_onesample(df, numeric_col, popmean):
    data = df[numeric_col].dropna()
    t_stat, p_value = ttest_1samp(data, popmean)
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), 'å‡å€¼': data.mean().round(2), 'æ ·æœ¬é‡': len(data)}

def t_test_independent(df, numeric_col, group_col):
    groups = df[group_col].unique()
    if len(groups) != 2:
        return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
    group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
    group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
    t_stat, p_value = ttest_ind(group1, group2, equal_var=False)
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), f'{groups[0]}å‡å€¼': group1.mean().round(2), f'{groups[1]}å‡å€¼': group2.mean().round(2), f'{groups[0]}æ ·æœ¬é‡': len(group1), f'{groups[1]}æ ·æœ¬é‡': len(group2)}

def nonparametric_test(df, test_type, numeric_col, group_col=None):
    if test_type == 'å•æ ·æœ¬K-Sæ£€éªŒ':
        data = df[numeric_col].dropna()
        ks_stat, p_value = stats.kstest(data, 'norm', args=(data.mean(), data.std()))
        return {'KSç»Ÿè®¡é‡': ks_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ':
        groups = df[group_col].unique()
        if len(groups) != 2:
            return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
        group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
        group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
        u_stat, p_value = mannwhitneyu(group1, group2)
        return {'Uå€¼': u_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ':
        data = df[numeric_col].dropna()
        success = sum(data == 1)
        n = len(data)
        p_value = sm_binom_test(success, n, prop=0.5)
        return {'æˆåŠŸæ¬¡æ•°': success, 'æ€»æ¬¡æ•°': n, 'på€¼': p_value.round(4)}
    return {'error': 'æ— æ•ˆæ£€éªŒç±»å‹'}

def anova_analysis(df, formula, anova_type):
    model = ols(formula, data=df).fit()
    anova_result = anova_lm(model, typ=2)
    tukey = pairwise_tukeyhsd(df[formula.split('~')[0]], df[formula.split('~')[1].split('+')[0]], alpha=0.05)
    return {'æ–¹å·®åˆ†æè¡¨': anova_result, 'äº‹åæ£€éªŒ(Tukey)': tukey.summary()}

def correlation_analysis(df, cols, corr_type='pearson'):
    corr_df = df[cols].dropna()
    if corr_type == 'pearson':
        corr_matrix = corr_df.corr(method='pearson')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.pearsonr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    elif corr_type == 'spearman':
        corr_matrix = corr_df.corr(method='spearman')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.spearmanr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    return {'ç›¸å…³çŸ©é˜µ': corr_matrix.round(3), 'på€¼çŸ©é˜µ': p_matrix}

def regression_analysis(df, target, features, reg_type):
    X = df[features].dropna()
    y = df[target][X.index].dropna()
    X = X.loc[y.index]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    if reg_type == 'çº¿æ€§å›å½’':
        model = LinearRegression().fit(X_scaled, y)
        y_pred = model.predict(X_scaled)
        r2 = r2_score(y, y_pred)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_.round(3), 'æˆªè·': [model.intercept_.round(3)]*len(features)})
        return {'RÂ²': r2.round(3), 'ç³»æ•°è¡¨': coef}
    elif reg_type == 'äºŒåˆ†ç±»Logisticå›å½’':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        model = LogisticRegression(max_iter=1000).fit(X_scaled, y_encoded)
        y_pred = model.predict(X_scaled)
        report = classification_report(y_encoded, y_pred, output_dict=True)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_[0].round(3), 'æˆªè·': [model.intercept_[0].round(3)]*len(features)})
        return {'åˆ†ç±»æŠ¥å‘Š': report, 'ç³»æ•°è¡¨': coef}
    return {'error': 'æ— æ•ˆå›å½’ç±»å‹'}

def cluster_analysis(df, cols, n_clusters=3):
    X = df[cols].dropna()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_scaled)
    df_cluster = X.copy()
    df_cluster['èšç±»ç»“æœ'] = kmeans.labels_
    centroids = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=cols).round(2)
    return {'èšç±»ç»“æœ': df_cluster, 'èšç±»ä¸­å¿ƒ': centroids}

def plot_chart(df, plot_type, x_col, y_col=None, group_col=None):
    if plot_type == 'æ¡å½¢å›¾':
        fig = px.bar(df, x=x_col, y=y_col, color=group_col, barmode='group', title=f'{x_col} - {y_col}')
    elif plot_type == 'æŠ˜çº¿å›¾':
        fig = px.line(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col}')
    elif plot_type == 'é¥¼å›¾':
        fig = px.pie(df, names=x_col, values=y_col, title=f'{x_col} åˆ†å¸ƒ')
    elif plot_type == 'ç®±å›¾':
        fig = px.box(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col} åˆ†å¸ƒ')
    fig.update_layout(width=800, height=500)
    return fig

st.title("ç§‘ç ”æ•°æ®åˆ†æå¹³å°")
st.divider()

with st.sidebar:
    st.markdown("## ğŸ“¥ æ•°æ®ä¸Šä¼ ")
    uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ï¼ˆCSV/Excelï¼Œæ”¯æŒå¤šæ–‡ä»¶ï¼‰", type=["xlsx", "csv"], accept_multiple_files=True)
    df = None
    var_types = None
    if uploaded_files:
        selected_file_names = st.multiselect("é€‰æ‹©åˆ†ææ–‡ä»¶", [f.name for f in uploaded_files], default=[uploaded_files[0].name])
        selected_files = [f for f in uploaded_files if f.name in selected_file_names]
        
        df_dict = {}
        for file in selected_files:
            df_temp = load_and_clean_data(file)
            if df_temp is not None:
                df_dict[file.name] = df_temp
                st.success(f"{file.name} ä¸Šä¼ æˆåŠŸ ({len(df_temp)}è¡ŒÃ—{len(df_temp.columns)}åˆ—)")
        
        if len(df_dict) >= 2:
            base_file = st.selectbox("åŸºç¡€æ–‡ä»¶", list(df_dict.keys()))
            df = df_dict[base_file]
            for other_file in [f for f in df_dict.keys() if f != base_file]:
                df_other = df_dict[other_file]
                common_cols = [col for col in df.columns if col in df_other.columns]
                base_key = st.selectbox(f"åŸºç¡€å…³è”å­—æ®µ", common_cols if common_cols else df.columns, key=f"base_{other_file}")
                join_key = st.selectbox(f"å…³è”å­—æ®µ", common_cols if common_cols else df_other.columns, key=f"join_{other_file}")
                join_type = st.selectbox(f"åˆå¹¶æ–¹å¼", ['å·¦è¿æ¥', 'å³è¿æ¥', 'å†…è¿æ¥', 'å¤–è¿æ¥'], key=f"type_{other_file}")
                join_map = {'å·¦è¿æ¥':'left', 'å³è¿æ¥':'right', 'å†…è¿æ¥':'inner', 'å¤–è¿æ¥':'outer'}
                if st.button(f"åˆå¹¶{other_file}", key=f"btn_{other_file}"):
                    df = pd.merge(df, df_other, left_on=base_key, right_on=join_key, how=join_map[join_type], suffixes=("", f"_{other_file.split('.')[0]}"))
                    st.success(f"åˆå¹¶åï¼š{len(df)}è¡ŒÃ—{len(df.columns)}åˆ—")
        else:
            df = df_dict[list(df_dict.keys())[0]] if df_dict else None
        
        if df is not None:
            var_types = identify_variable_types(df)
            st.markdown("## ğŸ“Š æ•°æ®æ¦‚å†µ")
            st.write(f"è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            st.write(f"æ•°å€¼å‹å˜é‡ï¼š{len(var_types['numeric'])}ä¸ª")
            st.write(f"åˆ†ç±»å‹å˜é‡ï¼š{len(var_types['categorical'])}ä¸ª")

if df is not None and var_types is not None:
    data_overview = f"""æœ¬æ¬¡åˆ†ææ•°æ®æ¦‚å†µï¼š1.æ•°æ®è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ— 2.æ•°å€¼å‹å˜é‡ï¼š{', '.join(var_types['numeric']) if var_types['numeric'] else 'æ— '} 3.åˆ†ç±»å‹å˜é‡ï¼š{', '.join(var_types['categorical']) if var_types['categorical'] else 'æ— '} 4.äºŒåˆ†ç±»å˜é‡ï¼š{', '.join(var_types['binary_categorical']) if var_types['binary_categorical'] else 'æ— '} 5.ç¼ºå¤±å€¼æ€»æ•°ï¼š{df.isnull().sum().sum()}ä¸ªï¼Œæ•´ä½“ç¼ºå¤±ç‡ï¼š{(df.isnull().sum().sum()/(df.shape[0]*df.shape[1]))*100:.2f}%"""
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8 = st.tabs(["æ•°æ®å¤„ç†", "åŸºæœ¬ç»Ÿè®¡", "å‡å€¼æ£€éªŒ", "æ–¹å·®åˆ†æ", "ç›¸å…³åˆ†æ", "å›å½’åˆ†æ", "å¯è§†åŒ–", "AIåˆ†æ"])

    with tab1:
        st.subheader("æ•°æ®å¤„ç†")
        sort_col = st.selectbox("æ’åºå­—æ®µ", df.columns, key='sort')
        sort_asc = st.radio("æ’åºæ–¹å¼", ['å‡åº', 'é™åº'], key='sort_asc')
        if st.button("æ‰§è¡Œæ’åº"):
            df_sorted = df.sort_values(by=sort_col, ascending=(sort_asc=='å‡åº'))
            st.dataframe(df_sorted.head(10), use_container_width=True)
        
        filter_col = st.selectbox("ç­›é€‰å­—æ®µ", df.columns, key='filter')
        filter_op = st.selectbox("è¿ç®—ç¬¦", ['>', '<', '>=', '<=', '==', '!='], key='filter_op')
        filter_val = st.text_input("ç­›é€‰å€¼", key='filter_val')
        if st.button("æ‰§è¡Œç­›é€‰"):
            try:
                if df[filter_col].dtype in [np.int64, np.float64]:
                    filter_val = float(filter_val)
                df_filtered = df.query(f"`{filter_col}` {filter_op} {filter_val}")
                st.success(f"ç­›é€‰åï¼š{len(df_filtered)}è¡Œ")
                st.dataframe(df_filtered.head(10), use_container_width=True)
            except:
                st.error("ç­›é€‰æ¡ä»¶é”™è¯¯ï¼Œè¯·æ£€æŸ¥å€¼çš„ç±»å‹")
        
        group_col = st.selectbox("åˆ†ç»„å­—æ®µ", var_types['categorical'], key='group', disabled=not var_types['categorical'])
        agg_col = st.selectbox("æ±‡æ€»å­—æ®µ", var_types['numeric'], key='agg', disabled=not var_types['numeric'])
        agg_func = st.selectbox("æ±‡æ€»æ–¹å¼", ['å‡å€¼', 'æ±‚å’Œ', 'è®¡æ•°', 'æœ€å¤§å€¼', 'æœ€å°å€¼'], key='agg_func')
        agg_map = {'å‡å€¼':'mean', 'æ±‚å’Œ':'sum', 'è®¡æ•°':'count', 'æœ€å¤§å€¼':'max', 'æœ€å°å€¼':'min'}
        if st.button("æ‰§è¡Œåˆ†ç±»æ±‡æ€»", disabled=not (group_col and agg_col)):
            df_agg = df.groupby(group_col)[agg_col].agg(agg_map[agg_func]).round(2)
            st.dataframe(df_agg, use_container_width=True)

    with tab2:
        st.subheader("åŸºæœ¬ç»Ÿè®¡")
        freq_cols = st.multiselect("é€‰æ‹©åˆ†ç±»å‹å˜é‡", var_types['categorical'], key='freq')
        if freq_cols and st.button("æ‰§è¡Œé¢‘æ•°åˆ†æ"):
            freq_dict = frequency_analysis(df, freq_cols)
            for col in freq_cols:
                st.subheader(col)
                st.dataframe(freq_dict[col], use_container_width=True)
        
        desc_cols = st.multiselect("é€‰æ‹©æ•°å€¼å‹å˜é‡", var_types['numeric'], key='desc')
        if desc_cols and st.button("æ‰§è¡Œæè¿°ç»Ÿè®¡"):
            desc_df = descriptive_analysis(df, desc_cols)
            st.dataframe(desc_df, use_container_width=True)
        
        if len(var_types['categorical'])>=2:
            cont_col1 = st.selectbox("è¡Œå˜é‡", var_types['categorical'], key='cont1')
            cont_col2 = st.selectbox("åˆ—å˜é‡", var_types['categorical'], key='cont2')
            if st.button("æ‰§è¡Œè”åˆ—è¡¨+å¡æ–¹æ£€éªŒ"):
                cont_res = contingency_table_analysis(df, cont_col1, cont_col2)
                st.subheader("è”åˆ—è¡¨")
                st.dataframe(cont_res['è”åˆ—è¡¨'], use_container_width=True)
                st.write(f"å¡æ–¹å€¼ï¼š{cont_res['å¡æ–¹å€¼']} | på€¼ï¼š{cont_res['på€¼']} | è‡ªç”±åº¦ï¼š{cont_res['è‡ªç”±åº¦']} | å…‹è±å§†Vç³»æ•°ï¼š{cont_res['å…‹è±å§†Vç³»æ•°']}")

    with tab3:
        st.subheader("å‡å€¼æ£€éªŒ")
        onesamp_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='onesamp', disabled=not var_types['numeric'])
        popmean = st.number_input("æ€»ä½“å‡å€¼", value=0.0, key='popmean')
        if st.button("æ‰§è¡Œå•æ ·æœ¬tæ£€éªŒ", disabled=not onesamp_col):
            onesamp_res = t_test_onesample(df, onesamp_col, popmean)
            st.write(f"tå€¼ï¼š{onesamp_res['tå€¼']} | på€¼ï¼š{onesamp_res['på€¼']} | æ ·æœ¬å‡å€¼ï¼š{onesamp_res['å‡å€¼']} | æ ·æœ¬é‡ï¼š{onesamp_res['æ ·æœ¬é‡']}")
        
        ind_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='ind', disabled=not var_types['numeric'])
        ind_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='ind_group', disabled=not var_types['categorical'])
        if st.button("æ‰§è¡Œä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ", disabled=not (ind_col and ind_group)):
            ind_res = t_test_independent(df, ind_col, ind_group)
            if 'error' in ind_res:
                st.error(ind_res['error'])
            else:
                st.write(f"tå€¼ï¼š{ind_res['tå€¼']} | på€¼ï¼š{ind_res['på€¼']}")
                st.write(f"{list(ind_res.keys())[2]}ï¼š{ind_res[list(ind_res.keys())[2]]} | {list(ind_res.keys())[3]}ï¼š{ind_res[list(ind_res.keys())[3]]}")
        
        test_type = st.selectbox("éå‚æ•°æ£€éªŒç±»å‹", ['å•æ ·æœ¬K-Sæ£€éªŒ', 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ', 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ'], key='test_type')
        np_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='np', disabled=not var_types['numeric'])
        np_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='np_group', disabled=test_type not in ['ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ'])
        if st.button("æ‰§è¡Œéå‚æ•°æ£€éªŒ", disabled=not np_col):
            np_res = nonparametric_test(df, test_type, np_col, np_group)
            if 'error' in np_res:
                st.error(np_res['error'])
            else:
                for k, v in np_res.items():
                    st.write(f"{k}ï¼š{v}")

    with tab4:
        st.subheader("æ–¹å·®åˆ†æ")
        if var_types['numeric'] and var_types['categorical']:
            anova_target = st.selectbox("å› å˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'], key='anova_target')
            anova_factor = st.selectbox("å› ç´ å˜é‡ï¼ˆåˆ†ç±»å‹ï¼‰", var_types['categorical'], key='anova_factor')
            formula = f"{anova_target} ~ C({anova_factor})"
            if st.button("æ‰§è¡Œå•å› ç´ æ–¹å·®åˆ†æ+Tukeyäº‹åæ£€éªŒ"):
                anova_res = anova_analysis(df, formula, 'å•å› ç´ æ–¹å·®åˆ†æ')
                st.subheader("æ–¹å·®åˆ†æè¡¨")
                st.dataframe(anova_res['æ–¹å·®åˆ†æè¡¨'], use_container_width=True)
                st.subheader("Tukeyäº‹åæ£€éªŒç»“æœ")
                st.text(anova_res['äº‹åæ£€éªŒ(Tukey)'])

    with tab5:
        st.subheader("ç›¸å…³åˆ†æ")
        corr_type = st.selectbox("ç›¸å…³ç³»æ•°ç±»å‹", ['pearsonï¼ˆçš®å°”é€Šï¼Œé€‚ç”¨äºæ­£æ€ï¼‰', 'spearmanï¼ˆæ–¯çš®å°”æ›¼ï¼Œéå‚æ•°ï¼‰'], key='corr_type')
        corr_type_map = {'pearsonï¼ˆçš®å°”é€Šï¼Œé€‚ç”¨äºæ­£æ€ï¼‰':'pearson', 'spearmanï¼ˆæ–¯çš®å°”æ›¼ï¼Œéå‚æ•°ï¼‰':'spearman'}
        corr_cols = st.multiselect("é€‰æ‹©æ•°å€¼å‹å˜é‡ï¼ˆè‡³å°‘2ä¸ªï¼‰", var_types['numeric'], key='corr_cols')
        if len(corr_cols) < 2:
            st.warning("âš ï¸ è¯·é€‰æ‹©è‡³å°‘2ä¸ªæ•°å€¼å‹å˜é‡")
            st.button("æ‰§è¡Œç›¸å…³åˆ†æï¼ˆå«çƒ­åŠ›å›¾ï¼‰", disabled=True)
        else:
            if st.button("æ‰§è¡Œç›¸å…³åˆ†æï¼ˆå«çƒ­åŠ›å›¾ï¼‰"):
                corr_res = correlation_analysis(df, corr_cols, corr_type_map[corr_type])
                st.subheader("ç›¸å…³ç³»æ•°çŸ©é˜µ")
                st.dataframe(corr_res['ç›¸å…³çŸ©é˜µ'], use_container_width=True)
                st.subheader("på€¼çŸ©é˜µ")
                st.dataframe(corr_res['på€¼çŸ©é˜µ'], use_container_width=True)
                
                fig, ax = plt.subplots(figsize=(10, 8))
                im = ax.imshow(corr_res['ç›¸å…³çŸ©é˜µ'], cmap='RdBu_r', vmin=-1, vmax=1)
                ax.set_xticks(np.arange(len(corr_cols)))
                ax.set_yticks(np.arange(len(corr_cols)))
                ax.set_xticklabels(corr_cols, rotation=45, ha='right')
                ax.set_yticklabels(corr_cols)
                for i in range(len(corr_cols)):
                    for j in range(len(corr_cols)):
                        text = ax.text(j, i, corr_res['ç›¸å…³çŸ©é˜µ'].iloc[i, j], ha="center", va="center", color="black")
                cbar = ax.figure.colorbar(im, ax=ax)
                plt.tight_layout()
                st.pyplot(fig)

    with tab6:
        st.subheader("å›å½’åˆ†æ")
        reg_type = st.selectbox("å›å½’ç±»å‹", ['çº¿æ€§å›å½’', 'äºŒåˆ†ç±»Logisticå›å½’'], key='reg_type')
        reg_target = st.selectbox("å› å˜é‡", var_types['numeric'] if reg_type=='çº¿æ€§å›å½’' else var_types['binary_categorical'], key='reg_target')
        reg_features = st.multiselect("è‡ªå˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", [col for col in var_types['numeric'] if col != reg_target], key='reg_features')
        if st.button("æ‰§è¡Œå›å½’åˆ†æ", disabled=not (reg_target and reg_features)):
            reg_res = regression_analysis(df, reg_target, reg_features, reg_type)
            if 'error' in reg_res:
                st.error(reg_res['error'])
            else:
                if reg_type == 'çº¿æ€§å›å½’':
                    st.write(f"ğŸ“Š æ¨¡å‹æ‹Ÿåˆåº¦ RÂ²ï¼š{reg_res['RÂ²']}")
                else:
                    st.write(f"ğŸ“Š æ¨¡å‹å‡†ç¡®ç‡ï¼š{reg_res['åˆ†ç±»æŠ¥å‘Š']['accuracy']:.3f}")
                st.subheader("ç³»æ•°è¡¨")
                st.dataframe(reg_res['ç³»æ•°è¡¨'], use_container_width=True)

    with tab7:
        st.subheader("å¯è§†åŒ–åˆ†æ")
        plot_type = st.selectbox("å›¾è¡¨ç±»å‹", ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'é¥¼å›¾', 'ç®±å›¾'], key='plot_type')
        if plot_type in ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'ç®±å›¾']:
            x_col = st.selectbox("Xè½´å˜é‡", df.columns, key='plot_x')
            y_col = st.selectbox("Yè½´å˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'], key='plot_y')
            group_col = st.selectbox("åˆ†ç»„å˜é‡ï¼ˆå¯é€‰ï¼‰", [None] + var_types['categorical'], key='plot_group')
        else:
            x_col = st.selectbox("ç±»åˆ«å˜é‡", var_types['categorical'], key='plot_x_pie')
            y_col = st.selectbox("æ•°å€¼å˜é‡ï¼ˆç”¨äºå æ¯”ï¼‰", var_types['numeric'], key='plot_y_pie')
            group_col = None
        if st.button("ç”Ÿæˆå›¾è¡¨"):
            fig = plot_chart(df, plot_type, x_col, y_col, group_col)
            st.plotly_chart(fig, use_container_width=True)

    with tab8:
        st.subheader("ğŸ¤– AI æ™ºèƒ½åˆ†æï¼ˆå›¾æ–‡åµŒæ’+å›ºå®šæ ¼å¼ï¼‰")
        if "DEEPSEEK_API_KEY" not in st.secrets:
            st.warning("âš ï¸ è¯·å…ˆåœ¨ã€Streamlit Cloud â†’ Settings â†’ Secretsã€‘ä¸­é…ç½®ï¼šDEEPSEEK_API_KEY = 'ä½ çš„sk-å¼€å¤´å¯†é’¥'")
        else:
            st.success("âœ… APIå¯†é’¥å·²é…ç½®ï¼ŒAIè¾“å‡ºå›¾æ–‡åµŒæ’+å›ºå®šç»Ÿä¸€æ ¼å¼åˆ†ææŠ¥å‘Š")
            st.markdown("---")
            with st.expander("ğŸ“‘ AIè‡ªåŠ¨æ•°æ®åˆ†æï¼ˆæ ¸å¿ƒåŠŸèƒ½ï¼‰", expanded=True):
                if st.button("ğŸš€ å¼€å§‹AIè‡ªåŠ¨åˆ†æ"):
                    with st.spinner("æ­£åœ¨é¢„å¤„ç†ç»Ÿè®¡ç»“æœ+ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨ï¼Œè¯·ç¨å€™..."):
                        desc_res = descriptive_analysis(df, var_types['numeric']) if var_types['numeric'] else "æ— æ•°å€¼å‹å˜é‡"
                        desc_text = desc_res.to_string() if var_types['numeric'] else "æ— æ•°å€¼å‹å˜é‡"
                        corr_res = correlation_analysis(df, var_types['numeric'], 'pearson') if len(var_types['numeric'])>=2 else "æ•°å€¼å‹å˜é‡ä¸è¶³2ä¸ª"
                        corr_text = corr_res['ç›¸å…³çŸ©é˜µ'].to_string() if len(var_types['numeric'])>=2 else "æ•°å€¼å‹å˜é‡ä¸è¶³2ä¸ª"
                        freq_res = frequency_analysis(df, var_types['categorical']) if var_types['categorical'] else "æ— åˆ†ç±»å‹å˜é‡"
                        freq_text = ""
                        if var_types['categorical']:
                            for col in var_types['categorical']:
                                freq_text += f"{col}ï¼š{freq_res[col].to_string()}\n"
                        else:
                            freq_text = "æ— åˆ†ç±»å‹å˜é‡"
                        ttest_text = "æ— ç¬¦åˆæ¡ä»¶çš„äºŒåˆ†ç±»å˜é‡ï¼Œæœªæ‰§è¡Œå‡å€¼æ£€éªŒ"
                        if var_types['binary_categorical'] and var_types['numeric']:
                            group_col = var_types['binary_categorical'][0]
                            test_col = var_types['numeric'][0]
                            ttest_res = t_test_independent(df, test_col, group_col)
                            if 'error' not in ttest_res:
                                ttest_text = f"ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆ{test_col}æŒ‰{group_col}åˆ†ç»„ï¼‰ï¼štå€¼={ttest_res['tå€¼']}ï¼Œpå€¼={ttest_res['på€¼']}ï¼Œ{list(ttest_res.keys())[2]}={ttest_res[list(ttest_res.keys())[2]]}ï¼Œ{list(ttest_res.keys())[3]}={ttest_res[list(ttest_res.keys())[3]]}"

                        chart_data = {}
                        try:
                            if len(var_types['numeric'])>=2:
                                fig_corr, ax_corr = plt.subplots(figsize=(10, 8))
                                im_corr = ax_corr.imshow(corr_res['ç›¸å…³çŸ©é˜µ'], cmap='RdBu_r', vmin=-1, vmax=1)
                                ax_corr.set_xticks(np.arange(len(var_types['numeric'])))
                                ax_corr.set_yticks(np.arange(len(var_types['numeric'])))
                                ax_corr.set_xticklabels(var_types['numeric'], rotation=45, ha='right')
                                ax_corr.set_yticklabels(var_types['numeric'])
                                for i in range(len(var_types['numeric'])):
                                    for j in range(len(var_types['numeric'])):
                                        text = ax_corr.text(j, i, corr_res['ç›¸å…³çŸ©é˜µ'].iloc[i, j], ha="center", va="center", color="black")
                                cbar_corr = ax_corr.figure.colorbar(im_corr, ax=ax_corr)
                                plt.tight_layout()
                                chart_data['å›¾1'] = {'fig': fig_corr, 'type': 'matplotlib', 'name': 'æ•°å€¼å˜é‡ç›¸å…³çƒ­åŠ›å›¾', 'desc': 'å±•ç¤ºå„æ•°å€¼å‹å˜é‡é—´çš®å°”é€Šç›¸å…³ç³»æ•°çš„å¼ºå¼±ä¸æ­£è´Ÿç›¸å…³æ–¹å‘ï¼Œç³»æ•°è¶Šæ¥è¿‘1/ -1è¡¨ç¤ºç›¸å…³æ€§è¶Šå¼ºï¼Œ0è¡¨ç¤ºæ— çº¿æ€§ç›¸å…³'}
                        except Exception as e:
                            pass

                        try:
                            if len(var_types['numeric'])>=2:
                                num1, num2 = var_types['numeric'][0], var_types['numeric'][1]
                                fig_line = px.line(df.head(1000), x=df.head(1000).index, y=[num1, num2], title=f"{num1}ä¸{num2}è¶‹åŠ¿å˜åŒ–å¯¹æ¯”", width=800, height=400)
                                chart_data['å›¾2'] = {'fig': fig_line, 'type': 'plotly', 'name': f'{num1}ä¸{num2}è¶‹åŠ¿æŠ˜çº¿å›¾', 'desc': f'å±•ç¤º{num1}å’Œ{num2}å‰1000æ¡æ•°æ®çš„æ—¶é—´åºåˆ—è¶‹åŠ¿å˜åŒ–ï¼Œå¯ç›´è§‚å¯¹æ¯”ä¸¤è€…çš„æ³¢åŠ¨è§„å¾‹ä¸å˜åŒ–ä¸€è‡´æ€§'}
                        except Exception as e:
                            pass

                        try:
                            if var_types['categorical']:
                                cat_col = var_types['categorical'][0]
                                freq_df = freq_res[cat_col].reset_index().rename(columns={'index': cat_col})
                                fig_bar = px.bar(freq_df, x=cat_col, y='é¢‘æ•°', title=f"{cat_col}é¢‘æ•°åˆ†å¸ƒ", width=800, height=400, text_auto=True)
                                chart_data['å›¾3'] = {'fig': fig_bar, 'type': 'plotly', 'name': f'{cat_col}é¢‘æ•°åˆ†å¸ƒæ¡å½¢å›¾', 'desc': f'å±•ç¤ºåˆ†ç±»å‹å˜é‡{cat_col}å„ç±»å‹çš„é¢‘æ•°ä¸å æ¯”æƒ…å†µï¼Œå¯ç›´è§‚åˆ¤æ–­è¯¥å˜é‡çš„åˆ†å¸ƒç‰¹å¾ä¸ä¸»è¦ç±»åˆ«æ„æˆ'}
                        except Exception as e:
                            pass

                        chart_names = list(chart_data.keys())
                        chart_desc = "\n".join([f"{k}ï¼š{v['name']} - {v['desc']}" for k, v in chart_data.items()]) if chart_data else "æ— å¯ç”¨å¯è§†åŒ–å›¾è¡¨"
                        real_stats = f"""ã€æè¿°ç»Ÿè®¡ç»“æœã€‘ï¼š{desc_text}
ã€ç›¸å…³çŸ©é˜µç»“æœã€‘ï¼š{corr_text}
ã€åˆ†ç±»å˜é‡é¢‘æ•°ã€‘ï¼š{freq_text}
ã€å‡å€¼æ£€éªŒç»“æœã€‘ï¼š{ttest_text}
ã€å¯ç”¨å¯è§†åŒ–å›¾è¡¨ã€‘ï¼š{chart_desc}"""

                        prompt = """ä½ æ˜¯èµ„æ·±ç§‘ç ”æ•°æ®åˆ†æä¸“å®¶ï¼Œä¸“æ³¨äºåŸºäºçœŸå®ç»Ÿè®¡ç»“æœå’Œå¯è§†åŒ–å›¾è¡¨ç”Ÿæˆæ ‡å‡†åŒ–åˆ†ææŠ¥å‘Šï¼Œä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹è¦æ±‚è¾“å‡ºï¼Œä»»ä½•æƒ…å†µä¸‹ä¸å¾—æ”¹å˜æ ¼å¼ã€ä¸å¾—åˆ å‡ç« èŠ‚ã€ä¸å¾—ç¼–é€ ä»»ä½•æ•°æ®/å›¾è¡¨ï¼Œä»…åŸºäºæä¾›çš„çœŸå®ä¿¡æ¯åˆ†æï¼š
### å›ºå®šè¾“å‡ºæ ¼å¼è¦æ±‚ï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼Œç« èŠ‚é¡ºåºã€æ ‡é¢˜å±‚çº§ã€æ ‡ç‚¹ç¬¦å·å®Œå…¨ä¸€è‡´ï¼‰ï¼š
# æ•°æ®ç»Ÿè®¡åˆ†ææŠ¥å‘Š
## ä¸€ã€æ•°æ®åŸºæœ¬ç‰¹å¾
1. æ ·æœ¬è§„æ¨¡ï¼šæ˜ç¡®è¯´æ˜æ•°æ®çš„è¡Œæ•°åˆ—æ•°ã€æ•´ä½“ç¼ºå¤±ç‡ï¼Œç®€è¦æè¿°æ•°æ®ç»´åº¦ç‰¹å¾
2. æ•°å€¼å˜é‡ç‰¹å¾ï¼šåŸºäºæè¿°ç»Ÿè®¡ç»“æœï¼Œæ€»ç»“æ•°å€¼å˜é‡çš„å‡å€¼ã€æ ‡å‡†å·®ã€æå€¼ã€ç¼ºå¤±æƒ…å†µï¼ŒæŒ‡å‡ºæ•°æ®çš„é›†ä¸­è¶‹åŠ¿ä¸ç¦»æ•£ç¨‹åº¦
3. åˆ†ç±»å˜é‡ç‰¹å¾ï¼šåŸºäºé¢‘æ•°åˆ†æç»“æœï¼Œæ€»ç»“åˆ†ç±»å˜é‡çš„ä¸»è¦ç±»åˆ«ã€é¢‘æ•°å æ¯”ï¼Œæè¿°åˆ†ç±»å˜é‡çš„åˆ†å¸ƒç‰¹å¾

## äºŒã€å¯è§†åŒ–å›¾è¡¨åˆ†æ
{CHART_ANALYSIS}
è¦æ±‚ï¼š1. æœ‰å¤šå°‘å¼ å›¾å°±åˆ†æå¤šå°‘å¼ ï¼Œæ¯å¼ å›¾å•ç‹¬æˆæ®µï¼Œä»¥ã€Xã€‘å¼€å¤´ï¼ˆXä¸ºå›¾1/å›¾2/å›¾3ï¼‰ï¼›2. å…ˆè¯´æ˜å›¾è¡¨å±•ç¤ºçš„æ ¸å¿ƒå†…å®¹ï¼Œå†ç»“åˆç»Ÿè®¡ç»“æœè§£è¯»å›¾è¡¨åæ˜ çš„è§„å¾‹/ç‰¹å¾/é—®é¢˜ï¼›3. è¯­è¨€ç®€æ´ä¸“ä¸šï¼Œå›¾è¡¨åˆ†æä¸çœŸå®æ•°æ®é«˜åº¦å¥‘åˆï¼›4. æ— å›¾è¡¨åˆ™å†™â€œæœ¬æ¬¡åˆ†ææ— å¯ç”¨å¯è§†åŒ–å›¾è¡¨ï¼Œè·³è¿‡æœ¬ç« èŠ‚åˆ†æâ€

## ä¸‰ã€å˜é‡å…³ç³»æ·±åº¦åˆ†æ
1. æ•°å€¼å˜é‡ç›¸å…³æ€§ï¼šåŸºäºç›¸å…³çŸ©é˜µç»“æœï¼Œåˆ†æå˜é‡é—´çš„çº¿æ€§ç›¸å…³ç¨‹åº¦ã€æ˜¾è‘—æ€§ï¼ŒæŒ‡å‡ºå¼ºç›¸å…³/å¼±ç›¸å…³/æ— ç›¸å…³çš„å˜é‡ç»„åˆ
2. ç»„é—´å‡å€¼å·®å¼‚ï¼šåŸºäºå‡å€¼æ£€éªŒç»“æœï¼Œåˆ†æäºŒåˆ†ç±»åˆ†ç»„ä¸‹æ•°å€¼å˜é‡çš„å‡å€¼å·®å¼‚æ˜¯å¦æ˜¾è‘—ï¼ˆp<0.05ä¸ºæ˜¾è‘—ï¼Œp<0.01ä¸ºææ˜¾è‘—ï¼‰ï¼Œæ— æ£€éªŒç»“æœåˆ™å†™â€œæ— ç¬¦åˆæ¡ä»¶çš„äºŒåˆ†ç±»å˜é‡ï¼Œæœªæ‰§è¡Œå‡å€¼æ£€éªŒï¼Œè·³è¿‡æœ¬é¡¹åˆ†æâ€
3. æ•´ä½“å˜é‡å…³ç³»æ€»ç»“ï¼šç»¼åˆä¸Šè¿°åˆ†æï¼Œæ€»ç»“æœ¬æ¬¡æ•°æ®ä¸­å˜é‡é—´çš„æ ¸å¿ƒå…³ç³»è§„å¾‹

## å››ã€ç ”ç©¶ç»“è®ºä¸å»ºè®®
### ï¼ˆä¸€ï¼‰ç ”ç©¶ç»“è®º
åŸºäºæœ¬æ¬¡å…¨é‡ç»Ÿè®¡åˆ†æä¸å¯è§†åŒ–ç»“æœï¼Œåˆ†3-5ç‚¹å®¢è§‚æ€»ç»“æ•°æ®åæ˜ çš„æ ¸å¿ƒè§„å¾‹ã€ç‰¹å¾ã€ç»“è®ºï¼Œæ¯ç‚¹ä¸€å¥è¯ï¼Œç®€æ´æ˜ç¡®ï¼Œä»…åŸºäºçœŸå®åˆ†æç»“æœï¼Œä¸åšè¿‡åº¦æ¨æ–­
### ï¼ˆäºŒï¼‰ç ”ç©¶å»ºè®®
ç»“åˆæ•°æ®ç‰¹å¾ä¸å˜é‡å…³ç³»ï¼Œåˆ†2-4ç‚¹ç»™å‡ºé’ˆå¯¹æ€§ã€å¯è½åœ°çš„ç ”ç©¶/åˆ†æå»ºè®®ï¼Œå»ºè®®éœ€è´´åˆæ•°æ®å®é™…ï¼Œå…·æœ‰å®é™…å‚è€ƒä»·å€¼

### è¾“å‡ºçº¦æŸï¼š
1. æ‰€æœ‰åˆ†æå¿…é¡»åŸºäºæä¾›çš„çœŸå®ç»Ÿè®¡ç»“æœå’Œå›¾è¡¨ï¼Œç»å¯¹ç¦æ­¢ç¼–é€ ä»»ä½•æ•°å€¼ã€ç»Ÿè®¡é‡ã€på€¼ã€å›¾è¡¨ä¿¡æ¯ï¼›
2. æ ¼å¼ä¸¥æ ¼éµå¾ªä¸Šè¿°è¦æ±‚ï¼Œæ ‡é¢˜å±‚çº§ï¼ˆ#/##/###ï¼‰ã€ç¼–å·ï¼ˆ1./2./3.ï¼‰ã€æ ‡ç‚¹ï¼ˆé¡¿å·/é€—å·/å¥å·ï¼‰å®Œå…¨ä¸€è‡´ï¼›
3. è¯­è¨€ä¸“ä¸šã€ç®€æ´ã€å®¢è§‚ï¼Œé€‚é…ç§‘ç ”/æ•°æ®åˆ†æåœºæ™¯ï¼Œé¿å…å£è¯­åŒ–ï¼›
4. å¯è§†åŒ–å›¾è¡¨åˆ†æéƒ¨åˆ†ï¼Œå¿…é¡»åœ¨å¯¹åº”çš„ã€å›¾Xã€‘åç´§è·Ÿåˆ†æå†…å®¹ï¼Œå›¾çš„æ ‡è¯†ä¸æä¾›çš„å›¾è¡¨å®Œå…¨ä¸€è‡´ï¼›
5. æ¸©åº¦ç³»æ•°å·²è®¾ä¸º0.2ï¼Œä¿è¯è¾“å‡ºç»“æœçš„ä¸€è‡´æ€§ï¼Œå¤šæ¬¡åˆ†æåŒä¸€æ•°æ®éœ€ä¿æŒæ ¼å¼å’Œæ ¸å¿ƒå†…å®¹é«˜åº¦ç»Ÿä¸€ã€‚

### æœ¬æ¬¡åˆ†æçœŸå®ç»Ÿè®¡ä¸å›¾è¡¨ä¿¡æ¯ï¼š
""" + real_stats + f"""
### æ•°æ®åŸºç¡€æ¦‚å†µï¼š
{data_overview}
### æ ¸å¿ƒè¦æ±‚é‡ç”³ï¼š
1. å›¾è¡¨åˆ†æéƒ¨åˆ†ï¼Œåˆ†æåˆ°æŸå¼ å›¾æ—¶ï¼Œä»…éœ€å†™å‡ºã€å›¾Xã€‘ï¼ˆæ— å…¶ä»–æ–‡å­—ï¼‰ï¼Œåç»­ç”±ç³»ç»Ÿè‡ªåŠ¨åµŒå…¥çœŸå®å›¾è¡¨ï¼Œä½ æ— éœ€é¢å¤–æè¿°å›¾è¡¨æ ·å¼ï¼›
2. ä¸¥æ ¼æŒ‰ç…§å›ºå®šæ ¼å¼è¾“å‡ºï¼Œç« èŠ‚å®Œæ•´ã€å±‚çº§æ¸…æ™°ï¼Œå¤šæ¬¡åˆ†ææ ¼å¼å®Œå…¨ç»Ÿä¸€ï¼›
3. ä»…ä½¿ç”¨æä¾›çš„çœŸå®æ•°æ®ï¼Œä¸ç¼–é€ ä»»ä½•å†…å®¹ã€‚"""

                        st.markdown("### ğŸ“‹ AIæ ‡å‡†åŒ–åˆ†ææŠ¥å‘Šï¼ˆå›¾æ–‡åµŒæ’ï¼‰")
                        report_placeholder = st.empty()
                        full_report = ""
                        stream = call_deepseek_api(prompt)
                        current_text = ""
                        for chunk in stream:
                            current_text += chunk
                            full_report += chunk
                            for chart in chart_names:
                                if chart in current_text:
                                    split_text = current_text.split(chart, 1)
                                    report_placeholder.markdown(split_text[0], unsafe_allow_html=True)
                                    if chart_data[chart]['type'] == 'matplotlib':
                                        st.pyplot(chart_data[chart]['fig'], key=f"plt_{chart}")
                                    else:
                                        st.plotly_chart(chart_data[chart]['fig'], use_container_width=True, key=f"plotly_{chart}")
                                    current_text = split_text[1]
                        if current_text:
                            report_placeholder.markdown(current_text, unsafe_allow_html=True)
            
            with st.expander("â“ AIç»Ÿè®¡é—®ç­”ï¼ˆå›ºå®šæ ¼å¼ï¼‰", expanded=False):
                user_question = st.text_area("è¾“å…¥ä½ çš„æ•°æ®åˆ†æé—®é¢˜", placeholder="ç¤ºä¾‹ï¼šåˆ†æAå’ŒBçš„ç›¸å…³æ€§å¹¶è§£è¯»ï¼›ç”¨tæ£€éªŒæ¯”è¾ƒä¸¤ç»„æ•°æ®çš„å‡å€¼å·®å¼‚ï¼›æ€»ç»“æ•°æ®çš„æ ¸å¿ƒåˆ†å¸ƒç‰¹å¾", height=100)
                if st.button("ğŸ’¬ å‘é€é—®é¢˜") and user_question:
                    st.markdown("### ğŸ“ AIæ ‡å‡†åŒ–è§£ç­”")
                    q_prompt = """ä½ æ˜¯ä¸“ä¸šç»Ÿè®¡åˆ†æå¸ˆï¼Œè§£ç­”é—®é¢˜éœ€ä¸¥æ ¼éµå¾ªä»¥ä¸‹å›ºå®šæ ¼å¼ï¼Œè¯­è¨€ä¸“ä¸šç®€æ´ï¼Œä»…åŸºäºæ•°æ®æ¦‚å†µåˆ†æï¼Œä¸ç¼–é€ ä»»ä½•å†…å®¹ï¼š
## é—®é¢˜è§£ç­”ï¼š
1. åˆ†ææ–¹æ³•ï¼šæ˜ç¡®è§£ç­”è¯¥é—®é¢˜éœ€ä½¿ç”¨çš„ç»Ÿè®¡åˆ†ææ–¹æ³•ï¼Œè¯´æ˜æ–¹æ³•é€‚ç”¨åœºæ™¯
2. æ“ä½œæ­¥éª¤ï¼šåˆ†ç‚¹è¯´æ˜ä½¿ç”¨è¯¥æ–¹æ³•çš„å…·ä½“æ“ä½œæ­¥éª¤ï¼Œé€‚é…æœ¬å¹³å°åŠŸèƒ½
3. ç»“æœè§£è¯»ï¼šè¯´æ˜è¯¥æ–¹æ³•ç»“æœçš„åˆ¤æ–­æ ‡å‡†ï¼ˆå¦‚p<0.05ä¸ºæ˜¾è‘—ï¼‰ï¼Œæ˜ç¡®æ ¸å¿ƒæŒ‡æ ‡è§£è¯»æ–¹å¼
4. ç»“è®ºå»ºè®®ï¼šåŸºäºæ•°æ®æ¦‚å†µï¼Œç»™å‡ºé’ˆå¯¹æ€§çš„åˆ†æå»ºè®®æˆ–æ³¨æ„äº‹é¡¹

### æ•°æ®æ¦‚å†µï¼š
""" + data_overview + f"""
### å¾…è§£ç­”é—®é¢˜ï¼š{user_question}
### çº¦æŸï¼š
1. ä¸¥æ ¼éµå¾ªä¸Šè¿°æ ¼å¼ï¼Œä¸å¾—åˆ å‡ç« èŠ‚ï¼Œç¼–å·ä¸æ ‡é¢˜å®Œå…¨ä¸€è‡´ï¼›
2. ä»…åŸºäºæ•°æ®æ¦‚å†µè§£ç­”ï¼Œä¸ç¼–é€ ä»»ä½•æ•°æ®/å˜é‡/ç»Ÿè®¡ç»“æœï¼›
3. è¯­è¨€ä¸“ä¸šã€ç®€æ´ï¼Œé€‚é…ç§‘ç ”æ•°æ®åˆ†æåœºæ™¯ï¼Œå¤šæ¬¡è§£ç­”æ ¼å¼ç»Ÿä¸€ã€‚"""
                    stream = call_deepseek_api(q_prompt, temperature=0.2)
                    st.write_stream(stream)
            
            with st.expander("ğŸ“ˆ AIç»“æœè§£è¯»ï¼ˆå›ºå®šæ ¼å¼ï¼‰", expanded=False):
                user_result = st.text_area("ç²˜è´´ä½ çš„ç»Ÿè®¡åˆ†æç»“æœ", placeholder="ç¤ºä¾‹ï¼šçš®å°”é€Šç›¸å…³ç³»æ•°0.78ï¼Œp=0.001ï¼›tæ£€éªŒt=2.35ï¼Œp=0.02ï¼›çº¿æ€§å›å½’RÂ²=0.82", height=100)
                if st.button("ğŸ” è§£è¯»ç»“æœ") and user_result:
                    st.markdown("### ğŸ“ AIæ ‡å‡†åŒ–ç»“æœè§£è¯»")
                    r_prompt = """ä½ æ˜¯ä¸“ä¸šç»Ÿè®¡åˆ†æå¸ˆï¼Œè§£è¯»ç»Ÿè®¡ç»“æœéœ€ä¸¥æ ¼éµå¾ªä»¥ä¸‹å›ºå®šæ ¼å¼ï¼Œè¯­è¨€ä¸“ä¸šç®€æ´ï¼Œé€ç‚¹è§£è¯»ï¼Œä¸ç¼–é€ ä»»ä½•å†…å®¹ï¼š
## ç»Ÿè®¡ç»“æœè§£è¯»æŠ¥å‘Š
1. æŒ‡æ ‡è§£è¯»ï¼šé€ç‚¹è§£è¯»æ¯ä¸ªç»Ÿè®¡æŒ‡æ ‡çš„æ ¸å¿ƒå«ä¹‰ï¼Œè¯´æ˜æŒ‡æ ‡çš„ç»Ÿè®¡æ„ä¹‰
2. æ˜¾è‘—æ€§åˆ¤æ–­ï¼šæ˜ç¡®æ¯ä¸ªç»“æœçš„æ˜¾è‘—æ€§æ°´å¹³ï¼ˆp<0.05ä¸ºæ˜¾è‘—ï¼Œp<0.01ä¸ºææ˜¾è‘—ï¼Œp>0.05ä¸ºä¸æ˜¾è‘—ï¼‰
3. å®é™…æ„ä¹‰ï¼šç»“åˆæ•°æ®æ¦‚å†µï¼Œè§£è¯»æ¯ä¸ªç»“æœçš„å®é™…ç ”ç©¶/åˆ†ææ„ä¹‰ï¼Œè¯´æ˜ç»“æœåæ˜ çš„é—®é¢˜/è§„å¾‹
4. ç»¼åˆç»“è®ºï¼šç»¼åˆæ‰€æœ‰ç»“æœï¼Œç»™å‡º1-2å¥æ ¸å¿ƒç»¼åˆç»“è®ºï¼Œç®€æ´æ˜ç¡®

### æ•°æ®æ¦‚å†µï¼š
""" + data_overview + f"""
### å¾…è§£è¯»ç»Ÿè®¡ç»“æœï¼š{user_result}
### çº¦æŸï¼š
1. ä¸¥æ ¼éµå¾ªä¸Šè¿°æ ¼å¼ï¼Œä¸å¾—åˆ å‡ç« èŠ‚ï¼Œç¼–å·ä¸æ ‡é¢˜å®Œå…¨ä¸€è‡´ï¼›
2. é€ç‚¹å¯¹åº”è¾“å…¥çš„ç»Ÿè®¡ç»“æœï¼Œä¸é—æ¼ã€ä¸ç¼–é€ ï¼›
3. æ˜ç¡®æ˜¾è‘—æ€§åˆ¤æ–­æ ‡å‡†ï¼Œè§£è¯»è´´åˆæ•°æ®å®é™…ï¼›
4. è¯­è¨€ä¸“ä¸šã€ç®€æ´ï¼Œé€‚é…ç§‘ç ”æ•°æ®åˆ†æåœºæ™¯ï¼Œå¤šæ¬¡è§£è¯»æ ¼å¼ç»Ÿä¸€ã€‚"""
                    stream = call_deepseek_api(r_prompt, temperature=0.2)
                    st.write_stream(stream)
else:
    st.info("ğŸ’¡ è¯·åœ¨ã€å·¦ä¾§è¾¹æ ã€‘ä¸Šä¼ CSV/Excelæ•°æ®æ–‡ä»¶ï¼Œå³å¯å¼€å§‹å…¨åŠŸèƒ½åˆ†æ")
    st.markdown("#### ğŸ“Œ æ ¸å¿ƒåŠŸèƒ½äº®ç‚¹")
    st.markdown("- é›†æˆSPSSæ ¸å¿ƒç»Ÿè®¡åŠŸèƒ½ï¼Œæ“ä½œç®€æ˜“ï¼Œç»“æœç²¾å‡†")
    st.markdown("- AIåˆ†ææ”¯æŒ**å›¾æ–‡åµŒæ’**ï¼Œå›¾è¡¨åµŒå…¥è§£ç­”å¯¹åº”ä½ç½®ï¼Œæ’ç‰ˆç¾è§‚")
    st.markdown("- AIè¾“å‡º**å›ºå®šç»Ÿä¸€æ ¼å¼**ï¼Œä¸åŒæ–‡ä»¶/å¤šæ¬¡åˆ†ææ ¼å¼é«˜åº¦ä¸€è‡´")
    st.markdown("- å›¾è¡¨ç”Ÿæˆå¸¦å¼‚å¸¸æ•è·ï¼Œå•å›¾å¤±è´¥ä¸ä¸­æ–­ï¼Œè‡ªåŠ¨è·³è¿‡ç»§ç»­åˆ†æ")
    st.markdown("- æ‰€æœ‰åˆ†æåŸºäºçœŸå®ç»Ÿè®¡ç»“æœï¼ŒAIä¸ç¼–é€ ä»»ä½•æ•°æ®/å›¾è¡¨")
