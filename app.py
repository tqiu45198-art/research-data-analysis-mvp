import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
import plotly.graph_objects as go
import altair as alt
import matplotlib.pyplot as plt
from scipy import stats, chi2_contingency
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder, PolynomialFeatures
import warnings
import io
import re
from datetime import datetime
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="ç§‘ç ”æ•°æ®æ™ºèƒ½è§£è¯»åŠ©æ‰‹",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

def inject_custom_css():
    st.markdown("""
    <style>
    .stApp {background-color: var(--backgroundColor);font-family: var(--font);}
    .stButton > button {background-color: var(--primaryColor);color: white;border-radius: 8px;border: none;padding: 8px 16px;font-size: 14px;box-shadow: 0 2px 4px rgba(0,0,0,0.1);transition: all 0.3s ease;}
    .stButton > button:hover {background-color: #1976d2;box-shadow: 0 4px 8px rgba(0,0,0,0.15);}
    .card {background-color: white;border-radius: 12px;padding: 16px;margin: 8px 0;box-shadow: 0 1px 3px rgba(0,0,0,0.05);}
    .dataframe {border-radius: 8px !important;overflow: hidden !important;}
    .sidebar-header {font-size: 16px;font-weight: bold;color: var(--primaryColor);margin: 16px 0 8px 0;}
    .hint-text {font-size: 12px;color: #6c757d;margin-top: 4px;}
    </style>
    """, unsafe_allow_html=True)

inject_custom_css()

@st.cache_data(show_spinner="åŠ è½½æ•°æ®ä¸­...")
def load_and_clean_data(file):
    encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312']
    seps = [',', '\t', ';']
    try:
        file_content = file.read()
        file.seek(0)
        df = None
        if file.name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        if encoding in ['utf-16']:
                            content = file_content.decode(encoding, errors='replace')
                            df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip')
                        else:
                            df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        break
                    except:
                        continue
                if df is not None:
                    break
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
        df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

def identify_variable_types(df):
    numeric_cols = []
    categorical_cols = []
    binary_categorical_cols = []
    datetime_cols = []
    for col in df.columns:
        if any(fmt in col.lower() for fmt in ['date', 'time', '2016', '2017', '2018']):
            try:
                df[col] = pd.to_datetime(df[col])
                datetime_cols.append(col)
                continue
            except:
                pass
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            numeric_cols.append(col)
        except:
            categorical_cols.append(col)
            if df[col].nunique() == 2:
                binary_categorical_cols.append(col)
    return {
        'numeric': numeric_cols,
        'categorical': categorical_cols,
        'binary_categorical': binary_categorical_cols,
        'datetime': datetime_cols
    }

def generate_multiple_charts(analysis_type, params, df):
    charts = {}
    if analysis_type == "descriptive":
        col = params["target_col"]
        group_col = params.get("group_col", None)
        fig_hist = px.histogram(
            df, x=col, color=group_col,
            title=f"{col}åˆ†å¸ƒç›´æ–¹å›¾",
            color_discrete_sequence=[st.get_option("theme.primaryColor"), "#ff7f0e", "#2ca02c"],
            width=800, height=400,
            labels={col: col, group_col: group_col if group_col else None}
        )
        charts['histogram'] = fig_hist
        fig_box = alt.Chart(df).mark_boxplot(extent='min-max', color=st.get_option("theme.primaryColor")).encode(
            x=alt.X(group_col, title=group_col) if group_col else alt.value(""),
            y=alt.Y(col, title=col),
            tooltip=[alt.Tooltip(col, aggregate='mean', title='å‡å€¼'), 
                     alt.Tooltip(col, aggregate='std', title='æ ‡å‡†å·®')]
        ).properties(title=f"{col}ç®±çº¿å›¾ï¼ˆæŒ‰{group_col}åˆ†ç»„ï¼‰" if group_col else f"{col}ç®±çº¿å›¾", width=800, height=400)
        charts['boxplot'] = fig_box
        if group_col:
            fig_density = alt.Chart(df).transform_density(
                col, groupby=[group_col],
                as_=[col, 'density']
            ).mark_area(opacity=0.6).encode(
                x=col, y='density:Q', color=group_col
            ).properties(title=f"{col}å¯†åº¦åˆ†å¸ƒ", width=800, height=400)
            charts['density'] = fig_density
    elif analysis_type == "correlation":
        corr_cols = params["corr_cols"]
        corr_matrix = df[corr_cols].corr()
        fig_heatmap = px.imshow(
            corr_matrix,
            title="å˜é‡ç›¸å…³æ€§çƒ­åŠ›å›¾",
            labels=dict(color="ç›¸å…³ç³»æ•°"),
            x=corr_cols, y=corr_cols,
            color_continuous_scale=[(0, "#ff4444"), (0.5, "#ffffff"), (1, "#00C851")],
            width=800, height=600
        )
        fig_heatmap.update_xaxes(side="bottom")
        charts['heatmap'] = fig_heatmap
        if len(corr_cols) >= 2:
            scatter_cols = corr_cols[:3]
            fig_scatter_matrix = alt.Chart(df).mark_point(opacity=0.6).encode(
                x=alt.X(alt.repeat("row"), type="quantitative"),
                y=alt.Y(alt.repeat("column"), type="quantitative"),
                tooltip=scatter_cols
            ).repeat(
                row=scatter_cols,
                column=scatter_cols
            ).properties(title="å˜é‡æ•£ç‚¹çŸ©é˜µ", width=200, height=200)
            charts['scatter_matrix'] = fig_scatter_matrix
    elif analysis_type == "regression":
        x_col, y_col = params["x_col"], params["y_col"]
        poly_degree = params.get("poly_degree", 1)
        df_reg = df[[x_col, y_col]].dropna()
        fig_reg = px.scatter(
            df_reg, x=x_col, y=y_col,
            title=f"{x_col}å¯¹{y_col}çš„å›å½’åˆ†æ",
            trendline="ols" if poly_degree == 1 else None,
            width=800, height=400,
            labels={x_col: x_col, y_col: y_col}
        )
        if poly_degree > 1:
            poly = PolynomialFeatures(degree=poly_degree)
            x_poly = poly.fit_transform(df_reg[[x_col]])
            model = ols(f"{y_col} ~ x_poly", data=df_reg).fit()
            x_range = np.linspace(df_reg[x_col].min(), df_reg[x_col].max(), 100)
            x_range_poly = poly.transform(x_range.reshape(-1, 1))
            y_pred = model.predict({"x_poly": x_range_poly, y_col: 0})
            fig_reg.add_trace(go.Scatter(x=x_range, y=y_pred, mode="lines", name=f"å¤šé¡¹å¼è¶‹åŠ¿çº¿ï¼ˆdegree={poly_degree}ï¼‰"))
        charts['regression'] = fig_reg
        model = ols(f"{y_col} ~ {x_col}", data=df_reg).fit()
        residuals = model.resid
        fig_resid, ax = plt.subplots(figsize=(10, 4))
        ax.scatter(df_reg[x_col], residuals, alpha=0.6, color=st.get_option("theme.primaryColor"))
        ax.axhline(y=0, color='red', linestyle='--')
        ax.set_xlabel(x_col)
        ax.set_ylabel("æ®‹å·®")
        ax.set_title(f"{y_col}å›å½’æ®‹å·®å›¾ï¼ˆæ®‹å·®~{x_col}ï¼‰")
        charts['residual'] = fig_resid
    elif analysis_type == "kmeans":
        feature_cols = params["feature_cols"]
        n_clusters = params["n_clusters"]
        df_cluster = df[feature_cols].dropna()
        kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(df_cluster)
        df_cluster["cluster"] = kmeans.labels_
        fig_2d = px.scatter(
            df_cluster, x=feature_cols[0], y=feature_cols[1], color="cluster",
            title=f"K-Meansèšç±»ç»“æœï¼ˆK={n_clusters}ï¼‰",
            color_discrete_sequence=px.colors.qualitative.Set3,
            width=800, height=400,
            labels={feature_cols[0]: feature_cols[0], feature_cols[1]: feature_cols[1]}
        )
        charts['kmeans_2d'] = fig_2d
        if len(feature_cols) >= 3:
            fig_3d = px.scatter_3d(
                df_cluster, x=feature_cols[0], y=feature_cols[1], z=feature_cols[2], color="cluster",
                title=f"K-Meansèšç±»3Då±•ç¤ºï¼ˆK={n_clusters}ï¼‰",
                color_discrete_sequence=px.colors.qualitative.Set3,
                width=800, height=600
            )
            charts['kmeans_3d'] = fig_3d
    elif analysis_type == "time_series":
        date_col = params["date_col"]
        value_col = params["value_col"]
        group_col = params.get("group_col", None)
        fig_line = px.line(
            df, x=date_col, y=value_col, color=group_col,
            title=f"{value_col}æ—¶é—´è¶‹åŠ¿",
            color_discrete_sequence=[st.get_option("theme.primaryColor"), "#ff7f0e"],
            width=1000, height=400,
            range_x=[df[date_col].min(), df[date_col].max()],
            labels={date_col: "æ—¥æœŸ", value_col: value_col}
        )
        fig_line.update_xaxes(rangeslider_visible=True)
        charts['time_line'] = fig_line
        if group_col:
            fig_area = alt.Chart(df).mark_area(opacity=0.6).encode(
                x=date_col,
                y=alt.Y(value_col, aggregate='mean', title=f"{value_col}å‡å€¼"),
                y2=alt.Y2(f"{value_col}:Q", aggregate='min'),
                y3=alt.Y3(f"{value_col}:Q", aggregate='max'),
                color=group_col
            ).properties(title=f"{value_col}æ—¶é—´è¶‹åŠ¿ï¼ˆå‡å€¼Â±æœ€å€¼ï¼‰", width=1000, height=400)
            charts['time_area'] = fig_area
    elif analysis_type == "geo_distribution":
        lon_col = params["lon_col"]
        lat_col = params["lat_col"]
        value_col = params["value_col"]
        df_geo = df[[lon_col, lat_col, value_col]].dropna()
        df_geo.columns = ['lon', 'lat', 'value']
        charts['geo_map'] = df_geo
        fig_geo = px.scatter_mapbox(
            df_geo, lat='lat', lon='lon', size='value', color='value',
            title=f"{value_col}åœ°ç†åˆ†å¸ƒ",
            color_continuous_scale=px.colors.sequential.Bluered,
            mapbox_style="carto-positron",
            zoom=3, width=1000, height=600,
            labels={'value': value_col}
        )
        charts['geo_plotly'] = fig_geo
    return charts

st.title("ğŸ“Š ç§‘ç ”æ•°æ®æ™ºèƒ½è§£è¯»åŠ©æ‰‹")
st.markdown("**ä½ä»£ç æ“ä½œ Â· å¤šæ–¹æ³•åˆ†æ Â· å¤šå›¾è¡¨å¯è§†åŒ–**")
st.divider()

with st.sidebar:
    st.markdown('<div class="sidebar-header">1. ä¸Šä¼ æ•°æ®æ–‡ä»¶</div>', unsafe_allow_html=True)
    uploaded_files = st.file_uploader(
        "æ”¯æŒ CSV/Excelï¼ˆå¯ä¸Šä¼ å¤šä¸ªï¼‰",
        type=["xlsx", "csv"],
        accept_multiple_files=True
    )
    st.markdown('<div class="hint-text">ç¤ºä¾‹ï¼šdf_order.csvï¼ˆè®¢å•æ•°æ®ï¼‰ã€df_loc.csvï¼ˆåŸå¸‚åœ°ç†æ•°æ®ï¼‰</div>', unsafe_allow_html=True)
    if uploaded_files:
        st.markdown('<div class="sidebar-header">2. é€‰æ‹©åˆ†ææ–‡ä»¶</div>', unsafe_allow_html=True)
        selected_files = st.multiselect(
            "å‹¾é€‰è¦å‚ä¸åˆ†æçš„æ–‡ä»¶",
            [f.name for f in uploaded_files],
            default=[uploaded_files[0].name]
        )
        selected_file_objs = [f for f in uploaded_files if f.name in selected_files]
        df_dict = {}
        for file in selected_file_objs:
            df = load_and_clean_data(file)
            if df is not None:
                df_dict[file.name] = df
        if len(df_dict) >= 2:
            st.markdown('<div class="sidebar-header">3. å¤šæ–‡ä»¶å…³è”</div>', unsafe_allow_html=True)
            base_file = st.selectbox("é€‰æ‹©åŸºç¡€æ–‡ä»¶", list(df_dict.keys()))
            df = df_dict[base_file]
            for other_file in [f for f in df_dict.keys() if f != base_file]:
                df_other = df_dict[other_file]
                base_key = st.selectbox(f"åŸºç¡€æ–‡ä»¶[{base_file}]å…³è”å­—æ®µ", df.columns, key=f"base_key_{other_file}")
                other_key = st.selectbox(f"å…³è”æ–‡ä»¶[{other_file}]å…³è”å­—æ®µ", df_other.columns, key=f"other_key_{other_file}")
                if st.button(f"å…³è”[{other_file}]", key=f"join_btn_{other_file}"):
                    df = pd.merge(df, df_other, left_on=base_key, right_on=other_key, how="left", suffixes=("", f"_{other_file.split('.')[0]}"))
                    st.success(f"âœ… å·²å…³è”[{other_file}]ï¼Œå½“å‰æ•°æ®ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
        else:
            df = df_dict[list(df_dict.keys())[0]]
        var_types = identify_variable_types(df)
        st.markdown('<div class="sidebar-header">4. å˜é‡ç±»å‹è¯†åˆ«</div>', unsafe_allow_html=True)
        st.write(f"ğŸ“ˆ æ•°å€¼å‹ï¼š{', '.join(var_types['numeric'][:5])}{'...' if len(var_types['numeric'])>5 else ''}")
        st.write(f"ğŸ·ï¸ åˆ†ç±»å‹ï¼š{', '.join(var_types['categorical'][:5])}{'...' if len(var_types['categorical'])>5 else ''}")
        st.write(f"â° æ—¶é—´å‹ï¼š{', '.join(var_types['datetime']) if var_types['datetime'] else 'æ— '}")
        st.write(f"ğŸ”‘ äºŒåˆ†ç±»ï¼š{', '.join(var_types['binary_categorical']) if var_types['binary_categorical'] else 'æ— '}")

if 'df' in locals():
    col1, col2 = st.columns([2, 1])
    with col1:
        st.subheader("æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰")
        st.dataframe(df.head(), use_container_width=True, height=200)
    with col2:
        st.subheader("æ•°æ®æ¦‚å†µ")
        st.markdown(f"""
        <div class="card">
        <p>ğŸ“Š æ•°æ®è§„æ¨¡ï¼š{len(df)} è¡Œ Ã— {len(df.columns)} åˆ—</p>
        <p>âŒ ç¼ºå¤±å€¼ï¼š{df.isnull().sum().sum()} ä¸ªï¼ˆ{df.isnull().sum().sum()/(len(df)*len(df.columns))*100:.1f}%ï¼‰</p>
        <p>ğŸ“ˆ æ•°å€¼åˆ—ï¼š{len(var_types['numeric'])} ä¸ª</p>
        <p>ğŸ·ï¸ åˆ†ç±»åˆ—ï¼š{len(var_types['categorical'])} ä¸ª</p>
        </div>
        """, unsafe_allow_html=True)
    st.divider()
    st.subheader("é€‰æ‹©åˆ†æç±»å‹")
    analysis_options = [
        "1. æè¿°æ€§ç»Ÿè®¡ï¼ˆå‡å€¼/åˆ†å¸ƒï¼‰",
        "2. ç›¸å…³æ€§åˆ†æï¼ˆå˜é‡å…³ç³»ï¼‰",
        "3. ä¸¤ç»„å·®å¼‚æ£€éªŒï¼ˆtæ£€éªŒ/å¡æ–¹ï¼‰",
        "4. å¤šå› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰",
        "5. å›å½’åˆ†æï¼ˆçº¿æ€§/å¤šé¡¹å¼ï¼‰",
        "6. é€»è¾‘å›å½’ï¼ˆåˆ†ç±»é¢„æµ‹ï¼‰",
        "7. K-Meansèšç±»ï¼ˆæ•°æ®åˆ†ç¾¤ï¼‰",
        "8. æ—¶é—´åºåˆ—åˆ†æï¼ˆè¶‹åŠ¿ï¼‰",
        "9. åœ°ç†åˆ†å¸ƒåˆ†æï¼ˆåœ°å›¾ï¼‰"
    ]
    analysis_type = st.radio("é€‰æ‹©è¦æ‰§è¡Œçš„åˆ†æ", analysis_options)
    analysis_key = analysis_type.split(".")[0].strip()
    st.subheader("é…ç½®åˆ†æå‚æ•°")
    params = {}
    if analysis_key == "1":
        params["target_col"] = st.selectbox("é€‰æ‹©è¦åˆ†æçš„æ•°å€¼å˜é‡", var_types['numeric'])
        params["group_col"] = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡ï¼ˆå¯é€‰ï¼‰", [None] + var_types['categorical'])
    elif analysis_key == "2":
        params["corr_cols"] = st.multiselect("é€‰æ‹©è¦åˆ†æçš„æ•°å€¼å˜é‡ï¼ˆè‡³å°‘2ä¸ªï¼‰", var_types['numeric'], default=var_types['numeric'][:3])
        if len(params["corr_cols"]) < 2:
            st.warning("âš ï¸ è¯·è‡³å°‘é€‰æ‹©2ä¸ªæ•°å€¼å˜é‡")
    elif analysis_key == "3":
        test_type = st.radio("é€‰æ‹©æ£€éªŒç±»å‹", ["tæ£€éªŒï¼ˆæ•°å€¼å‹ç»“æœï¼‰", "å¡æ–¹æ£€éªŒï¼ˆåˆ†ç±»å‹ç»“æœï¼‰"])
        params["test_type"] = test_type
        params["group_col"] = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡ï¼ˆäºŒåˆ†ç±»ï¼‰", var_types['binary_categorical'])
        if test_type == "tæ£€éªŒï¼ˆæ•°å€¼å‹ç»“æœï¼‰":
            params["result_col"] = st.selectbox("é€‰æ‹©ç»“æœå˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'])
        else:
            params["result_col"] = st.selectbox("é€‰æ‹©ç»“æœå˜é‡ï¼ˆåˆ†ç±»å‹ï¼‰", var_types['categorical'])
    elif analysis_key == "4":
        params["factor_cols"] = st.multiselect("é€‰æ‹©å› ç´ å˜é‡ï¼ˆåˆ†ç±»å‹ï¼‰", var_types['categorical'], default=var_types['categorical'][:2])
        params["result_col"] = st.selectbox("é€‰æ‹©ç»“æœå˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'])
    elif analysis_key == "5":
        reg_type = st.radio("é€‰æ‹©å›å½’ç±»å‹", ["çº¿æ€§å›å½’", "å¤šé¡¹å¼å›å½’"])
        params["reg_type"] = reg_type
        params["x_col"] = st.selectbox("é€‰æ‹©è‡ªå˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'])
        params["y_col"] = st.selectbox("é€‰æ‹©å› å˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", [c for c in var_types['numeric'] if c != params["x_col"]])
        if reg_type == "å¤šé¡¹å¼å›å½’":
            params["poly_degree"] = st.slider("å¤šé¡¹å¼æ¬¡æ•°", 2, 5, 2)
    elif analysis_key == "6":
        params["target_col"] = st.selectbox("é€‰æ‹©é¢„æµ‹ç›®æ ‡ï¼ˆäºŒåˆ†ç±»ï¼‰", var_types['binary_categorical'])
        params["feature_cols"] = st.multiselect("é€‰æ‹©ç‰¹å¾å˜é‡ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'], default=var_types['numeric'][:2])
    elif analysis_key == "7":
        params["feature_cols"] = st.multiselect("é€‰æ‹©èšç±»ç‰¹å¾ï¼ˆæ•°å€¼å‹ï¼‰", var_types['numeric'], default=var_types['numeric'][:2])
        params["n_clusters"] = st.slider("èšç±»æ•°é‡ï¼ˆKï¼‰", 2, 10, 3)
    elif analysis_key == "8":
        if not var_types['datetime']:
            st.error("âš ï¸ æœªè¯†åˆ«åˆ°æ—¶é—´å‹å˜é‡ï¼Œè¯·ä¸Šä¼ å«æ—¥æœŸåˆ—çš„æ•°æ®ï¼ˆå¦‚ df_past_order.csvï¼‰")
        else:
            params["date_col"] = st.selectbox("é€‰æ‹©æ—¥æœŸå˜é‡", var_types['datetime'])
            params["value_col"] = st.selectbox("é€‰æ‹©è¦åˆ†æçš„æ•°å€¼å˜é‡", var_types['numeric'])
            params["group_col"] = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡ï¼ˆå¯é€‰ï¼‰", [None] + var_types['categorical'])
    elif analysis_key == "9":
        lon_cols = [c for c in df.columns if any(kw in c.lower() for kw in ['lon', 'ç»åº¦'])]
        lat_cols = [c for c in df.columns if any(kw in c.lower() for kw in ['lat', 'çº¬åº¦'])]
        if not lon_cols or not lat_cols:
            st.error("âš ï¸ æœªè¯†åˆ«åˆ°ç»çº¬åº¦å˜é‡ï¼Œè¯·ä¸Šä¼ å«ç»çº¬åº¦çš„æ–‡ä»¶ï¼ˆå¦‚ df_loc.csvï¼‰")
        else:
            params["lon_col"] = st.selectbox("é€‰æ‹©ç»åº¦åˆ—", lon_cols)
            params["lat_col"] = st.selectbox("é€‰æ‹©çº¬åº¦åˆ—", lat_cols)
            params["value_col"] = st.selectbox("é€‰æ‹©è¦å±•ç¤ºçš„æ•°å€¼å˜é‡ï¼ˆå¦‚è®¢å•é‡ï¼‰", var_types['numeric'])
    if st.button("ğŸš€ å¼€å§‹åˆ†æ", type="primary"):
        with st.spinner("åˆ†æä¸­..."):
            if analysis_key == "1":
                st.subheader("ğŸ“Š æè¿°æ€§ç»Ÿè®¡ç»“æœ")
                col = params["target_col"]
                group_col = params["group_col"]
                if group_col:
                    stats_table = df.groupby(group_col)[col].agg(['count', 'mean', 'std', 'min', 'max', 'median']).round(2)
                    stats_table.columns = ['æ ·æœ¬æ•°', 'å‡å€¼', 'æ ‡å‡†å·®', 'æœ€å°å€¼', 'æœ€å¤§å€¼', 'ä¸­ä½æ•°']
                else:
                    stats_table = df[col].agg(['count', 'mean', 'std', 'min', 'max', 'median']).round(2)
                    stats_table = pd.DataFrame(stats_table, columns=[col]).T
                st.dataframe(stats_table, use_container_width=True)
                charts = generate_multiple_charts("descriptive", params, df)
                for chart_name, chart in charts.items():
                    st.subheader(f"ğŸ“ˆ {chart_name.capitalize()}")
                    if isinstance(chart, alt.Chart):
                        st.altair_chart(chart, use_container_width=True)
                    else:
                        st.plotly_chart(chart, use_container_width=True)
                st.subheader("ğŸ“ ç»“æœè§£è¯»")
                st.markdown(f"""
                <div class="card">
                1. æ ¸å¿ƒç»Ÿè®¡ï¼š{col}çš„å‡å€¼ä¸º{stats_table['å‡å€¼'].iloc[0]:.2f}ï¼Œæ ‡å‡†å·®ä¸º{stats_table['æ ‡å‡†å·®'].iloc[0]:.2f}ï¼Œæ•°æ®{'è¾ƒé›†ä¸­' if stats_table['æ ‡å‡†å·®'].iloc[0] < stats_table['å‡å€¼'].iloc[0]*0.3 else 'è¾ƒåˆ†æ•£'}ï¼›<br>
                2. æ•°æ®èŒƒå›´ï¼šæœ€å°å€¼{stats_table['æœ€å°å€¼'].iloc[0]:.2f}ï¼Œæœ€å¤§å€¼{stats_table['æœ€å¤§å€¼'].iloc[0]:.2f}ï¼Œæå·®ä¸º{stats_table['æœ€å¤§å€¼'].iloc[0]-stats_table['æœ€å°å€¼'].iloc[0]:.2f}ï¼›<br>
                3. åˆ†ç»„å·®å¼‚ï¼š{f'æŒ‰{group_col}åˆ†ç»„æ—¶ï¼Œ{stats_table.index[stats_table["å‡å€¼"].idxmax()]}çš„{col}å‡å€¼æœ€é«˜ï¼ˆ{stats_table["å‡å€¼"].max():.2f}ï¼‰' if group_col else 'æ— åˆ†ç»„å·®å¼‚åˆ†æ'}ã€‚
                </div>
                """, unsafe_allow_html=True)
            elif analysis_key == "2" and len(params["corr_cols"]) >= 2:
                st.subheader("ğŸ”— ç›¸å…³æ€§åˆ†æç»“æœ")
                corr_matrix = df[params["corr_cols"]].corr().round(3)
                charts = generate_multiple_charts("correlation", params, df)
                for chart_name, chart in charts.items():
                    st.subheader(f"ğŸ“ˆ {chart_name.capitalize()}")
                    if isinstance(chart, alt.Chart):
                        st.altair_chart(chart, use_container_width=True)
                    else:
                        st.plotly_chart(chart, use_container_width=True)
                st.subheader("æ˜¾è‘—ç›¸å…³æ€§ï¼ˆ|r| > 0.5ï¼‰")
                corr_significant = corr_matrix[(abs(corr_matrix) > 0.5) & (corr_matrix != 1.0)].stack().drop_duplicates()
                if not corr_significant.empty:
                    st.dataframe(corr_significant.round(3), use_container_width=True)
                else:
                    st.info("âš ï¸ æœªå‘ç°ç»å¯¹å€¼å¤§äº0.5çš„æ˜¾è‘—ç›¸å…³æ€§")
                st.subheader("ğŸ“ ç»“æœè§£è¯»")
                st.markdown(f"""
                <div class="card">
                1. æœ€å¼ºæ­£ç›¸å…³ï¼š{corr_matrix.max().idxmax()}ä¸{corr_matrix.idxmax()[corr_matrix.max().idxmax()]}çš„ç›¸å…³ç³»æ•°ä¸º{corr_matrix.max().max():.3f}ï¼›<br>
                2. æœ€å¼ºè´Ÿç›¸å…³ï¼š{corr_matrix.min().idxmin()}ä¸{corr_matrix.idxmin()[corr_matrix.min().idxmin()]}çš„ç›¸å…³ç³»æ•°ä¸º{corr_matrix.min().min():.3f}ï¼›<br>
                3. ç§‘ç ”å»ºè®®ï¼š{f'{corr_matrix.max().idxmax()}ä¸{corr_matrix.idxmax()[corr_matrix.max().idxmax()]}é«˜åº¦æ­£ç›¸å…³ï¼Œå¯è¿›ä¸€æ­¥åšå›å½’åˆ†ææ¢ç´¢å› æœå…³ç³»' if corr_matrix.max().max() > 0.7 else 'æ— é«˜åº¦ç›¸å…³å˜é‡ï¼Œéœ€ç»“åˆå…¶ä»–åˆ†ææ–¹æ³•'}ã€‚
                </div>
                """, unsafe_allow_html=True)
            elif analysis_key == "3":
                st.subheader("ğŸ” ä¸¤ç»„å·®å¼‚æ£€éªŒç»“æœ")
                group_col = params["group_col"]
                result_col = params["result_col"]
                group1, group2 = df[group_col].unique()[:2]
                df_filtered = df[df[group_col].isin([group1, group2])]
                if params["test_type"] == "tæ£€éªŒï¼ˆæ•°å€¼å‹ç»“æœï¼‰":
                    data1 = df_filtered[df_filtered[group_col] == group1][result_col].dropna()
                    data2 = df_filtered[df_filtered[group_col] == group2][result_col].dropna()
                    t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=False)
                    st.write(f"åˆ†ç»„1ï¼ˆ{group1}ï¼‰ï¼šæ ·æœ¬æ•°={len(data1)}ï¼Œå‡å€¼={data1.mean():.2f}ï¼Œæ ‡å‡†å·®={data1.std():.2f}")
                    st.write(f"åˆ†ç»„2ï¼ˆ{group2}ï¼‰ï¼šæ ·æœ¬æ•°={len(data2)}ï¼Œå‡å€¼={data2.mean():.2f}ï¼Œæ ‡å‡†å·®={data2.std():.2f}")
                    st.write(f"tç»Ÿè®¡é‡ï¼š{t_stat:.4f}ï¼Œpå€¼ï¼š{p_value:.4f}")
                    st.write(f"ç»“è®ºï¼š{'å­˜åœ¨æ˜¾è‘—å·®å¼‚' if p_value < 0.05 else 'æ— æ˜¾è‘—å·®å¼‚'}ï¼ˆÎ±=0.05ï¼‰")
                    fig_box = px.box(df_filtered, x=group_col, y=result_col, title=f"{result_col}ä¸¤ç»„å·®å¼‚ç®±çº¿å›¾")
                    st.plotly_chart(fig_box, use_container_width=True)
                else:
                    contingency_table = pd.crosstab(df_filtered[group_col], df_filtered[result_col])
                    chi2_stat, p_value, dof, expected = chi2_contingency(contingency_table)
                    st.write("åˆ—è”è¡¨ï¼š")
                    st.dataframe(contingency_table, use_container_width=True)
                    st.write(f"å¡æ–¹ç»Ÿè®¡é‡ï¼š{chi2_stat:.4f}ï¼Œpå€¼ï¼š{p_value:.4f}ï¼Œè‡ªç”±åº¦ï¼š{dof}")
                    st.write(f"ç»“è®ºï¼š{'ä¸¤ç»„åˆ†å¸ƒå­˜åœ¨æ˜¾è‘—å·®å¼‚' if p_value < 0.05 else 'ä¸¤ç»„åˆ†å¸ƒæ— æ˜¾è‘—å·®å¼‚'}ï¼ˆÎ±=0.05ï¼‰")
                st.subheader("ğŸ“ ç»“æœè§£è¯»")
                st.markdown(f"""
                <div class="card">
                1. æ£€éªŒç±»å‹ï¼š{params['test_type']}ï¼Œåˆ†ç»„å˜é‡ä¸º{group_col}ï¼ˆ{group1} vs {group2}ï¼‰ï¼›<br>
                2. ç»Ÿè®¡ç»“è®ºï¼š{'ä¸¤ç»„åœ¨{result_col}ä¸Šå­˜åœ¨æ˜¾è‘—å·®å¼‚ï¼Œå¯è®¤ä¸ºåˆ†ç»„æ˜¯å¯¼è‡´å·®å¼‚çš„åŸå› ä¹‹ä¸€' if p_value < 0.05 else 'æœªå‘ç°ä¸¤ç»„åœ¨{result_col}ä¸Šçš„æ˜¾è‘—å·®å¼‚ï¼Œå·®å¼‚å¯èƒ½ç”±éšæœºå› ç´ å¯¼è‡´'}ï¼›<br>
                3. ç§‘ç ”å»ºè®®ï¼š{'å»ºè®®è¿›ä¸€æ­¥æ¢ç©¶åˆ†ç»„å˜é‡å¯¹ç»“æœçš„å½±å“æœºåˆ¶' if p_value < 0.05 else 'å¯å°è¯•å¢åŠ æ ·æœ¬é‡æˆ–æ›´æ¢åˆ†ç»„å˜é‡é‡æ–°æ£€éªŒ'}ã€‚
                </div>
                """, unsafe_allow_html=True)
            st.divider()
            st.subheader("ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Š")
            report_content = f"# ç§‘ç ”æ•°æ®åˆ†ææŠ¥å‘Š\n## åˆ†æç±»å‹ï¼š{analysis_type}\n## æ•°æ®æ¦‚å†µï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—\n## æ ¸å¿ƒç»“è®ºï¼š{st.session_state.get('report_conclusion', 'è¯¦è§ä¸Šè¿°åˆ†æ')}"
            st.download_button(
                label="ä¸‹è½½ Markdown æŠ¥å‘Š",
                data=report_content,
                file_name=f"ç§‘ç ”æ•°æ®åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d%H%M')}.md",
                mime="text/markdown"
            )
else:
    st.info("ğŸ’¡ è¯·åœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼Œæ”¯æŒå¤šæ–‡ä»¶å…³è”åˆ†æ")
