import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import plotly.graph_objects as go
from scipy import stats
import warnings
import io
import re
import os
from datetime import datetime

# åŸºç¡€é…ç½®
warnings.filterwarnings('ignore')
plt.rcParams['font.sans-serif'] = ['SimHei']
plt.rcParams['axes.unicode_minus'] = False
st.set_page_config(page_title="ç§‘ç ”æ•°æ®åˆ†æå¹³å°", page_icon="ğŸ“Š", layout="wide", initial_sidebar_state="expanded")

# æ ¸å¿ƒä¾èµ–å¯¼å…¥ï¼ˆä»…ä¿ç•™å¿…è¦çš„ï¼Œæ— å†—ä½™æç¤ºï¼‰
try:
    from scipy.stats import chi2_contingency, ttest_1samp, ttest_ind, ttest_rel, ks_2samp, mannwhitneyu, kruskal, friedmanchisquare, wilcoxon
    from statsmodels.stats.proportion import binom_test as sm_binom_test
    from statsmodels.formula.api import ols
    from statsmodels.stats.anova import anova_lm
    from statsmodels.stats.multicomp import pairwise_tukeyhsd
    from sklearn.cluster import KMeans
    from sklearn.preprocessing import StandardScaler, LabelEncoder
    from sklearn.linear_model import LinearRegression, LogisticRegression
    from sklearn.metrics import r2_score, classification_report
except ImportError:
    pass

# æ ¸å¿ƒå·¥å…·å‡½æ•°
def load_and_clean_data(file):
    encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312']
    seps = [',', '\t', ';']
    try:
        file_content = file.read()
        file.seek(0)
        df = None
        if file.name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        if encoding == 'utf-16':
                            content = file_content.decode(encoding, errors='replace')
                            df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip')
                        else:
                            df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        break
                    except:
                        continue
                if df is not None:
                    break
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
        else:
            df = pd.read_excel(file, engine='openpyxl')
        df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
        df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

def identify_variable_types(df):
    numeric_cols = []
    categorical_cols = []
    binary_categorical_cols = []
    datetime_cols = []
    for col in df.columns:
        if any(fmt in col.lower() for fmt in ['date', 'time', '2016', '2017', '2018', '2019', '2020']):
            try:
                df[col] = pd.to_datetime(df[col])
                datetime_cols.append(col)
                continue
            except:
                pass
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            numeric_cols.append(col)
        except:
            categorical_cols.append(col)
            if df[col].nunique() == 2:
                binary_categorical_cols.append(col)
    return {'numeric': numeric_cols, 'categorical': categorical_cols, 'binary_categorical': binary_categorical_cols, 'datetime': datetime_cols}

def frequency_analysis(df, categorical_cols):
    freq_dict = {}
    for col in categorical_cols:
        freq = df[col].value_counts()
        freq_pct = df[col].value_counts(normalize=True) * 100
        freq_df = pd.DataFrame({'é¢‘æ•°': freq, 'é¢‘ç‡(%)': freq_pct.round(2)})
        freq_dict[col] = freq_df
    return freq_dict

def descriptive_analysis(df, numeric_cols):
    desc_df = df[numeric_cols].describe().T
    desc_df['ç¼ºå¤±å€¼'] = df[numeric_cols].isnull().sum()
    desc_df['ç¼ºå¤±ç‡(%)'] = (desc_df['ç¼ºå¤±å€¼'] / len(df) * 100).round(2)
    desc_df['ååº¦'] = df[numeric_cols].skew().round(3)
    desc_df['å³°åº¦'] = df[numeric_cols].kurt().round(3)
    return desc_df

def contingency_table_analysis(df, col1, col2):
    cont_table = pd.crosstab(df[col1], df[col2])
    chi2, p, dof, expected = chi2_contingency(cont_table)
    cramers_v = np.sqrt(chi2 / (len(df) * min(cont_table.shape[0]-1, cont_table.shape[1]-1)))
    return {
        'è”åˆ—è¡¨': cont_table,
        'å¡æ–¹å€¼': chi2.round(3),
        'på€¼': p.round(4),
        'è‡ªç”±åº¦': dof,
        'å…‹è±å§†Vç³»æ•°': cramers_v.round(3)
    }

def t_test_onesample(df, numeric_col, popmean):
    data = df[numeric_col].dropna()
    t_stat, p_value = ttest_1samp(data, popmean)
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), 'å‡å€¼': data.mean().round(2), 'æ ·æœ¬é‡': len(data)}

def t_test_independent(df, numeric_col, group_col):
    groups = df[group_col].unique()
    if len(groups) != 2:
        return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
    group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
    group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
    t_stat, p_value = ttest_ind(group1, group2, equal_var=False)
    return {
        'tå€¼': t_stat.round(3),
        'på€¼': p_value.round(4),
        f'{groups[0]}å‡å€¼': group1.mean().round(2),
        f'{groups[1]}å‡å€¼': group2.mean().round(2),
        f'{groups[0]}æ ·æœ¬é‡': len(group1),
        f'{groups[1]}æ ·æœ¬é‡': len(group2)
    }

def t_test_paired(df, col1, col2):
    paired_data = df[[col1, col2]].dropna()
    t_stat, p_value = ttest_rel(paired_data[col1], paired_data[col2])
    return {'tå€¼': t_stat.round(3), 'på€¼': p_value.round(4), 'å·®å€¼å‡å€¼': (paired_data[col1]-paired_data[col2]).mean().round(2), 'æ ·æœ¬é‡': len(paired_data)}

def nonparametric_test(df, test_type, numeric_col, group_col=None):
    if test_type == 'å•æ ·æœ¬K-Sæ£€éªŒ':
        data = df[numeric_col].dropna()
        ks_stat, p_value = stats.kstest(data, 'norm', args=(data.mean(), data.std()))
        return {'KSç»Ÿè®¡é‡': ks_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ':
        groups = df[group_col].unique()
        if len(groups) != 2:
            return {'error': 'åˆ†ç»„å˜é‡å¿…é¡»ä¸ºäºŒåˆ†ç±»'}
        group1 = df[df[group_col] == groups[0]][numeric_col].dropna()
        group2 = df[df[group_col] == groups[1]][numeric_col].dropna()
        u_stat, p_value = mannwhitneyu(group1, group2)
        return {'Uå€¼': u_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'å¤šç‹¬ç«‹æ ·æœ¬Kruskal-Wallis Hæ£€éªŒ':
        groups_data = [df[df[group_col] == g][numeric_col].dropna() for g in df[group_col].unique()]
        h_stat, p_value = kruskal(*groups_data)
        return {'Hå€¼': h_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'ä¸¤é…å¯¹æ ·æœ¬Wilcoxonæ£€éªŒ':
        paired_data = df[[numeric_col, group_col]].dropna()
        w_stat, p_value = wilcoxon(paired_data[numeric_col], paired_data[group_col])
        return {'Wå€¼': w_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'å¤šé…å¯¹æ ·æœ¬Friedmanæ£€éªŒ':
        cols = [col for col in df.columns if col in [numeric_col, group_col]] if group_col else df.select_dtypes(include=np.number).columns[:3]
        friedman_stat, p_value = friedmanchisquare(*[df[col].dropna() for col in cols])
        return {'Friedmanç»Ÿè®¡é‡': friedman_stat.round(3), 'på€¼': p_value.round(4)}
    elif test_type == 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ':
        data = df[numeric_col].dropna()
        success = sum(data == 1)
        n = len(data)
        p_value = sm_binom_test(success, n, prop=0.5)
        return {'æˆåŠŸæ¬¡æ•°': success, 'æ€»æ¬¡æ•°': n, 'på€¼': p_value.round(4)}
    return {'error': 'æ— æ•ˆæ£€éªŒç±»å‹'}

def anova_analysis(df, formula, anova_type):
    model = ols(formula, data=df).fit()
    if anova_type == 'å•å› ç´ æ–¹å·®åˆ†æ':
        anova_result = anova_lm(model, typ=2)
    elif anova_type == 'å¤šå› ç´ æ–¹å·®åˆ†æ':
        anova_result = anova_lm(model, typ=3)
    elif anova_type == 'åæ–¹å·®åˆ†æ':
        anova_result = anova_lm(model, typ=2)
    else:
        return {'error': 'æ— æ•ˆæ–¹å·®åˆ†æç±»å‹'}
    tukey = pairwise_tukeyhsd(df[formula.split('~')[0]], df[formula.split('~')[1].split('+')[0]], alpha=0.05)
    return {'æ–¹å·®åˆ†æè¡¨': anova_result, 'äº‹åæ£€éªŒ(Tukey)': tukey.summary()}

def correlation_analysis(df, cols, corr_type='pearson'):
    corr_df = df[cols].dropna()
    if corr_type == 'pearson':
        corr_matrix = corr_df.corr(method='pearson')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.pearsonr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    elif corr_type == 'spearman':
        corr_matrix = corr_df.corr(method='spearman')
        p_matrix = pd.DataFrame(np.ones_like(corr_matrix), index=corr_matrix.index, columns=corr_matrix.columns)
        for col1 in cols:
            for col2 in cols:
                if col1 != col2:
                    corr, p = stats.spearmanr(corr_df[col1], corr_df[col2])
                    p_matrix.loc[col1, col2] = round(p, 4)
    return {'ç›¸å…³çŸ©é˜µ': corr_matrix.round(3), 'på€¼çŸ©é˜µ': p_matrix}

def regression_analysis(df, target, features, reg_type):
    X = df[features].dropna()
    y = df[target][X.index].dropna()
    X = X.loc[y.index]
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    if reg_type == 'çº¿æ€§å›å½’':
        model = LinearRegression().fit(X_scaled, y)
        y_pred = model.predict(X_scaled)
        r2 = r2_score(y, y_pred)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_.round(3), 'æˆªè·': [model.intercept_.round(3)]*len(features)})
        return {'RÂ²': r2.round(3), 'ç³»æ•°è¡¨': coef}
    elif reg_type == 'äºŒåˆ†ç±»Logisticå›å½’':
        le = LabelEncoder()
        y_encoded = le.fit_transform(y)
        model = LogisticRegression(max_iter=1000).fit(X_scaled, y_encoded)
        y_pred = model.predict(X_scaled)
        report = classification_report(y_encoded, y_pred, output_dict=True)
        coef = pd.DataFrame({'ç‰¹å¾': features, 'ç³»æ•°': model.coef_[0].round(3), 'æˆªè·': [model.intercept_[0].round(3)]*len(features)})
        return {'åˆ†ç±»æŠ¥å‘Š': report, 'ç³»æ•°è¡¨': coef}
    return {'error': 'æ— æ•ˆå›å½’ç±»å‹'}

def cluster_analysis(df, cols, n_clusters=3):
    X = df[cols].dropna()
    scaler = StandardScaler()
    X_scaled = scaler.fit_transform(X)
    kmeans = KMeans(n_clusters=n_clusters, random_state=42).fit(X_scaled)
    df_cluster = X.copy()
    df_cluster['èšç±»ç»“æœ'] = kmeans.labels_
    centroids = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=cols).round(2)
    return {'èšç±»ç»“æœ': df_cluster, 'èšç±»ä¸­å¿ƒ': centroids}

def plot_chart(df, plot_type, x_col, y_col=None, group_col=None):
    if plot_type == 'æ¡å½¢å›¾':
        fig = px.bar(df, x=x_col, y=y_col, color=group_col, barmode='group', title=f'{x_col} - {y_col}')
    elif plot_type == 'æŠ˜çº¿å›¾':
        fig = px.line(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col}')
    elif plot_type == 'é¥¼å›¾':
        fig = px.pie(df, names=x_col, values=y_col, title=f'{x_col} åˆ†å¸ƒ')
    elif plot_type == 'ç®±å›¾':
        fig = px.box(df, x=x_col, y=y_col, color=group_col, title=f'{x_col} - {y_col} åˆ†å¸ƒ')
    fig.update_layout(width=800, height=500)
    return fig

# é¡µé¢ä¸»ä½“
st.title("ç§‘ç ”æ•°æ®åˆ†æå¹³å°")
st.divider()

# ä¾§è¾¹æ 
with st.sidebar:
    uploaded_files = st.file_uploader("ä¸Šä¼ æ–‡ä»¶ï¼ˆCSV/Excelï¼‰", type=["xlsx", "csv"], accept_multiple_files=True)
    df = None
    if uploaded_files:
        selected_file_names = st.multiselect("é€‰æ‹©æ–‡ä»¶", [f.name for f in uploaded_files], default=[uploaded_files[0].name])
        selected_files = [f for f in uploaded_files if f.name in selected_file_names]
        
        df_dict = {}
        for file in selected_files:
            df_temp = load_and_clean_data(file)
            if df_temp is not None:
                df_dict[file.name] = df_temp
                st.success(f"{file.name} ä¸Šä¼ æˆåŠŸ ({len(df_temp)}è¡ŒÃ—{len(df_temp.columns)}åˆ—)")
        
        if len(df_dict) >= 2:
            base_file = st.selectbox("åŸºç¡€æ–‡ä»¶", list(df_dict.keys()))
            df = df_dict[base_file]
            for other_file in [f for f in df_dict.keys() if f != base_file]:
                df_other = df_dict[other_file]
                common_cols = [col for col in df.columns if col in df_other.columns]
                base_key = st.selectbox(f"åŸºç¡€å…³è”å­—æ®µ", common_cols if common_cols else df.columns, key=f"base_{other_file}")
                join_key = st.selectbox(f"å…³è”å­—æ®µ", common_cols if common_cols else df_other.columns, key=f"join_{other_file}")
                join_type = st.selectbox(f"åˆå¹¶æ–¹å¼", ['å·¦è¿æ¥', 'å³è¿æ¥', 'å†…è¿æ¥', 'å¤–è¿æ¥'], key=f"type_{other_file}")
                join_map = {'å·¦è¿æ¥':'left', 'å³è¿æ¥':'right', 'å†…è¿æ¥':'inner', 'å¤–è¿æ¥':'outer'}
                if st.button(f"åˆå¹¶{other_file}", key=f"btn_{other_file}"):
                    df = pd.merge(df, df_other, left_on=base_key, right_on=join_key, how=join_map[join_type], suffixes=("", f"_{other_file.split('.')[0]}"))
                    st.success(f"åˆå¹¶åï¼š{len(df)}è¡ŒÃ—{len(df.columns)}åˆ—")
        else:
            df = df_dict[list(df_dict.keys())[0]] if df_dict else None
        
        if df is not None:
            var_types = identify_variable_types(df)
            st.write(f"æ•°æ®è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")

# ä¸»å†…å®¹åŒº
if df is not None:
    var_types = identify_variable_types(df)
    col1, col2 = st.columns([3, 2])
    with col1:
        st.subheader("æ•°æ®é¢„è§ˆ")
        st.dataframe(df.head(10), use_container_width=True, height=300)
    with col2:
        st.subheader("å˜é‡ç±»å‹")
        st.write(f"æ•°å€¼å‹ï¼š{', '.join(var_types['numeric']) if var_types['numeric'] else 'æ— '}")
        st.write(f"åˆ†ç±»å‹ï¼š{', '.join(var_types['categorical']) if var_types['categorical'] else 'æ— '}")
    
    # åˆ†ææ ‡ç­¾é¡µ
    tab1, tab2, tab3, tab4, tab5, tab6, tab7 = st.tabs([
        "æ•°æ®å¤„ç†", "åŸºæœ¬ç»Ÿè®¡", "å‡å€¼æ£€éªŒ", "æ–¹å·®åˆ†æ", "ç›¸å…³åˆ†æ", "å›å½’åˆ†æ", "å¯è§†åŒ–"
    ])
    
    with tab1:
        st.subheader("æ•°æ®å¤„ç†")
        # æ•°æ®æ’åº
        sort_col = st.selectbox("æ’åºå­—æ®µ", df.columns, key='sort')
        sort_asc = st.radio("æ’åºæ–¹å¼", ['å‡åº', 'é™åº'], key='sort_asc')
        if st.button("æ‰§è¡Œæ’åº"):
            df_sorted = df.sort_values(by=sort_col, ascending=(sort_asc=='å‡åº'))
            st.dataframe(df_sorted.head(10), use_container_width=True)
        
        # æ•°æ®ç­›é€‰
        filter_col = st.selectbox("ç­›é€‰å­—æ®µ", df.columns, key='filter')
        filter_op = st.selectbox("è¿ç®—ç¬¦", ['>', '<', '>=', '<=', '==', '!='], key='filter_op')
        filter_val = st.text_input("ç­›é€‰å€¼", key='filter_val')
        if st.button("æ‰§è¡Œç­›é€‰"):
            try:
                if df[filter_col].dtype in [np.int64, np.float64]:
                    filter_val = float(filter_val)
                df_filtered = df.query(f"`{filter_col}` {filter_op} {filter_val}")
                st.success(f"ç­›é€‰åï¼š{len(df_filtered)}è¡Œ")
                st.dataframe(df_filtered.head(10), use_container_width=True)
            except:
                st.error("ç­›é€‰æ¡ä»¶é”™è¯¯")
        
        # åˆ†ç±»æ±‡æ€»
        group_col = st.selectbox("åˆ†ç»„å­—æ®µ", var_types['categorical'], key='group', disabled=not var_types['categorical'])
        agg_col = st.selectbox("æ±‡æ€»å­—æ®µ", var_types['numeric'], key='agg', disabled=not var_types['numeric'])
        agg_func = st.selectbox("æ±‡æ€»æ–¹å¼", ['å‡å€¼', 'æ±‚å’Œ', 'è®¡æ•°', 'æœ€å¤§å€¼', 'æœ€å°å€¼'], key='agg_func')
        agg_map = {'å‡å€¼':'mean', 'æ±‚å’Œ':'sum', 'è®¡æ•°':'count', 'æœ€å¤§å€¼':'max', 'æœ€å°å€¼':'min'}
        if st.button("æ‰§è¡Œæ±‡æ€»", disabled=not (group_col and agg_col)):
            df_agg = df.groupby(group_col)[agg_col].agg(agg_map[agg_func]).round(2)
            st.dataframe(df_agg, use_container_width=True)
    
    with tab2:
        st.subheader("åŸºæœ¬ç»Ÿè®¡")
        # é¢‘æ•°åˆ†æ
        freq_cols = st.multiselect("é€‰æ‹©åˆ†ç±»å‹å˜é‡", var_types['categorical'], key='freq')
        if freq_cols and st.button("æ‰§è¡Œé¢‘æ•°åˆ†æ"):
            freq_dict = frequency_analysis(df, freq_cols)
            for col in freq_cols:
                st.subheader(col)
                st.dataframe(freq_dict[col], use_container_width=True)
        
        # æè¿°ç»Ÿè®¡
        desc_cols = st.multiselect("é€‰æ‹©æ•°å€¼å‹å˜é‡", var_types['numeric'], key='desc')
        if desc_cols and st.button("æ‰§è¡Œæè¿°ç»Ÿè®¡"):
            desc_df = descriptive_analysis(df, desc_cols)
            st.dataframe(desc_df, use_container_width=True)
        
        # è”åˆ—è¡¨åˆ†æ
        if len(var_types['categorical'])>=2:
            cont_col1 = st.selectbox("è¡Œå˜é‡", var_types['categorical'], key='cont1')
            cont_col2 = st.selectbox("åˆ—å˜é‡", var_types['categorical'], key='cont2')
            if st.button("æ‰§è¡Œè”åˆ—è¡¨åˆ†æ"):
                cont_res = contingency_table_analysis(df, cont_col1, cont_col2)
                st.subheader("è”åˆ—è¡¨")
                st.dataframe(cont_res['è”åˆ—è¡¨'], use_container_width=True)
                st.write(f"å¡æ–¹å€¼ï¼š{cont_res['å¡æ–¹å€¼']}, på€¼ï¼š{cont_res['på€¼']}, å…‹è±å§†Vç³»æ•°ï¼š{cont_res['å…‹è±å§†Vç³»æ•°']}")
    
    with tab3:
        st.subheader("å‡å€¼æ£€éªŒ")
        # å•æ ·æœ¬tæ£€éªŒ
        onesamp_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='onesamp', disabled=not var_types['numeric'])
        popmean = st.number_input("æ€»ä½“å‡å€¼", value=0.0, key='popmean')
        if st.button("æ‰§è¡Œå•æ ·æœ¬tæ£€éªŒ", disabled=not onesamp_col):
            onesamp_res = t_test_onesample(df, onesamp_col, popmean)
            st.write(f"tå€¼ï¼š{onesamp_res['tå€¼']}, på€¼ï¼š{onesamp_res['på€¼']}, æ ·æœ¬å‡å€¼ï¼š{onesamp_res['å‡å€¼']}")
        
        # ä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ
        ind_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='ind', disabled=not var_types['numeric'])
        ind_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='ind_group', disabled=not var_types['categorical'])
        if st.button("æ‰§è¡Œä¸¤ç‹¬ç«‹æ ·æœ¬tæ£€éªŒ", disabled=not (ind_col and ind_group)):
            ind_res = t_test_independent(df, ind_col, ind_group)
            if 'error' in ind_res:
                st.error(ind_res['error'])
            else:
                st.write(f"tå€¼ï¼š{ind_res['tå€¼']}, på€¼ï¼š{ind_res['på€¼']}")
                st.write(f"{list(ind_res.keys())[2]}ï¼š{ind_res[list(ind_res.keys())[2]]}")
                st.write(f"{list(ind_res.keys())[3]}ï¼š{ind_res[list(ind_res.keys())[3]]}")
        
        # éå‚æ•°æ£€éªŒ
        test_type = st.selectbox("æ£€éªŒç±»å‹", ['å•æ ·æœ¬K-Sæ£€éªŒ', 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ', 'ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ'], key='test_type')
        np_col = st.selectbox("æ£€éªŒå˜é‡", var_types['numeric'], key='np', disabled=not var_types['numeric'])
        np_group = st.selectbox("åˆ†ç»„å˜é‡", var_types['categorical'], key='np_group', disabled=test_type not in ['ä¸¤ç‹¬ç«‹æ ·æœ¬Mann-Whitney Uæ£€éªŒ'])
        if st.button("æ‰§è¡Œéå‚æ•°æ£€éªŒ", disabled=not np_col):
            if test_type in ['å•æ ·æœ¬K-Sæ£€éªŒ', 'äºŒé¡¹åˆ†å¸ƒæ£€éªŒ']:
                np_res = nonparametric_test(df, test_type, np_col)
            else:
                np_res = nonparametric_test(df, test_type, np_col, np_group)
            if 'error' in np_res:
                st.error(np_res['error'])
            else:
                for k, v in np_res.items():
                    st.write(f"{k}ï¼š{v}")
    
    with tab4:
        st.subheader("æ–¹å·®åˆ†æ")
        if var_types['numeric'] and var_types['categorical']:
            anova_target = st.selectbox("å› å˜é‡", var_types['numeric'], key='anova_target')
            anova_factor = st.selectbox("å› ç´ å˜é‡", var_types['categorical'], key='anova_factor')
            formula = f"{anova_target} ~ C({anova_factor})"
            if st.button("æ‰§è¡Œå•å› ç´ æ–¹å·®åˆ†æ"):
                anova_res = anova_analysis(df, formula, 'å•å› ç´ æ–¹å·®åˆ†æ')
                if 'error' in anova_res:
                    st.error(anova_res['error'])
                else:
                    st.subheader("æ–¹å·®åˆ†æè¡¨")
                    st.dataframe(anova_res['æ–¹å·®åˆ†æè¡¨'], use_container_width=True)
                    st.subheader("äº‹åæ£€éªŒ")
                    st.text(anova_res['äº‹åæ£€éªŒ(Tukey)'])
    
    with tab5:
        st.subheader("ç›¸å…³åˆ†æ")
        corr_type = st.selectbox("ç›¸å…³ç±»å‹", ['pearson', 'spearman'], key='corr_type')
        corr_cols = st.multiselect("é€‰æ‹©å˜é‡", var_types['numeric'], key='corr_cols')
        if corr_cols and len(corr_cols)>=2 and st.button("æ‰§è¡Œç›¸å…³åˆ†æ"):
            corr_res = correlation_analysis(df, corr_cols, corr_type)
            st.subheader("ç›¸å…³çŸ©é˜µ")
            st.dataframe(corr_res['ç›¸å…³çŸ©é˜µ'], use_container_width=True)
            st.subheader("på€¼çŸ©é˜µ")
            st.dataframe(corr_res['på€¼çŸ©é˜µ'], use_container_width=True)
            
            # çƒ­åŠ›å›¾
            fig, ax = plt.subplots(figsize=(10, 8))
            im = ax.imshow(corr_res['ç›¸å…³çŸ©é˜µ'], cmap='RdBu_r', vmin=-1, vmax=1)
            ax.set_xticks(np.arange(len(corr_cols)))
            ax.set_yticks(np.arange(len(corr_cols)))
            ax.set_xticklabels(corr_cols, rotation=45, ha='right')
            ax.set_yticklabels(corr_cols)
            for i in range(len(corr_cols)):
                for j in range(len(corr_cols)):
                    text = ax.text(j, i, corr_res['ç›¸å…³çŸ©é˜µ'].iloc[i, j], ha="center", va="center", color="black")
            cbar = ax.figure.colorbar(im, ax=ax)
            plt.tight_layout()
            st.pyplot(fig)
    
    with tab6:
        st.subheader("å›å½’åˆ†æ")
        reg_type = st.selectbox("å›å½’ç±»å‹", ['çº¿æ€§å›å½’', 'äºŒåˆ†ç±»Logisticå›å½’'], key='reg_type')
        reg_target = st.selectbox("å› å˜é‡", var_types['numeric'] if reg_type=='çº¿æ€§å›å½’' else var_types['binary_categorical'], key='reg_target')
        reg_features = st.multiselect("è‡ªå˜é‡", [col for col in var_types['numeric'] if col != reg_target], key='reg_features')
        if st.button("æ‰§è¡Œå›å½’åˆ†æ", disabled=not (reg_target and reg_features)):
            reg_res = regression_analysis(df, reg_target, reg_features, reg_type)
            if 'error' in reg_res:
                st.error(reg_res['error'])
            else:
                if reg_type == 'çº¿æ€§å›å½’':
                    st.write(f"RÂ²ï¼š{reg_res['RÂ²']}")
                else:
                    st.write(f"å‡†ç¡®ç‡ï¼š{reg_res['åˆ†ç±»æŠ¥å‘Š']['accuracy']:.3f}")
                st.subheader("ç³»æ•°è¡¨")
                st.dataframe(reg_res['ç³»æ•°è¡¨'], use_container_width=True)
    
    with tab7:
        st.subheader("å¯è§†åŒ–åˆ†æ")
        plot_type = st.selectbox("å›¾è¡¨ç±»å‹", ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'é¥¼å›¾', 'ç®±å›¾'], key='plot_type')
        if plot_type in ['æ¡å½¢å›¾', 'æŠ˜çº¿å›¾', 'ç®±å›¾']:
            x_col = st.selectbox("Xè½´å˜é‡", df.columns, key='plot_x')
            y_col = st.selectbox("Yè½´å˜é‡", var_types['numeric'], key='plot_y')
            group_col = st.selectbox("åˆ†ç»„å˜é‡", [None] + var_types['categorical'], key='plot_group')
        else:
            x_col = st.selectbox("ç±»åˆ«å˜é‡", var_types['categorical'], key='plot_x_pie')
            y_col = st.selectbox("æ•°å€¼å˜é‡", var_types['numeric'], key='plot_y_pie')
            group_col = None
        if st.button("ç”Ÿæˆå›¾è¡¨"):
            fig = plot_chart(df, plot_type, x_col, y_col, group_col)
            st.plotly_chart(fig, use_container_width=True)
    
    # æŠ¥å‘Šå¯¼å‡º
    st.divider()
    st.subheader("å¯¼å‡ºæŠ¥å‘Š")
    report_content = f"""# ç§‘ç ”æ•°æ®åˆ†ææŠ¥å‘Š
## ç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
## æ•°æ®æ¦‚å†µ
- è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—
- æ•°å€¼å‹å˜é‡ï¼š{', '.join(var_types['numeric'])}
- åˆ†ç±»å‹å˜é‡ï¼š{', '.join(var_types['categorical'])}
- ç¼ºå¤±å€¼æ€»æ•°ï¼š{df.isnull().sum().sum()}ä¸ª
"""
    st.download_button(
        label="ä¸‹è½½æŠ¥å‘Š",
        data=report_content,
        file_name=f"åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d%H%M')}.md",
        mime="text/markdown"
    )

else:
    st.info("è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSV/Excelæ–‡ä»¶è¿›è¡Œåˆ†æ")
