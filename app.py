import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import plotly.express as px
import altair as alt
from scipy import stats
from scipy.stats import chi2_contingency
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
import warnings
import io
import re
import os
from datetime import datetime
from dotenv import load_dotenv

# LangChain ç›¸å…³å¯¼å…¥ï¼ˆé€‚é…æœ€æ–°ç‰ˆæœ¬ï¼‰
from langchain.agents import create_react_agent, AgentExecutor
from langchain_core.prompts import PromptTemplate
from langchain_core.tools import tool
from langchain_experimental.tools import PythonAstREPLTool
from langchain_ollama import ChatOllama  # æœ¬åœ°Ollamaæ”¯æŒ
from langchain_huggingface import HuggingFaceEndpoint  # HuggingFaceäº‘ç«¯æ”¯æŒ

warnings.filterwarnings('ignore')
load_dotenv()

# é¡µé¢åŸºç¡€é…ç½®
st.set_page_config(
    page_title="AIç§‘ç ”æ•°æ®åˆ†æå¹³å°ï¼ˆè®¤çŸ¥+è°ƒåº¦ç‰ˆï¼‰",
    page_icon="ğŸ”¬ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ---------------------- 1. æ ¸å¿ƒå·¥å…·å‡½æ•°ï¼ˆæ•°æ®åŠ è½½+å˜é‡è¯†åˆ«ï¼‰----------------------
@st.cache_data(show_spinner="åŠ è½½æ•°æ®ä¸­...")
def load_and_clean_data(file):
    """åŠ è½½CSV/Excelæ–‡ä»¶ï¼Œè‡ªåŠ¨å¤„ç†ç¼–ç å’Œåˆ†éš”ç¬¦ï¼Œæ¸…ç†åˆ—å"""
    encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312']
    seps = [',', '\t', ';']
    try:
        file_content = file.read()
        file.seek(0)
        df = None
        
        # å¤„ç†CSVæ–‡ä»¶
        if file.name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        if encoding == 'utf-16':
                            content = file_content.decode(encoding, errors='replace')
                            df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip')
                        else:
                            df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        break
                    except:
                        continue
                if df is not None:
                    break
            # å…œåº•ï¼šè‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦
            if df is None:
                from csv import Sniffer
                sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                delimiter = Sniffer().sniff(sample).delimiter
                df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
        # å¤„ç†Excelæ–‡ä»¶
        else:
            df = pd.read_excel(file, engine='openpyxl')
        
        # æ¸…ç†åˆ—åï¼ˆç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œè¡¥å……ç©ºåˆ—åï¼‰
        df.columns = [re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() for col in df.columns]
        df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
        return df
    except Exception as e:
        st.error(f"æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{str(e)}")
        return None

def identify_variable_types(df):
    """è‡ªåŠ¨è¯†åˆ«å˜é‡ç±»å‹ï¼šæ•°å€¼å‹ã€åˆ†ç±»å‹ã€äºŒåˆ†ç±»ã€æ—¶é—´å‹"""
    numeric_cols = []
    categorical_cols = []
    binary_categorical_cols = []
    datetime_cols = []
    
    for col in df.columns:
        # ä¼˜å…ˆè¯†åˆ«æ—¶é—´ç±»å˜é‡ï¼ˆå«æ—¥æœŸ/æ—¶é—´å…³é”®è¯æˆ–å¹´ä»½ï¼‰
        if any(fmt in col.lower() for fmt in ['date', 'time', '2016', '2017', '2018', '2019', '2020']):
            try:
                df[col] = pd.to_datetime(df[col])
                datetime_cols.append(col)
                continue
            except:
                pass
        
        # è¯†åˆ«æ•°å€¼å‹å˜é‡
        try:
            df[col] = pd.to_numeric(df[col], errors='raise')
            numeric_cols.append(col)
        # è¯†åˆ«åˆ†ç±»å‹å˜é‡
        except:
            categorical_cols.append(col)
            # äºŒåˆ†ç±»å˜é‡ï¼ˆå”¯ä¸€å€¼æ•°é‡=2ï¼‰
            if df[col].nunique() == 2:
                binary_categorical_cols.append(col)
    
    return {
        'numeric': numeric_cols,
        'categorical': categorical_cols,
        'binary_categorical': binary_categorical_cols,
        'datetime': datetime_cols
    }

# ---------------------- 2. LLMæ¨¡å‹é…ç½®ï¼ˆæœ¬åœ°Ollama/äº‘ç«¯HuggingFaceäºŒé€‰ä¸€ï¼‰----------------------
# é€‰é¡¹1ï¼šæœ¬åœ°Ollamaï¼ˆæ¨èï¼Œä½å»¶è¿Ÿ+æ•°æ®éšç§ï¼‰
llm = ChatOllama(
    model="llama3-8b-scientific",  # æ›¿æ¢ä¸ºä½ çš„å¾®è°ƒæ¨¡å‹Tagï¼ˆå¦‚llama3-8b-lora-researchï¼‰
    temperature=0.25,  # ä½æ¸©åº¦ï¼šç§‘ç ”åˆ†ææ›´ä¸¥è°¨
    base_url="http://localhost:11434",  # æœ¬åœ°é»˜è®¤åœ°å€ï¼Œè¿œç¨‹éƒ¨ç½²éœ€ä¿®æ”¹
    max_tokens=2048  # æœ€å¤§è¾“å‡ºé•¿åº¦
)

# é€‰é¡¹2ï¼šHuggingFaceäº‘ç«¯ï¼ˆéœ€é…ç½®API Tokenï¼Œé€‚åˆæ— æœ¬åœ°ç®—åŠ›ï¼‰
# llm = HuggingFaceEndpoint(
#     repo_id="ä½ çš„ç”¨æˆ·å/llama3-8b-scientific-lora",  # ä½ çš„å¾®è°ƒæ¨¡å‹ä»“åº“ID
#     task="text-generation",
#     huggingfacehub_api_token=os.getenv("HUGGINGFACE_TOKEN"),  # ä».envè¯»å–Token
#     temperature=0.25,
#     max_new_tokens=2048,
#     model_kwargs={"device": "auto"}  # è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼ˆCPU/GPUï¼‰
# )

# ---------------------- 3. ç§‘ç ”ä¸“ç”¨å·¥å…·é“¾ï¼ˆä»£ç æ‰§è¡Œ+è¾…åŠ©å·¥å…·ï¼‰----------------------
@tool
def get_current_time() -> str:
    """è¿”å›å½“å‰æ—¶é—´ï¼Œç”¨äºæŠ¥å‘Šæ—¶é—´æˆ³"""
    return datetime.now().strftime("%Y-%m-%d %H:%M:%S")

# Pythonä»£ç æ‰§è¡Œå·¥å…·ï¼ˆé¢„åŠ è½½æ•°æ®åˆ†æåº“ï¼ŒåŠ¨æ€æ³¨å…¥æ•°æ®é›†ï¼‰
python_repl = PythonAstREPLTool(
    name="python_repl",
    description="""æ‰§è¡ŒPythonä»£ç å®Œæˆç§‘ç ”æ•°æ®åˆ†æï¼Œæ”¯æŒï¼š
    1. ç»Ÿè®¡è®¡ç®—ï¼ˆæè¿°ç»Ÿè®¡ã€å‡è®¾æ£€éªŒã€ç›¸å…³æ€§åˆ†æç­‰ï¼‰
    2. å¯è§†åŒ–ï¼ˆæŠ˜çº¿å›¾ã€æŸ±çŠ¶å›¾ã€ç®±çº¿å›¾ã€çƒ­åŠ›å›¾ç­‰ï¼‰
    3. æ•°æ®é¢„å¤„ç†ï¼ˆç¼ºå¤±å€¼å¤„ç†ã€å¼‚å¸¸å€¼æ£€æµ‹ï¼‰
    å…¨å±€å˜é‡ï¼š
    - dfï¼šå½“å‰åŠ è½½çš„æ•°æ®é›†ï¼ˆè‡ªåŠ¨æ³¨å…¥ï¼‰
    - å·²å¯¼å…¥åº“ï¼špandas(pd)ã€numpy(np)ã€matplotlib(plt)ã€plotly(px)ã€scipy(stats)ã€statsmodels
    ç»˜å›¾è¦æ±‚ï¼šä¿å­˜ä¸ºplot.pngï¼Œé¿å…ç›´æ¥plt.show()""",
    globals={"df": None, "pd": pd, "np": np, "plt": plt, "px": px, "alt": alt, "stats": stats}
)

# å·¥å…·åˆ—è¡¨ï¼ˆå¯æ‰©å±•ï¼šå¦‚æ–‡çŒ®æ£€ç´¢å·¥å…·ã€ç»Ÿè®¡æ£€éªŒå°è£…å·¥å…·ï¼‰
tools = [python_repl, get_current_time]

# ---------------------- 4. ReAct Agenté…ç½®ï¼ˆç§‘ç ”åœºæ™¯ä¸“å±æç¤ºè¯ï¼‰----------------------
system_prompt = """ä½ æ˜¯ä¸“æ³¨äºæœ¬ç§‘ç”Ÿç§‘ç ”çš„æ•°æ®åˆ†æä¸“å®¶ï¼Œéœ€ä¸¥æ ¼éµå¾ªä»¥ä¸‹æµç¨‹å®Œæˆä»»åŠ¡ï¼š
1. æ„å›¾ç†è§£ï¼šå…ˆæ˜ç¡®ç”¨æˆ·çš„ç§‘ç ”ç›®æ ‡ï¼ˆå¦‚éªŒè¯å‡è®¾ã€æ¢ç´¢å˜é‡å…³ç³»ã€å¼‚å¸¸å€¼åˆ†æï¼‰ã€æ ¸å¿ƒå˜é‡ï¼ˆè‡ªå˜é‡/å› å˜é‡ï¼‰
2. æ•°æ®è¯„ä¼°ï¼šä¼˜å…ˆç”¨python_replæŸ¥çœ‹æ•°æ®æ¦‚å†µï¼ˆè¡Œæ•°/åˆ—æ•°ã€å˜é‡ç±»å‹ã€ç¼ºå¤±å€¼ï¼‰ï¼Œå†ç¡®å®šåˆ†ææ–¹æ¡ˆ
3. å·¥å…·è°ƒç”¨ï¼š
   - ç»Ÿè®¡è®¡ç®—/ç»˜å›¾å¿…é¡»ç”¨python_replï¼Œç»“æœéœ€åŒ…å«ç»Ÿè®¡å­¦æŒ‡æ ‡ï¼ˆå¦‚å‡å€¼ã€æ ‡å‡†å·®ã€på€¼ã€RÂ²ï¼‰
   - ç»˜å›¾éœ€é€‰æ‹©ç§‘ç ”è§„èŒƒå›¾è¡¨ï¼ˆé¿å…èŠ±å“¨æ ·å¼ï¼‰ï¼Œä¿å­˜ä¸ºplot.png
   - æ— éœ€è°ƒç”¨å·¥å…·çš„ç®€å•é—®é¢˜ï¼ˆå¦‚æ–¹æ³•è§£é‡Šï¼‰å¯ç›´æ¥å›ç­”
4. ç»“æœè§£è¯»ï¼š
   - ç”¨"ã€æ•°æ®æ¦‚å†µã€‘ã€åˆ†ææ–¹æ³•ã€‘ã€æ ¸å¿ƒç»“æœã€‘ã€ç§‘ç ”è§£è¯»ä¸å»ºè®®ã€‘ã€å›¾è¡¨ã€‘"ç»“æ„è¾“å‡º
   - è§£é‡Šéœ€é€‚é…æœ¬ç§‘ç”Ÿè®¤çŸ¥ï¼ˆé¿å…è¿‡åº¦ä¸“ä¸šæœ¯è¯­ï¼Œå¦‚"p<0.05è¡¨ç¤ºä¸¤ç»„å·®å¼‚å…·æœ‰ç»Ÿè®¡å­¦æ„ä¹‰"ï¼‰
   - ç»™å‡ºä¸‹ä¸€æ­¥å»ºè®®ï¼ˆå¦‚"å»ºè®®è¡¥å……XXå˜é‡çš„åˆ†æ""å¯å°è¯•XXæ£€éªŒéªŒè¯å‡è®¾"ï¼‰
5. å¼‚å¸¸å¤„ç†ï¼šæ•°æ®è´¨é‡é—®é¢˜ï¼ˆå¦‚ç¼ºå¤±å€¼>30%ï¼‰éœ€å…ˆæé†’ç”¨æˆ·ï¼Œå†åŸºäºå¯ç”¨æ•°æ®åˆ†æ"""

# æ„å»ºReAct Promptæ¨¡æ¿
prompt = PromptTemplate.from_template(
    system_prompt + "\n\nç”¨æˆ·é—®é¢˜ï¼š{input}\n\n{agent_scratchpad}"
)

# åˆ›å»ºReAct Agentä¸æ‰§è¡Œå™¨
agent = create_react_agent(llm, tools, prompt)
agent_executor = AgentExecutor(
    agent=agent,
    tools=tools,
    verbose=False,  # å¼€å‘æ—¶è®¾ä¸ºTrueæŸ¥çœ‹æ€è€ƒè¿‡ç¨‹ï¼Œç”Ÿäº§ç¯å¢ƒè®¾ä¸ºFalse
    handle_parsing_errors="è¯·é‡æ–°ç”Ÿæˆç¬¦åˆæ ¼å¼çš„Pythonä»£ç ï¼Œç¡®ä¿è¯­æ³•æ­£ç¡®ä¸”ä»…æ“ä½œdfå˜é‡",
    max_iterations=15,  # é¿å…æ— é™å¾ªç¯
    early_stopping_method="generate"
)

# åŠ¨æ€æ³¨å…¥æ•°æ®é›†åˆ°å·¥å…·
def get_analysis_agent(current_df):
    python_repl.globals["df"] = current_df  # å…³é”®ï¼šå°†å½“å‰æ•°æ®é›†ä¼ å…¥ä»£ç æ‰§è¡Œå·¥å…·
    return agent_executor

# ---------------------- 5. Streamlité¡µé¢æ ¸å¿ƒé€»è¾‘ï¼ˆäº¤äº’+åˆ†æï¼‰----------------------
st.title("ğŸ”¬ AIç§‘ç ”æ•°æ®åˆ†æå¹³å°ï¼ˆè®¤çŸ¥+è°ƒåº¦åˆ†ç¦»ç‰ˆï¼‰")
st.markdown("**åŸºäºå¾®è°ƒLLMç†è§£ç§‘ç ”æ„å›¾ | LangChainæ™ºèƒ½è°ƒåº¦åˆ†æå·¥å…·**")
st.divider()

# ä¾§è¾¹æ ï¼šæ–‡ä»¶ä¸Šä¼ ä¸æ•°æ®ç®¡ç†
with st.sidebar:
    st.markdown("### 1. æ•°æ®ä¸Šä¼ ")
    uploaded_files = st.file_uploader(
        "æ”¯æŒCSV/Excelï¼ˆå¯ä¼ å¤šä¸ªæ–‡ä»¶å…³è”ï¼‰",
        type=["xlsx", "csv"],
        accept_multiple_files=True
    )
    
    df = None  # å…¨å±€æ•°æ®é›†å˜é‡
    if uploaded_files:
        # æ­¥éª¤1ï¼šé€‰æ‹©å¾…åˆ†ææ–‡ä»¶
        st.markdown("### 2. é€‰æ‹©åˆ†ææ–‡ä»¶")
        selected_file_names = st.multiselect(
            "å‹¾é€‰éœ€å‚ä¸åˆ†æçš„æ–‡ä»¶",
            options=[f.name for f in uploaded_files],
            default=[uploaded_files[0].name]
        )
        selected_files = [f for f in uploaded_files if f.name in selected_file_names]
        
        # æ­¥éª¤2ï¼šåŠ è½½é€‰ä¸­æ–‡ä»¶åˆ°å­—å…¸
        df_dict = {}
        for file in selected_files:
            file_df = load_and_clean_data(file)
            if file_df is not None:
                df_dict[file.name] = file_df
                st.success(f"âœ… åŠ è½½æˆåŠŸï¼š{file.name}ï¼ˆ{len(file_df)}è¡ŒÃ—{len(file_df.columns)}åˆ—ï¼‰")
        
        # æ­¥éª¤3ï¼šå•æ–‡ä»¶/å¤šæ–‡ä»¶å…³è”å¤„ç†
        if len(df_dict) >= 2:
            st.markdown("### 3. å¤šæ–‡ä»¶å…³è”")
            # é€‰æ‹©åŸºç¡€æ–‡ä»¶
            base_file_name = st.selectbox("é€‰æ‹©åŸºç¡€æ–‡ä»¶", options=list(df_dict.keys()))
            df = df_dict[base_file_name]
            
            # å…³è”å…¶ä»–æ–‡ä»¶
            for other_file_name in [f for f in df_dict.keys() if f != base_file_name]:
                other_df = df_dict[other_file_name]
                # è‡ªåŠ¨è¯†åˆ«å…±åŒå­—æ®µ
                common_cols = [col for col in df.columns if col in other_df.columns]
                
                st.markdown(f"#### å…³è” {other_file_name}")
                base_key = st.selectbox(
                    f"åŸºç¡€æ–‡ä»¶ï¼ˆ{base_file_name}ï¼‰å…³è”å­—æ®µ",
                    options=common_cols if common_cols else df.columns,
                    key=f"base_key_{other_file_name}"
                )
                other_key = st.selectbox(
                    f"å…³è”æ–‡ä»¶ï¼ˆ{other_file_name}ï¼‰å…³è”å­—æ®µ",
                    options=common_cols if common_cols else other_df.columns,
                    key=f"other_key_{other_file_name}"
                )
                
                # æ‰§è¡Œå…³è”
                if st.button(f"å¼€å§‹å…³è” {other_file_name}", key=f"join_btn_{other_file_name}"):
                    df = pd.merge(
                        df, other_df,
                        left_on=base_key, right_on=other_key,
                        how="left",  # å·¦è¿æ¥ï¼šä¿ç•™åŸºç¡€æ–‡ä»¶æ‰€æœ‰æ•°æ®
                        suffixes=("", f"_{other_file_name.split('.')[0]}")  # é¿å…åˆ—åé‡å¤
                    )
                    st.success(f"âœ… å…³è”å®Œæˆï¼šå½“å‰æ•°æ®ï¼ˆ{len(df)}è¡ŒÃ—{len(df.columns)}åˆ—ï¼‰")
        
        # å•æ–‡ä»¶ç›´æ¥èµ‹å€¼
        else:
            df = df_dict[list(df_dict.keys())[0]]
        
        # æ­¥éª¤4ï¼šæ˜¾ç¤ºæ•°æ®æ¦‚å†µ
        if df is not None:
            var_types = identify_variable_types(df)
            st.markdown("### 4. æ•°æ®æ¦‚å†µ")
            st.write(f"ğŸ“Š æ•°æ®è§„æ¨¡ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—")
            st.write(f"ğŸ“ˆ æ•°å€¼å‹å˜é‡ï¼š{len(var_types['numeric'])}ä¸ªï¼ˆ{', '.join(var_types['numeric'][:5])}{'...' if len(var_types['numeric'])>5 else ''}ï¼‰")
            st.write(f"ğŸ·ï¸ åˆ†ç±»å‹å˜é‡ï¼š{len(var_types['categorical'])}ä¸ªï¼ˆ{', '.join(var_types['categorical'][:5])}{'...' if len(var_types['categorical'])>5 else ''}ï¼‰")
            st.write(f"âŒ ç¼ºå¤±å€¼æ€»æ•°ï¼š{df.isnull().sum().sum()}ä¸ªï¼ˆ{df.isnull().sum().sum()/(len(df)*len(df.columns))*100:.1f}%ï¼‰")

# ä¸»ç•Œé¢ï¼šæ•°æ®é¢„è§ˆä¸AIåˆ†æ
if df is not None:
    # æ•°æ®é¢„è§ˆï¼ˆåˆ†æ æ˜¾ç¤ºï¼‰
    col1, col2 = st.columns([3, 2])
    with col1:
        st.subheader("æ•°æ®é¢„è§ˆï¼ˆå‰5è¡Œï¼‰")
        st.dataframe(df.head(), use_container_width=True, height=220)
    
    with col2:
        st.subheader("å˜é‡ç±»å‹è¯¦æƒ…")
        var_types = identify_variable_types(df)
        st.markdown(f"""
        <div style="background:white;padding:12px;border-radius:8px;box-shadow:0 1px 3px rgba(0,0,0,0.05)">
        <p>â° æ—¶é—´å‹å˜é‡ï¼š{', '.join(var_types['datetime']) if var_types['datetime'] else 'æ— '}</p>
        <p>ğŸ”¢ äºŒåˆ†ç±»å˜é‡ï¼š{', '.join(var_types['binary_categorical']) if var_types['binary_categorical'] else 'æ— '}</p>
        <p>âš ï¸ é«˜ç¼ºå¤±å€¼å˜é‡ï¼š{[col for col in df.columns if df[col].isnull().sum()/len(df)>0.3] if any(df[col].isnull().sum()/len(df)>0.3 for col in df.columns) else 'æ— '}</p>
        </div>
        """, unsafe_allow_html=True)
    
    st.divider()
    
    # åˆ†æåŠŸèƒ½æ ‡ç­¾é¡µ
    tab1, tab2 = st.tabs(["ğŸ“Š è‡ªåŠ¨ç§‘ç ”åˆ†æ", "ğŸ’¬ è‡ªç”±æé—®åˆ†æ"])
    
    # æ ‡ç­¾1ï¼šè‡ªåŠ¨ç§‘ç ”åˆ†æï¼ˆä¸€é”®ç”Ÿæˆå®Œæ•´æŠ¥å‘Šï¼‰
    with tab1:
        st.subheader("è‡ªåŠ¨ç§‘ç ”çº§æ¢ç´¢åˆ†æ")
        st.markdown("ç‚¹å‡»æŒ‰é’®åï¼ŒAIå°†è‡ªåŠ¨å®Œæˆï¼šæ•°æ®è´¨é‡è¯„ä¼°â†’æè¿°ç»Ÿè®¡â†’å‡è®¾æ£€éªŒâ†’å¯è§†åŒ–â†’ç§‘ç ”è§£è¯»")
        
        if st.button("ğŸš€ å¯åŠ¨è‡ªåŠ¨åˆ†æ", type="primary", use_container_width=True):
            with st.spinner("ğŸ” è®¤çŸ¥å±‚ç†è§£ç§‘ç ”éœ€æ±‚ â†’ ğŸ› ï¸ è°ƒåº¦å±‚æ‰§è¡Œåˆ†æï¼ˆçº¦30-60ç§’ï¼‰..."):
                # è‡ªåŠ¨åˆ†ææŒ‡ä»¤ï¼ˆæ˜ç¡®ç§‘ç ”ç›®æ ‡ï¼‰
                auto_query = """
                å¯¹å½“å‰æ•°æ®é›†æ‰§è¡Œå®Œæ•´æ¢ç´¢æ€§ç§‘ç ”åˆ†æï¼Œéœ€åŒ…å«ï¼š
                1. æ•°æ®è´¨é‡è¯„ä¼°ï¼ˆç¼ºå¤±å€¼ã€å¼‚å¸¸å€¼ã€å˜é‡åˆç†æ€§ï¼‰
                2. æ ¸å¿ƒå˜é‡æè¿°ç»Ÿè®¡ï¼ˆæ•°å€¼å‹å˜é‡ï¼šå‡å€¼Â±æ ‡å‡†å·®/ä¸­ä½æ•°ï¼›åˆ†ç±»å‹å˜é‡ï¼šé¢‘æ•°+å æ¯”ï¼‰
                3. 2é¡¹æœ‰ç§‘ç ”æ„ä¹‰çš„æ·±åº¦åˆ†æï¼ˆå¦‚ï¼šæ•°å€¼å˜é‡ç›¸å…³æ€§åˆ†æ+æ˜¾è‘—æ€§æ£€éªŒã€åˆ†ç±»å‹å˜é‡ç»„é—´å·®å¼‚åˆ†æï¼ˆtæ£€éªŒ/æ–¹å·®åˆ†æï¼‰ï¼‰
                4. 1å¼ è§„èŒƒç§‘ç ”å›¾è¡¨ï¼ˆå¦‚ç›¸å…³æ€§çƒ­åŠ›å›¾ã€ç»„é—´å¯¹æ¯”ç®±çº¿å›¾ï¼‰ï¼Œä¿å­˜ä¸ºplot.png
                5. 3-5æ¡æœ¬ç§‘ç”Ÿå¯ç†è§£çš„ç§‘ç ”ç»“è®ºï¼ˆå«ç»Ÿè®¡å­¦ä¾æ®ï¼‰+ 2æ¡ä¸‹ä¸€æ­¥ç ”ç©¶å»ºè®®
                """
                # æ‰§è¡ŒAgentåˆ†æ
                analysis_agent = get_analysis_agent(df)
                result = analysis_agent.invoke({"input": auto_query})
                
                # æ˜¾ç¤ºåˆ†ææŠ¥å‘Š
                st.markdown("### ğŸ“‹ AIç§‘ç ”åˆ†ææŠ¥å‘Š")
                st.markdown(result["output"], unsafe_allow_html=True)
                
                # æ˜¾ç¤ºç”Ÿæˆçš„å›¾è¡¨
                if os.path.exists("plot.png"):
                    st.markdown("### ğŸ“ˆ åˆ†æå›¾è¡¨")
                    st.image("plot.png", use_container_width=True)
                    os.remove("plot.png")  # æ¸…ç†ä¸´æ—¶æ–‡ä»¶ï¼Œé¿å…ç¼“å­˜
    
    # æ ‡ç­¾2ï¼šè‡ªç”±æé—®åˆ†æï¼ˆç”¨æˆ·è‡ªå®šä¹‰ç§‘ç ”éœ€æ±‚ï¼‰
    with tab2:
        st.subheader("åŸºäºç§‘ç ”é—®é¢˜çš„è‡ªç”±åˆ†æ")
        st.markdown("ç¤ºä¾‹æé—®ï¼š\n1. åˆ†ææ€§åˆ«ï¼ˆåˆ†ç±»å‹ï¼‰å¯¹æˆç»©ï¼ˆæ•°å€¼å‹ï¼‰çš„å½±å“ï¼Œç”¨tæ£€éªŒéªŒè¯å·®å¼‚æ˜¾è‘—æ€§\n2. æ¢ç´¢å¹´é¾„ä¸æ”¶å…¥çš„ç›¸å…³æ€§ï¼Œç»˜åˆ¶æ•£ç‚¹å›¾å¹¶è®¡ç®—Pearsonç›¸å…³ç³»æ•°\n3. æ£€æµ‹é”€å”®é¢çš„å¼‚å¸¸å€¼ï¼Œç”¨ç®±çº¿å›¾å±•ç¤ºå¹¶ç»™å‡ºå¤„ç†å»ºè®®")
        
        user_query = st.text_area(
            "è¯·è¾“å…¥ä½ çš„ç§‘ç ”é—®é¢˜æˆ–åˆ†æéœ€æ±‚",
            height=150,
            placeholder="è¯·è¯¦ç»†æè¿°ä½ çš„åˆ†æç›®æ ‡ï¼Œä¾‹å¦‚ï¼šéªŒè¯Aã€Bä¸¤ç§æ•™å­¦æ–¹æ³•å¯¹å­¦ç”Ÿæˆç»©çš„å·®å¼‚ï¼Œéœ€ç”¨ç‹¬ç«‹æ ·æœ¬tæ£€éªŒå¹¶ç»˜åˆ¶å¯¹æ¯”æŸ±çŠ¶å›¾"
        )
        
        if st.button("æäº¤åˆ†æè¯·æ±‚", type="secondary", use_container_width=True) and user_query:
            with st.spinner("ğŸ¤– æ­£åœ¨ç†è§£ä½ çš„ç§‘ç ”æ„å›¾å¹¶æ‰§è¡Œåˆ†æ..."):
                analysis_agent = get_analysis_agent(df)
                result = analysis_agent.invoke({"input": user_query})
                
                st.markdown("### ğŸ’¡ ç§‘ç ”åˆ†æç»“æœ")
                st.markdown(result["output"], unsafe_allow_html=True)
                
                if os.path.exists("plot.png"):
                    st.markdown("### ğŸ“ˆ ç»“æœå¯è§†åŒ–")
                    st.image("plot.png", use_container_width=True)
                    os.remove("plot.png")
    
    # æŠ¥å‘Šä¸‹è½½åŠŸèƒ½
    if "result" in locals() and result.get("output"):
        st.divider()
        report_content = f"""# AIç§‘ç ”æ•°æ®åˆ†ææŠ¥å‘Š
## æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
## æ•°æ®æ¦‚å†µï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—
## åˆ†æéœ€æ±‚ï¼š{auto_query if 'auto_query' in locals() else user_query}
## å®Œæ•´åˆ†æç»“æœï¼š
{result['output']}
"""
        st.download_button(
            label="ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Šï¼ˆMarkdownæ ¼å¼ï¼‰",
            data=report_content,
            file_name=f"AIç§‘ç ”åˆ†ææŠ¥å‘Š_{datetime.now().strftime('%Y%m%d%H%M')}.md",
            mime="text/markdown"
        )

# æ— æ•°æ®æ—¶çš„æç¤º
else:
    st.info("ğŸ’¡ è¯·åœ¨å·¦ä¾§è¾¹æ ä¸Šä¼ CSV/Excelæ–‡ä»¶ï¼ˆæ”¯æŒå¤šæ–‡ä»¶å…³è”ï¼‰ï¼Œä¸Šä¼ åè‡ªåŠ¨åŠ è½½æ•°æ®æ¦‚å†µ")
