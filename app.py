import streamlit as st
import pandas as pd
import numpy as np
import plotly.express as px
from scipy import stats
from statsmodels.formula.api import ols
from statsmodels.stats.anova import anova_lm
from sklearn.cluster import KMeans
from sklearn.linear_model import LogisticRegression
from sklearn.preprocessing import LabelEncoder
import warnings
import io
import re
warnings.filterwarnings('ignore')

st.set_page_config(
    page_title="æ™ºèƒ½ç§‘ç ”æ•°æ®åˆ†æåŠ©æ‰‹",
    page_icon="ğŸ“Š",
    layout="wide"
)
st.title("ğŸ“Š æ™ºèƒ½ç§‘ç ”æ•°æ®åˆ†æåŠ©æ‰‹")
st.markdown("**è‡ªåŠ¨ç­›é€‰æ–‡ä»¶+æ™ºèƒ½æ¨èåˆ†æç±»å‹+é€šç”¨æ ¼å¼é€‚é…**")
st.divider()

# ---------------------- ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ–‡ä»¶ï¼ˆæ”¯æŒä»»æ„æ ¼å¼ï¼‰----------------------
st.subheader("ç¬¬ä¸€æ­¥ï¼šä¸Šä¼ æ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒCSV/Excelï¼Œå¯ä¸Šä¼ å¤šä¸ªï¼‰")
uploaded_files = st.file_uploader(
    "æ”¯æŒExcel(.xlsx)æˆ–CSV(.csv)æ–‡ä»¶ï¼Œä¸Šä¼ åå¯é€‰æ‹©éƒ¨åˆ†å‚ä¸åˆ†æ", 
    type=["xlsx", "csv"],
    accept_multiple_files=True
)

if not uploaded_files:
    st.info("ğŸ’¡ ç¤ºä¾‹ï¼šä¸Šä¼ å®¢æˆ·ä¿¡æ¯ã€è®¢å•æ•°æ®ã€ç»Ÿè®¡æŠ¥è¡¨ç­‰ï¼Œæ”¯æŒåç»­ç­›é€‰éƒ¨åˆ†æ–‡ä»¶åˆ†æ")
    st.stop()

# è¯»å–æ‰€æœ‰ä¸Šä¼ æ–‡ä»¶ï¼ˆé€šç”¨é€‚é…ï¼Œè§£å†³ä¹±ç ï¼‰
df_list = []
file_names = []
encodings = ['utf-8-sig', 'gbk', 'utf-8', 'gb2312', 'big5', 'utf-16', 'gb18030', 'latin-1']
seps = [',', '\t', ';', '|', ' ', ':', '\s+']

def clean_column_names(df):
    """é€šç”¨åˆ—åæ¸…ç†ï¼Œç§»é™¤ç‰¹æ®Šå­—ç¬¦å’Œä¹±ç """
    df.columns = [
        re.sub(r'[^\w\s\u4e00-\u9fa5/]', '', str(col)).strip() 
        for col in df.columns
    ]
    df.columns = [col if col else f"col_{i}" for i, col in enumerate(df.columns)]
    return df

for file in uploaded_files:
    try:
        file_content = file.read()
        if len(file_content) == 0:
            raise ValueError("æ–‡ä»¶ä¸ºç©º")
        file.seek(0)
        df = None
        file_name = file.name
        
        # CSVæ–‡ä»¶ï¼šå¤šç¼–ç +å¤šåˆ†éš”ç¬¦å°è¯•
        if file_name.endswith(".csv"):
            for encoding in encodings:
                for sep in seps:
                    try:
                        if encoding in ['utf-16', 'utf-16le', 'utf-16be']:
                            content = file_content.decode(encoding, errors='replace')
                            df = pd.read_csv(io.StringIO(content), sep=sep, on_bad_lines='skip')
                        else:
                            df = pd.read_csv(file, encoding=encoding, sep=sep, on_bad_lines='skip')
                        df = clean_column_names(df)
                        break
                    except:
                        continue
                if df is not None:
                    break
            # è‡ªåŠ¨æ£€æµ‹åˆ†éš”ç¬¦å…œåº•
            if df is None:
                try:
                    from csv import Sniffer
                    sample = file_content[:4096].decode('utf-8-sig', errors='replace')
                    delimiter = Sniffer().sniff(sample).delimiter
                    df = pd.read_csv(file, encoding='utf-8-sig', sep=delimiter, on_bad_lines='skip')
                    df = clean_column_names(df)
                except:
                    raise ValueError("ç¼–ç /åˆ†éš”ç¬¦åŒ¹é…å¤±è´¥")
        
        # Excelæ–‡ä»¶
        else:
            df = pd.read_excel(file, engine='openpyxl')
            df = clean_column_names(df)
        
        if df is not None and len(df) > 0:
            df_list.append(df)
            file_names.append(file_name)
            st.success(f"âœ… æˆåŠŸè¯»å–ï¼š{file_name}ï¼ˆ{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—ï¼‰")
        else:
            st.warning(f"âš ï¸ {file_name} æ— æœ‰æ•ˆæ•°æ®ï¼Œå·²è·³è¿‡")
    except Exception as e:
        st.error(f"âŒ è¯»å–{file_name}å¤±è´¥ï¼š{str(e)}")

if not df_list:
    st.error("âŒ æ— æœ‰æ•ˆæ–‡ä»¶å¯åˆ†æï¼Œè¯·æ£€æŸ¥æ–‡ä»¶æ ¼å¼")
    st.stop()

# ---------------------- ç¬¬äºŒæ­¥ï¼šæ™ºèƒ½æ–‡ä»¶ç­›é€‰ï¼ˆé€‰æ‹©æœ¬æ¬¡å‚ä¸åˆ†æçš„æ–‡ä»¶ï¼‰----------------------
st.subheader("ç¬¬äºŒæ­¥ï¼šé€‰æ‹©æœ¬æ¬¡å‚ä¸åˆ†æçš„æ–‡ä»¶")
selected_file_idxs = st.multiselect(
    "ä»ä¸Šä¼ æ–‡ä»¶ä¸­é€‰æ‹©ï¼ˆå¯å¤šé€‰ï¼Œè‡³å°‘1ä¸ªï¼‰",
    range(len(file_names)),
    default=[0],
    format_func=lambda x: file_names[x]
)

if len(selected_file_idxs) == 0:
    st.error("âŒ è‡³å°‘é€‰æ‹©1ä¸ªæ–‡ä»¶å‚ä¸åˆ†æ")
    st.stop()

# æå–é€‰ä¸­çš„æ–‡ä»¶
selected_dfs = [df_list[i] for i in selected_file_idxs]
selected_file_names = [file_names[i] for i in selected_file_idxs]

# ---------------------- ç¬¬ä¸‰æ­¥ï¼šé€‰æ‹©åˆ†ææ¨¡å¼ï¼ˆå•æ–‡ä»¶/å¤šæ–‡ä»¶å…³è”ï¼‰----------------------
st.subheader("ç¬¬ä¸‰æ­¥ï¼šé€‰æ‹©åˆ†ææ¨¡å¼")
if len(selected_file_idxs) == 1:
    # ä»…é€‰ä¸­1ä¸ªæ–‡ä»¶ï¼Œé»˜è®¤å•æ–‡ä»¶åˆ†æ
    analysis_mode = "å•æ–‡ä»¶ç‹¬ç«‹åˆ†æ"
    st.write(f"ğŸ“Œ å·²è‡ªåŠ¨é€‰æ‹©å•æ–‡ä»¶åˆ†æï¼š{selected_file_names[0]}")
    df = selected_dfs[0]
else:
    analysis_mode = st.radio(
        "é€‰ä¸­å¤šä¸ªæ–‡ä»¶ï¼Œé€‰æ‹©åˆ†ææ¨¡å¼",
        options=["å•æ–‡ä»¶ç‹¬ç«‹åˆ†æ", "å¤šæ–‡ä»¶å…³è”åˆ†æ"]
    )

    # å•æ–‡ä»¶åˆ†æï¼ˆä»é€‰ä¸­æ–‡ä»¶ä¸­é€‰1ä¸ªï¼‰
    if analysis_mode == "å•æ–‡ä»¶ç‹¬ç«‹åˆ†æ":
        selected_idx = st.selectbox(
            "é€‰æ‹©è¦åˆ†æçš„å•ä¸ªæ–‡ä»¶",
            range(len(selected_file_names)),
            format_func=lambda x: selected_file_names[x]
        )
        df = selected_dfs[selected_idx]
        st.success(f"âœ… å·²é€‰æ‹©å•æ–‡ä»¶ï¼š{selected_file_names[selected_idx]}")
    
    # å¤šæ–‡ä»¶å…³è”åˆ†æï¼ˆä»é€‰ä¸­æ–‡ä»¶ä¸­é€‰åŸºç¡€æ–‡ä»¶å’Œå…³è”æ–‡ä»¶ï¼‰
    else:
        st.markdown("### é…ç½®å¤šæ–‡ä»¶å…³è”")
        # é€‰æ‹©åŸºç¡€æ–‡ä»¶
        base_idx = st.selectbox(
            "é€‰æ‹©åŸºç¡€æ–‡ä»¶",
            range(len(selected_file_names)),
            format_func=lambda x: selected_file_names[x]
        )
        df = selected_dfs[base_idx]
        base_name = selected_file_names[base_idx]
        remaining_idxs = [i for i in range(len(selected_file_names)) if i != base_idx]
        remaining_dfs = [selected_dfs[i] for i in remaining_idxs]
        remaining_names = [selected_file_names[i] for i in remaining_idxs]

        # é€æ­¥å…³è”å…¶ä»–é€‰ä¸­çš„æ–‡ä»¶
        for i in range(len(remaining_idxs)):
            st.markdown(f"#### å…³è”ç¬¬{i+1}ä¸ªæ–‡ä»¶")
            col1, col2, col3 = st.columns(3)
            
            with col1:
                join_idx = st.selectbox(
                    f"é€‰æ‹©å…³è”æ–‡ä»¶ {i+1}",
                    remaining_idxs,
                    format_func=lambda x: remaining_names[x],
                    key=f"join_file_{i}"
                )
                join_df = remaining_dfs[remaining_idxs.index(join_idx)]
                join_name = remaining_names[remaining_idxs.index(join_idx)]
            
            with col2:
                base_key = st.selectbox(f"åŸºç¡€æ–‡ä»¶å…³è”å­—æ®µ", df.columns.tolist(), key=f"base_key_{i}")
            
            with col3:
                join_key = st.selectbox(f"å…³è”æ–‡ä»¶å…³è”å­—æ®µ", join_df.columns.tolist(), key=f"join_key_{i}")
            
            # å…³è”æ–¹å¼
            join_type = st.radio(
                f"å…³è”æ–¹å¼",
                options=["å†…å…³è”ï¼ˆä»…ä¿ç•™åŒ¹é…æ•°æ®ï¼‰", "å·¦å…³è”ï¼ˆä¿ç•™åŸºç¡€æ–‡ä»¶æ•°æ®ï¼‰"],
                key=f"join_type_{i}"
            )
            join_map = {"å†…å…³è”ï¼ˆä»…ä¿ç•™åŒ¹é…æ•°æ®ï¼‰": "inner", "å·¦å…³è”ï¼ˆä¿ç•™åŸºç¡€æ–‡ä»¶æ•°æ®ï¼‰": "left"}

            # å­—æ®µæœ‰æ•ˆæ€§æ£€æŸ¥
            if base_key not in df.columns or join_key not in join_df.columns:
                st.error("âŒ å…³è”å­—æ®µä¸å­˜åœ¨ï¼Œè¯·é‡æ–°é€‰æ‹©")
                st.stop()

            # é‡å‘½åå†²çªå­—æ®µ
            join_suffix = f"_{join_name.split('.')[0]}"
            join_df_renamed = join_df.rename(
                columns={col: f"{col}{join_suffix}" for col in join_df.columns if col != join_key and col in df.columns}
            )

            # æ‰§è¡Œå…³è”
            try:
                df = pd.merge(df, join_df_renamed, left_on=base_key, right_on=join_key, how=join_map[join_type])
                st.success(f"âœ… å…³è”å®Œæˆï¼š{base_name} â†” {join_name}ï¼ˆå½“å‰ï¼š{len(df)}è¡Œ Ã— {len(df.columns)}åˆ—ï¼‰")
            except Exception as e:
                st.error(f"âŒ å…³è”å¤±è´¥ï¼š{str(e)}")
                st.stop()

            # ç§»é™¤å·²å…³è”æ–‡ä»¶
            remaining_idxs.remove(join_idx)
            if not remaining_idxs:
                break

# ---------------------- ç¬¬å››æ­¥ï¼šæ™ºèƒ½è¯†åˆ«å˜é‡+æ¨èåˆ†æç±»å‹----------------------
st.subheader("ç¬¬å››æ­¥ï¼šæ•°æ®å˜é‡æ™ºèƒ½è¯†åˆ«")
# è‡ªåŠ¨åŒºåˆ†æ•°å€¼å‹/åˆ†ç±»å‹å˜é‡
numeric_cols = []
categorical_cols = []
binary_categorical_cols = []  # äºŒåˆ†ç±»å˜é‡ï¼ˆç”¨äºé€»è¾‘å›å½’ï¼‰

for col in df.columns:
    try:
        # å°è¯•è½¬æ¢ä¸ºæ•°å€¼å‹
        df[col] = pd.to_numeric(df[col], errors='raise')
        numeric_cols.append(col)
    except:
        # åˆ†ç±»å‹å˜é‡
        categorical_cols.append(col)
        # è¯†åˆ«äºŒåˆ†ç±»å˜é‡
        if df[col].nunique() == 2:
            binary_categorical_cols.append(col)

# å»é‡å¹¶æ˜¾ç¤º
numeric_cols = list(set(numeric_cols))
categorical_cols = list(set(categorical_cols))
binary_categorical_cols = list(set(binary_categorical_cols))

# æ˜¾ç¤ºå˜é‡è¯†åˆ«ç»“æœ
st.write(f"ğŸ“ˆ æ•°å€¼å‹å˜é‡ï¼ˆ{len(numeric_cols)}ä¸ªï¼‰ï¼š{', '.join(numeric_cols) if numeric_cols else 'æ— '}")
st.write(f"ğŸ·ï¸ åˆ†ç±»å‹å˜é‡ï¼ˆ{len(categorical_cols)}ä¸ªï¼‰ï¼š{', '.join(categorical_cols) if categorical_cols else 'æ— '}")
st.write(f"ğŸ”‘ äºŒåˆ†ç±»å˜é‡ï¼ˆ{len(binary_categorical_cols)}ä¸ªï¼‰ï¼š{', '.join(binary_categorical_cols) if binary_categorical_cols else 'æ— '}")

if not numeric_cols:
    st.error("âŒ æ— å¯ç”¨æ•°å€¼å‹å˜é‡ï¼Œæ— æ³•è¿›è¡Œç»Ÿè®¡åˆ†æ")
    st.stop()

# æ™ºèƒ½åˆ¤æ–­æ”¯æŒçš„åˆ†æç±»å‹
def get_supported_analyses():
    supported = []
    reasons = {}

    # 1. æè¿°æ€§ç»Ÿè®¡ï¼ˆåªè¦æœ‰æ•°å€¼å‹å˜é‡ï¼‰
    supported.append("æè¿°æ€§ç»Ÿè®¡ï¼ˆåˆ†å¸ƒ/å‡å€¼/æ ‡å‡†å·®ï¼‰")
    reasons["æè¿°æ€§ç»Ÿè®¡ï¼ˆåˆ†å¸ƒ/å‡å€¼/æ ‡å‡†å·®ï¼‰"] = "âœ… æœ‰æ•°å€¼å‹å˜é‡ï¼Œæ”¯æŒåŸºç¡€ç»Ÿè®¡å’Œå¯è§†åŒ–"

    # 2. ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆéœ€åˆ†ç±»å‹å˜é‡â‰¥1+æ•°å€¼å‹å˜é‡â‰¥1ï¼Œä¸”åˆ†ç±»å‹å˜é‡è‡³å°‘2ç»„ï¼‰
    t_test_support = len(categorical_cols) >= 1 and len(numeric_cols) >= 1
    if t_test_support:
        # æ£€æŸ¥æ˜¯å¦æœ‰åˆ†ç±»å‹å˜é‡â‰¥2ç»„
        multi_group_cats = [col for col in categorical_cols if df[col].nunique() >= 2]
        if len(multi_group_cats) == 0:
            t_test_support = False
            reasons["ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼‰"] = "âŒ æ‰€æœ‰åˆ†ç±»å‹å˜é‡ä»…1ç»„ï¼Œæ— æ³•åˆ†ç»„å¯¹æ¯”"
        else:
            reasons["ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼‰"] = "âœ… æœ‰åˆ†ç±»å‹å˜é‡ï¼ˆâ‰¥2ç»„ï¼‰å’Œæ•°å€¼å‹å˜é‡ï¼Œæ”¯æŒå·®å¼‚æ£€éªŒ"
    else:
        reasons["ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼‰"] = "âŒ ç¼ºå°‘åˆ†ç±»å‹å˜é‡æˆ–æ•°å€¼å‹å˜é‡"
    
    if t_test_support:
        supported.append("ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼‰")

    # 3. å¤šå› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰ï¼ˆéœ€åˆ†ç±»å‹å˜é‡â‰¥1+æ•°å€¼å‹å˜é‡â‰¥1ï¼‰
    anova_support = len(categorical_cols) >= 1 and len(numeric_cols) >= 1
    if anova_support:
        reasons["å¤šå› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰"] = "âœ… æœ‰åˆ†ç±»å‹å˜é‡å’Œæ•°å€¼å‹å˜é‡ï¼Œæ”¯æŒå¤šå› ç´ å½±å“åˆ†æ"
        supported.append("å¤šå› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰")
    else:
        reasons["å¤šå› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰"] = "âŒ ç¼ºå°‘åˆ†ç±»å‹å˜é‡æˆ–æ•°å€¼å‹å˜é‡"

    # 4. ç®€å•çº¿æ€§å›å½’ï¼ˆéœ€æ•°å€¼å‹å˜é‡â‰¥2ï¼‰
    regression_support = len(numeric_cols) >= 2
    if regression_support:
        reasons["ç®€å•çº¿æ€§å›å½’ï¼ˆå˜é‡å…³ç³»åˆ†æï¼‰"] = "âœ… æ•°å€¼å‹å˜é‡â‰¥2ä¸ªï¼Œæ”¯æŒå˜é‡å…³ç³»å»ºæ¨¡"
        supported.append("ç®€å•çº¿æ€§å›å½’ï¼ˆå˜é‡å…³ç³»åˆ†æï¼‰")
    else:
        reasons["ç®€å•çº¿æ€§å›å½’ï¼ˆå˜é‡å…³ç³»åˆ†æï¼‰"] = "âŒ æ•°å€¼å‹å˜é‡ä¸è¶³2ä¸ªï¼Œæ— æ³•å»ºç«‹å›å½’"

    # 5. é€»è¾‘å›å½’ï¼ˆéœ€äºŒåˆ†ç±»å˜é‡â‰¥1+æ•°å€¼å‹å˜é‡â‰¥1ï¼‰
    logistic_support = len(binary_categorical_cols) >= 1 and len(numeric_cols) >= 1
    if logistic_support:
        reasons["é€»è¾‘å›å½’ï¼ˆåˆ†ç±»é¢„æµ‹ï¼‰"] = "âœ… æœ‰äºŒåˆ†ç±»å˜é‡å’Œæ•°å€¼å‹å˜é‡ï¼Œæ”¯æŒåˆ†ç±»é¢„æµ‹"
        supported.append("é€»è¾‘å›å½’ï¼ˆåˆ†ç±»é¢„æµ‹ï¼‰")
    else:
        reasons["é€»è¾‘å›å½’ï¼ˆåˆ†ç±»é¢„æµ‹ï¼‰"] = "âŒ ç¼ºå°‘äºŒåˆ†ç±»å˜é‡æˆ–æ•°å€¼å‹å˜é‡"

    # 6. K-Meansèšç±»ï¼ˆéœ€æ•°å€¼å‹å˜é‡â‰¥2ï¼‰
    kmeans_support = len(numeric_cols) >= 2
    if kmeans_support:
        reasons["K-Meansèšç±»ï¼ˆæ•°æ®åˆ†ç»„ï¼‰"] = "âœ… æ•°å€¼å‹å˜é‡â‰¥2ä¸ªï¼Œæ”¯æŒæ•°æ®åˆ†ç¾¤"
        supported.append("K-Meansèšç±»ï¼ˆæ•°æ®åˆ†ç»„ï¼‰")
    else:
        reasons["K-Meansèšç±»ï¼ˆæ•°æ®åˆ†ç»„ï¼‰"] = "âŒ æ•°å€¼å‹å˜é‡ä¸è¶³2ä¸ªï¼Œæ— æ³•èšç±»"

    return supported, reasons

supported_analyses, analysis_reasons = get_supported_analyses()

# æ˜¾ç¤ºæ”¯æŒçš„åˆ†æç±»å‹ï¼ˆéšè—ä¸æ”¯æŒçš„ï¼Œæ˜¾ç¤ºåŸå› ï¼‰
st.subheader("ç¬¬äº”æ­¥ï¼šæ™ºèƒ½æ¨èåˆ†æç±»å‹")
st.write("ğŸ’¡ åŸºäºæ•°æ®è‡ªåŠ¨ç­›é€‰æ”¯æŒçš„åˆ†æç±»å‹ï¼Œä¸æ”¯æŒçš„ç±»å‹åŠåŸå› å¦‚ä¸‹ï¼š")
for analysis in [
    "æè¿°æ€§ç»Ÿè®¡ï¼ˆåˆ†å¸ƒ/å‡å€¼/æ ‡å‡†å·®ï¼‰",
    "ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼‰",
    "å¤šå› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰",
    "ç®€å•çº¿æ€§å›å½’ï¼ˆå˜é‡å…³ç³»åˆ†æï¼‰",
    "é€»è¾‘å›å½’ï¼ˆåˆ†ç±»é¢„æµ‹ï¼‰",
    "K-Meansèšç±»ï¼ˆæ•°æ®åˆ†ç»„ï¼‰"
]:
    if analysis not in supported_analyses:
        st.write(f"- {analysis_reasons[analysis]}")

# è®©ç”¨æˆ·é€‰æ‹©æ”¯æŒçš„åˆ†æç±»å‹
if not supported_analyses:
    st.error("âŒ æ— å¯ç”¨åˆ†æç±»å‹ï¼Œè¯·æ£€æŸ¥æ•°æ®å˜é‡")
    st.stop()

analysis_type = st.radio(
    "é€‰æ‹©è¦æ‰§è¡Œçš„åˆ†æï¼ˆä»…æ˜¾ç¤ºæ”¯æŒçš„ç±»å‹ï¼‰",
    options=supported_analyses
)

type_map = {
    "æè¿°æ€§ç»Ÿè®¡ï¼ˆåˆ†å¸ƒ/å‡å€¼/æ ‡å‡†å·®ï¼‰": "descriptive",
    "ç‹¬ç«‹æ ·æœ¬tæ£€éªŒï¼ˆä¸¤ç»„å·®å¼‚å¯¹æ¯”ï¼‰": "t_test",
    "å¤šå› ç´ æ–¹å·®åˆ†æï¼ˆANOVAï¼‰": "anova",
    "ç®€å•çº¿æ€§å›å½’ï¼ˆå˜é‡å…³ç³»åˆ†æï¼‰": "regression",
    "é€»è¾‘å›å½’ï¼ˆåˆ†ç±»é¢„æµ‹ï¼‰": "logistic_reg",
    "K-Meansèšç±»ï¼ˆæ•°æ®åˆ†ç»„ï¼‰": "kmeans"
}
target_analysis = type_map[analysis_type]

# ---------------------- ç¬¬å…­æ­¥ï¼šé…ç½®åˆ†æå‚æ•°----------------------
st.subheader("ç¬¬å…­æ­¥ï¼šé…ç½®åˆ†æå‚æ•°")
params = {}
st.markdown("### ğŸ¨ å›¾è¡¨è‡ªå®šä¹‰")
params["chart_color"] = st.color_picker("å›¾è¡¨ä¸»è‰²è°ƒ", value="#1f77b4")
params["chart_width"] = st.slider("å›¾è¡¨å®½åº¦", 600, 1200, 800)
params["chart_height"] = st.slider("å›¾è¡¨é«˜åº¦", 400, 800, 500)

# æŒ‰åˆ†æç±»å‹é…ç½®å‚æ•°
if target_analysis == "kmeans":
    params["n_clusters"] = st.slider("èšç±»æ•°é‡ï¼ˆKå€¼ï¼‰", 2, 10, 3)

elif target_analysis == "descriptive":
    params["target_col"] = st.selectbox("é€‰æ‹©åˆ†æçš„æ•°å€¼å˜é‡", numeric_cols)
    params["chart_type"] = st.radio("å›¾è¡¨ç±»å‹", ["ç›´æ–¹å›¾ï¼ˆåˆ†å¸ƒï¼‰", "æŸ±çŠ¶å›¾ï¼ˆå‡å€¼ï¼‰"])

elif target_analysis == "t_test":
    # ä»…æ˜¾ç¤ºâ‰¥2ç»„çš„åˆ†ç±»å‹å˜é‡
    valid_group_cols = [col for col in categorical_cols if df[col].nunique() >= 2]
    params["group_col"] = st.selectbox("é€‰æ‹©åˆ†ç»„å˜é‡", valid_group_cols)
    params["result_col"] = st.selectbox("é€‰æ‹©å¯¹æ¯”çš„æ•°å€¼å˜é‡", numeric_cols)
    # è‡ªåŠ¨å¤„ç†å¤šç»„
    group_counts = df[params["group_col"]].nunique()
    if group_counts != 2:
        st.warning(f"âš ï¸ è‡ªåŠ¨å–æ ·æœ¬é‡å‰2çš„ç»„ï¼ˆå…±{group_counts}ç»„ï¼‰")
        top2_groups = df[params["group_col"]].value_counts().nlargest(2).index.tolist()
        df = df[df[params["group_col"]].isin(top2_groups)]

elif target_analysis == "anova":
    params["factor_cols"] = st.multiselect("é€‰æ‹©å› ç´ å˜é‡ï¼ˆå¯å¤šé€‰ï¼‰", categorical_cols, default=categorical_cols[0])
    params["result_col"] = st.selectbox("é€‰æ‹©å› å˜é‡", numeric_cols)
    params["formula"] = f"{params['result_col']} ~ {' + '.join(params['factor_cols'])}"

elif target_analysis == "regression":
    params["x_col"] = st.selectbox("é€‰æ‹©è‡ªå˜é‡", numeric_cols)
    params["y_col"] = st.selectbox("é€‰æ‹©å› å˜é‡", [col for col in numeric_cols if col != params["x_col"]])

elif target_analysis == "logistic_reg":
    params["target_col"] = st.selectbox("é€‰æ‹©é¢„æµ‹ç›®æ ‡ï¼ˆäºŒåˆ†ç±»å˜é‡ï¼‰", binary_categorical_cols)
    params["feature_cols"] = st.multiselect("é€‰æ‹©ç‰¹å¾å˜é‡", numeric_cols, default=numeric_cols[:2])
    df[params["target_col"] + "_encoded"] = LabelEncoder().fit_transform(df[params["target_col"]])

elif target_analysis == "kmeans":
    params["feature_cols"] = st.multiselect("é€‰æ‹©èšç±»ç‰¹å¾", numeric_cols, default=numeric_cols[:2])
    df_cluster = df[params["feature_cols"]].dropna()
    if len(df_cluster) < params["n_clusters"]:
        st.error(f"âŒ æœ‰æ•ˆæ ·æœ¬æ•°ï¼ˆ{len(df_cluster)}ï¼‰< èšç±»æ•°é‡ï¼ˆ{params['n_clusters']}ï¼‰ï¼Œè¯·å‡å°‘Kå€¼")
        st.stop()

# ---------------------- ç¬¬ä¸ƒæ­¥ï¼šæ‰§è¡Œåˆ†æå¹¶ç”Ÿæˆç»“æœ----------------------
st.divider()
st.subheader("ç¬¬ä¸ƒæ­¥ï¼šæ‰§è¡Œåˆ†æ")

if st.button("ğŸš€ å¼€å§‹åˆ†æ"):
    try:
        with st.spinner("åˆ†æä¸­..."):
            report = ""
            # æè¿°æ€§ç»Ÿè®¡
            if target_analysis == "descriptive":
                col = params["target_col"]
                stats_result = df[col].describe()
                st.subheader("ğŸ“Š æè¿°æ€§ç»Ÿè®¡ç»“æœ")
                st.dataframe(stats_result.to_frame(), use_container_width=True)
                
                fig = px.histogram(df, x=col, title=f"{col}åˆ†å¸ƒ" if params["chart_type"] == "ç›´æ–¹å›¾ï¼ˆåˆ†å¸ƒï¼‰" else f"{col}å‡å€¼",
                                  color_discrete_sequence=[params["chart_color"]], width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                report = f"""### åˆ†ææŠ¥å‘Š
1. åˆ†æå˜é‡ï¼š{col}
2. æ ¸å¿ƒç»Ÿè®¡ï¼šå‡å€¼{stats_result['mean']:.2f}ã€ä¸­ä½æ•°{stats_result['50%']:.2f}ã€æ ‡å‡†å·®{stats_result['std']:.2f}
3. æ•°æ®èŒƒå›´ï¼š{stats_result['min']:.2f} ~ {stats_result['max']:.2f}
4. åˆ†å¸ƒç‰¹å¾ï¼š{'å‡åŒ€' if stats_result['std'] < stats_result['mean']*0.3 else 'åˆ†æ•£'}
"""

            # tæ£€éªŒ
            elif target_analysis == "t_test":
                group_col, result_col = params["group_col"], params["result_col"]
                group1, group2 = df[group_col].unique()[:2]
                data1, data2 = df[df[group_col]==group1][result_col].dropna(), df[df[group_col]==group2][result_col].dropna()
                t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=False)
                
                st.subheader("ğŸ” tæ£€éªŒç»“æœ")
                st.write(f"{group1}å‡å€¼ï¼š{data1.mean():.2f}ï¼Œ{group2}å‡å€¼ï¼š{data2.mean():.2f}")
                st.write(f"tç»Ÿè®¡é‡ï¼š{t_stat:.4f}ï¼Œpå€¼ï¼š{p_value:.4f}")
                
                fig = px.box(df, x=group_col, y=result_col, color_discrete_sequence=[params["chart_color"]],
                           title=f"{group_col}å¯¹{result_col}çš„å½±å“", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                report = f"""### åˆ†ææŠ¥å‘Š
1. æ£€éªŒåœºæ™¯ï¼š{group_col}åˆ†ç»„å¯¹{result_col}çš„å·®å¼‚
2. ç»“è®ºï¼š{'å­˜åœ¨æ˜¾è‘—å·®å¼‚' if p_value<0.05 else 'æ— æ˜¾è‘—å·®å¼‚'}ï¼ˆp={p_value:.4f}ï¼‰
3. å·®å¼‚å¹…åº¦ï¼š{group1}æ¯”{group2} {'é«˜' if data1.mean()>data2.mean() else 'ä½'} {abs(data1.mean()-data2.mean()):.2f}
"""

            # ANOVA
            elif target_analysis == "anova":
                model = ols(params["formula"], data=df).fit()
                anova_result = anova_lm(model, typ=2)
                st.subheader("ğŸ“Š æ–¹å·®åˆ†æç»“æœ")
                st.dataframe(anova_result, use_container_width=True)
                
                fig = px.box(df, x=params["factor_cols"][0], y=params["result_col"],
                           color=params["factor_cols"][1] if len(params["factor_cols"])>1 else None,
                           title=f"å„å› ç´ å¯¹{params['result_col']}çš„å½±å“", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                significant = [idx for idx, p in anova_result["PR(>F)"].items() if p<0.05]
                report = f"""### åˆ†ææŠ¥å‘Š
1. åˆ†æå…¬å¼ï¼š{params['formula']}
2. æ˜¾è‘—å› ç´ ï¼ˆp<0.05ï¼‰ï¼š{', '.join(significant) if significant else 'æ— '}
3. ç»“è®ºï¼š{'éƒ¨åˆ†å› ç´ å¯¹ç»“æœæœ‰æ˜¾è‘—å½±å“' if significant else 'æ‰€æœ‰å› ç´ æ— æ˜¾è‘—å½±å“'}
"""

            # çº¿æ€§å›å½’
            elif target_analysis == "regression":
                x_col, y_col = params["x_col"], params["y_col"]
                df_reg = df[[x_col, y_col]].dropna()
                model = ols(f"{y_col} ~ {x_col}", data=df_reg).fit()
                
                st.subheader("ğŸ“ˆ å›å½’ç»“æœ")
                st.write(f"å›å½’æ–¹ç¨‹ï¼š{y_col} = {model.params[0]:.2f} + {model.params[x_col]:.4f}Ã—{x_col}")
                st.write(f"RÂ²ï¼š{model.rsquared:.4f}ï¼Œpå€¼ï¼š{model.pvalues[x_col]:.4f}")
                
                fig = px.scatter(df_reg, x=x_col, y=y_col, trendline="ols", color_discrete_sequence=[params["chart_color"]],
                               title=f"{x_col}å¯¹{y_col}çš„å›å½’", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                report = f"""### åˆ†ææŠ¥å‘Š
1. å˜é‡å…³ç³»ï¼š{'æ˜¾è‘—ç›¸å…³' if model.pvalues[x_col]<0.05 else 'æ— æ˜¾è‘—ç›¸å…³'}ï¼ˆp={model.pvalues[x_col]:.4f}ï¼‰
2. å›å½’ç³»æ•°ï¼š{model.params[x_col]:.4f}ï¼ˆ{x_col}æ¯å¢1ï¼Œ{y_col}{'å¢' if model.params[x_col]>0 else 'å‡'} {abs(model.params[x_col]):.4f}ï¼‰
3. æ‹Ÿåˆç¨‹åº¦ï¼šRÂ²={model.rsquared:.4f}ï¼ˆ{x_col}è§£é‡Š{y_col} {model.rsquared*100:.1f}%çš„å˜åŒ–ï¼‰
"""

            # é€»è¾‘å›å½’
            elif target_analysis == "logistic_reg":
                target_col, feature_cols = params["target_col"], params["feature_cols"]
                df_log = df[[*feature_cols, target_col + "_encoded"]].dropna()
                model = LogisticRegression()
                model.fit(df_log[feature_cols], df_log[target_col + "_encoded"])
                accuracy = model.score(df_log[feature_cols], df_log[target_col + "_encoded"])
                coefs = dict(zip(feature_cols, model.coef_[0]))
                
                st.subheader("ğŸ”® é€»è¾‘å›å½’ç»“æœ")
                st.write(f"æ¨¡å‹å‡†ç¡®ç‡ï¼š{accuracy:.4f}")
                st.dataframe(pd.DataFrame({"ç‰¹å¾": coefs.keys(), "ç³»æ•°": coefs.values()}), use_container_width=True)
                
                fig = px.bar(x=coefs.keys(), y=coefs.values(), color_discrete_sequence=[params["chart_color"]],
                           title="ç‰¹å¾é‡è¦æ€§", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                report = f"""### åˆ†ææŠ¥å‘Š
1. é¢„æµ‹ç›®æ ‡ï¼š{target_col}ï¼Œæ¨¡å‹å‡†ç¡®ç‡ï¼š{accuracy:.4f}
2. å…³é”®ç‰¹å¾ï¼š{max(coefs, key=coefs.get)}ï¼ˆç³»æ•°{coefs[max(coefs, key=coefs.get)]:.4f}ï¼‰
3. ç»“è®ºï¼šæ¨¡å‹å¯ç”¨äº{target_col}çš„äºŒåˆ†ç±»é¢„æµ‹
"""

            # K-Meansèšç±»
            elif target_analysis == "kmeans":
                feature_cols = params["feature_cols"]
                df_cluster = df[feature_cols].dropna()
                kmeans = KMeans(n_clusters=params["n_clusters"], random_state=42).fit(df_cluster)
                df["èšç±»æ ‡ç­¾"] = kmeans.labels_
                
                st.subheader("ğŸŒ€ èšç±»ç»“æœ")
                st.dataframe(df["èšç±»æ ‡ç­¾"].value_counts(), use_container_width=True)
                st.dataframe(pd.DataFrame(kmeans.cluster_centers_, columns=feature_cols), use_container_width=True)
                
                fig = px.scatter(df_cluster, x=feature_cols[0], y=feature_cols[1], color=kmeans.labels_,
                               color_discrete_sequence=[params["chart_color"], "#ff7f0e", "#2ca02c", "#d62728"][:params["n_clusters"]],
                               title=f"K={params['n_clusters']}èšç±»ç»“æœ", width=params["chart_width"], height=params["chart_height"])
                st.plotly_chart(fig, use_container_width=True)
                
                report = f"""### åˆ†ææŠ¥å‘Š
1. èšç±»æ•°é‡ï¼š{params['n_clusters']}ç»„ï¼Œæ ·æœ¬æ•°ï¼š{dict(df['èšç±»æ ‡ç­¾'].value_counts())}
2. æ ¸å¿ƒç‰¹å¾ï¼šå„èšç±»ä¸­å¿ƒåæ˜ ç»„å†…ç‰¹å¾å‡å€¼
3. åº”ç”¨ï¼šå¯ç”¨äºæ•°æ®åˆ†ç¾¤ç®¡ç†ã€å·®å¼‚åŒ–ç­–ç•¥åˆ¶å®š
"""

            # æŠ¥å‘Šä¸‹è½½
            st.divider()
            st.markdown(report)
            st.download_button(
                label="ğŸ“¥ ä¸‹è½½åˆ†ææŠ¥å‘Šï¼ˆMarkdownï¼‰",
                data=report,
                file_name=f"æ™ºèƒ½åˆ†ææŠ¥å‘Š_{analysis_type}.md",
                mime="text/markdown"
            )
            
    except Exception as e:
        st.error(f"âŒ åˆ†æå¤±è´¥ï¼š{str(e)}")
        st.info("ğŸ’¡ å¯èƒ½åŸå› ï¼šæ•°æ®ç¼ºå¤±è¿‡å¤šã€å˜é‡é€‰æ‹©ä¸å½“ã€æ ·æœ¬é‡ä¸è¶³")
